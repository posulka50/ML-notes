# K-Means Clustering (K-—Å–µ—Ä–µ–¥–Ω—ñ—Ö)

## –©–æ —Ü–µ?

**K-Means** ‚Äî —Ü–µ –∞–ª–≥–æ—Ä–∏—Ç–º unsupervised learning –¥–ª—è **–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó** (–≥—Ä—É–ø—É–≤–∞–Ω–Ω—è) –¥–∞–Ω–∏—Ö —É $K$ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ö–æ–∂–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–∞–Ω—ñ –Ω–∞ $K$ –≥—Ä—É–ø —Ç–∞–∫, —â–æ–± –æ–±'—î–∫—Ç–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∞ –±—É–ª–∏ —Å—Ö–æ–∂–∏–º–∏, –∞ –æ–±'—î–∫—Ç–∏ –∑ —Ä—ñ–∑–Ω–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Äî –≤—ñ–¥–º—ñ–Ω–Ω–∏–º–∏.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω?

- üéØ **–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç—ñ–≤** ‚Äî —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –∫–ª—ñ—î–Ω—Ç—ñ–≤ –Ω–∞ –≥—Ä—É–ø–∏ –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–æ–≤–∞–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É
- üìä **–°—Ç–∏—Å–Ω–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö** ‚Äî –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–∏ –¥–∞–Ω—ñ –º–µ–Ω—à–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤
- üîç **Anomaly detection** ‚Äî –∑–Ω–∞–π—Ç–∏ –≤–∏–∫–∏–¥–∏ (–¥–∞–ª–µ–∫–æ –≤—ñ–¥ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤)
- üé® **–°—Ç–∏—Å–Ω–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å** ‚Äî –∑–º–µ–Ω—à–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª—å–æ—Ä—ñ–≤
- üìà **Feature engineering** ‚Äî —Å—Ç–≤–æ—Ä–∏—Ç–∏ –Ω–æ–≤—ñ –æ–∑–Ω–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
- üó∫Ô∏è **–ì–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è** ‚Äî –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è –ª–æ–∫–∞—Ü—ñ–π

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–ó–Ω–∞—î–º–æ –ø—Ä–∏–±–ª–∏–∑–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** $K$
- –ö–ª–∞—Å—Ç–µ—Ä–∏ **–ø—Ä–∏–±–ª–∏–∑–Ω–æ —Å—Ñ–µ—Ä–∏—á–Ω–æ—ó —Ñ–æ—Ä–º–∏**
- –ö–ª–∞—Å—Ç–µ—Ä–∏ **–ø—Ä–∏–±–ª–∏–∑–Ω–æ –æ–¥–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É**
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ **—à–≤–∏–¥–∫—ñ—Å—Ç—å** ‚Äî K-Means –¥—É–∂–µ —à–≤–∏–¥–∫–∏–π
- **–ß–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏** (–Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω—ñ)
- –í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ (–º–∞—Å—à—Ç–∞–±—É—î—Ç—å—Å—è –¥–æ–±—Ä–µ)

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–ù–µ –∑–Ω–∞—î–º–æ $K$** ‚Üí Hierarchical Clustering, DBSCAN
- –ö–ª–∞—Å—Ç–µ—Ä–∏ **—Å–∫–ª–∞–¥–Ω–æ—ó —Ñ–æ—Ä–º–∏** (–µ–ª—ñ–ø—Å–∏, –¥–æ–≤–≥—ñ) ‚Üí DBSCAN, Gaussian Mixture
- –ö–ª–∞—Å—Ç–µ—Ä–∏ **—Ä—ñ–∑–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É/—â—ñ–ª—å–Ω–æ—Å—Ç—ñ** ‚Üí DBSCAN
- **–ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ** ‚Üí K-Modes
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ **—ñ—î—Ä–∞—Ä—Ö—ñ—è** –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí Hierarchical Clustering

---

## –Ø–∫ –ø—Ä–∞—Ü—é—î K-Means?

### –ê–ª–≥–æ—Ä–∏—Ç–º

**–í—Ö—ñ–¥:** –¥–∞–Ω—ñ $X = \{x_1, x_2, ..., x_n\}$, –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ $K$

**1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
   - –í–∏–ø–∞–¥–∫–æ–≤–æ –≤–∏–±—Ä–∞—Ç–∏ $K$ —Ç–æ—á–æ–∫ —è–∫ –ø–æ—á–∞—Ç–∫–æ–≤—ñ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ $\mu_1, \mu_2, ..., \mu_K$

**2. –ü–æ–≤—Ç–æ—Ä—é–≤–∞—Ç–∏ –¥–æ –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ:**

   **a) Assignment step (–ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è):**
   - –î–ª—è –∫–æ–∂–Ω–æ—ó —Ç–æ—á–∫–∏ $x_i$ –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–±–ª–∏–∂—á–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥
   - –ü—Ä–∏–∑–Ω–∞—á–∏—Ç–∏ —Ç–æ—á–∫—É –¥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ $c_i$:
   $$c_i = \arg\min_k ||x_i - \mu_k||^2$$

   **b) Update step (–æ–Ω–æ–≤–ª–µ–Ω–Ω—è):**
   - –ü–µ—Ä–µ—Ä–∞—Ö—É–≤–∞—Ç–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ —è–∫ —Å–µ—Ä–µ–¥–Ω—î —Ç–æ—á–æ–∫ —É –∫–ª–∞—Å—Ç–µ—Ä—ñ:
   $$\mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i$$
   –¥–µ $C_k$ ‚Äî –º–Ω–æ–∂–∏–Ω–∞ —Ç–æ—á–æ–∫ —É –∫–ª–∞—Å—Ç–µ—Ä—ñ $k$

**3. –ó—É–ø–∏–Ω–∫–∞:**
   - –¶–µ–Ω—Ç—Ä–æ—ó–¥–∏ –Ω–µ –∑–º—ñ–Ω—é—é—Ç—å—Å—è
   - –ê–±–æ –¥–æ—Å—è–≥–Ω—É—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–ª–≥–æ—Ä–∏—Ç–º—É

```
–Ü—Ç–µ—Ä–∞—Ü—ñ—è 0 (—ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è):
    y
    |  ‚Ä¢   ‚Ä¢ ‚Ä¢
    |    +     ‚Ä¢    + = —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏
    | ‚Ä¢    ‚Ä¢  ‚Ä¢
    |‚Ä¢   +   ‚Ä¢
    |_________ x

–Ü—Ç–µ—Ä–∞—Ü—ñ—è 1 (assignment):
    y
    |  üî¥   üî¥ üî¥
    |    +     üîµ    
    | üîµ    üîµ  üîµ
    |üü¢   +   üü¢
    |_________ x
    
    –ö–æ–∂–Ω–∞ —Ç–æ—á–∫–∞ –ø–æ—Ñ–∞—Ä–±–æ–≤–∞–Ω–∞ –≤ –∫–æ–ª—ñ—Ä –Ω–∞–π–±–ª–∏–∂—á–æ–≥–æ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—É

–Ü—Ç–µ—Ä–∞—Ü—ñ—è 1 (update):
    y
    |  üî¥   üî¥ üî¥
    |      +   üîµ    ‚Üê —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ –∑—Å—É–Ω—É–ª–∏—Å—å
    | üîµ    üîµ  üîµ
    |üü¢     +
    |_________ x

–Ü—Ç–µ—Ä–∞—Ü—ñ—è 2-3... ‚Üí –∑–±—ñ–∂–Ω—ñ—Å—Ç—å
```

### –§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç (Inertia / Within-Cluster Sum of Squares)

$$J = \sum_{k=1}^{K} \sum_{x_i \in C_k} ||x_i - \mu_k||^2$$

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:** —Å—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ –≤—ñ–¥—Å—Ç–∞–Ω–µ–π –≤—ñ–¥ —Ç–æ—á–æ–∫ –¥–æ —ó—Ö–Ω—ñ—Ö —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤.

**–ú–µ—Ç–∞:** –º—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ $J$ ‚Üí –∫–æ–º–ø–∞–∫—Ç–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏.

---

## –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

### –ï–≤–∫–ª—ñ–¥–æ–≤–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å

$$d(x_i, \mu_k) = ||x_i - \mu_k|| = \sqrt{\sum_{j=1}^{p} (x_{ij} - \mu_{kj})^2}$$

–¥–µ:
- $p$ ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
- $x_{ij}$ ‚Äî –∑–Ω–∞—á–µ–Ω–Ω—è $j$-—ó –æ–∑–Ω–∞–∫–∏ —Ç–æ—á–∫–∏ $i$
- $\mu_{kj}$ ‚Äî –∑–Ω–∞—á–µ–Ω–Ω—è $j$-—ó –æ–∑–Ω–∞–∫–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞ $k$

**–î–ª—è 2D:**
$$d = \sqrt{(x_1 - \mu_1)^2 + (x_2 - \mu_2)^2}$$

### –ü—Ä–∏–∫–ª–∞–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è

**–¢–æ—á–∫–∞:** $x = [3, 4]$
**–¶–µ–Ω—Ç—Ä–æ—ó–¥:** $\mu = [1, 2]$

$$d = \sqrt{(3-1)^2 + (4-2)^2} = \sqrt{4 + 4} = \sqrt{8} \approx 2.83$$

### –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞

**–ö–ª–∞—Å—Ç–µ—Ä –º—ñ—Å—Ç–∏—Ç—å —Ç–æ—á–∫–∏:** $\{[1, 2], [3, 4], [2, 3]\}$

**–ù–æ–≤–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥:**
$$\mu = \left[\frac{1+3+2}{3}, \frac{2+4+3}{3}\right] = [2, 3]$$

---

## –ü—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥: –°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç—ñ–≤

### –î–∞–Ω—ñ

| –ö–ª—ñ—î–Ω—Ç | –í—ñ–∫ | –î–æ—Ö—ñ–¥ (—Ç–∏—Å. $) |
|--------|-----|----------------|
| A | 25 | 30 |
| B | 45 | 80 |
| C | 35 | 50 |
| D | 50 | 90 |
| E | 28 | 35 |
| F | 47 | 85 |
| G | 32 | 45 |

**–ú–µ—Ç–∞:** —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –Ω–∞ $K=2$ —Å–µ–≥–º–µ–Ω—Ç–∏.

### –Ü—Ç–µ—Ä–∞—Ü—ñ—è 0: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è

**–í–∏–ø–∞–¥–∫–æ–≤–æ –≤–∏–±—Ä–∞–Ω—ñ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏:**
- $\mu_1 = [25, 30]$ (–∫–ª—ñ—î–Ω—Ç A)
- $\mu_2 = [50, 90]$ (–∫–ª—ñ—î–Ω—Ç D)

### –Ü—Ç–µ—Ä–∞—Ü—ñ—è 1: Assignment

**–î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª—ñ—î–Ω—Ç–∞ –æ–±—á–∏—Å–ª—é—î–º–æ –≤—ñ–¥—Å—Ç–∞–Ω—ñ:**

**–ö–ª—ñ—î–Ω—Ç B:** $[45, 80]$
- –î–æ $\mu_1$: $\sqrt{(45-25)^2 + (80-30)^2} = \sqrt{400+2500} = 53.85$
- –î–æ $\mu_2$: $\sqrt{(45-50)^2 + (80-90)^2} = \sqrt{25+100} = 11.18$ ‚úì

**–ö–ª—ñ—î–Ω—Ç B ‚Üí –ö–ª–∞—Å—Ç–µ—Ä 2**

–ê–Ω–∞–ª–æ–≥—ñ—á–Ω–æ –¥–ª—è —ñ–Ω—à–∏—Ö...

**–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:**
- **–ö–ª–∞—Å—Ç–µ—Ä 1:** A, C, E, G (–º–æ–ª–æ–¥—ñ –∑ –Ω–∏–∑—å–∫–∏–º –¥–æ—Ö–æ–¥–æ–º)
- **–ö–ª–∞—Å—Ç–µ—Ä 2:** B, D, F (—Å—Ç–∞—Ä—à—ñ –∑ –≤–∏—Å–æ–∫–∏–º –¥–æ—Ö–æ–¥–æ–º)

### –Ü—Ç–µ—Ä–∞—Ü—ñ—è 1: Update

**–ö–ª–∞—Å—Ç–µ—Ä 1:** $\{[25,30], [35,50], [28,35], [32,45]\}$
$$\mu_1 = \left[\frac{25+35+28+32}{4}, \frac{30+50+35+45}{4}\right] = [30, 40]$$

**–ö–ª–∞—Å—Ç–µ—Ä 2:** $\{[45,80], [50,90], [47,85]\}$
$$\mu_2 = \left[\frac{45+50+47}{3}, \frac{80+90+85}{3}\right] = [47.3, 85]$$

### –Ü—Ç–µ—Ä–∞—Ü—ñ—è 2, 3...

–ü–æ–≤—Ç–æ—Ä—é—î–º–æ –¥–æ –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ (—Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ –ø–µ—Ä–µ—Å—Ç–∞—é—Ç—å –∑–º—ñ–Ω—é–≤–∞—Ç–∏—Å—è).

**–§—ñ–Ω–∞–ª—å–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏:**
- **–°–µ–≥–º–µ–Ω—Ç 1:** "–ú–æ–ª–æ–¥—ñ –∑ —Å–µ—Ä–µ–¥–Ω—ñ–º –¥–æ—Ö–æ–¥–æ–º"
- **–°–µ–≥–º–µ–Ω—Ç 2:** "–°—Ç–∞—Ä—à—ñ –∑ –≤–∏—Å–æ–∫–∏–º –¥–æ—Ö–æ–¥–æ–º"

---

## –°–∫–ª–∞–¥–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: –°—Ç–∏—Å–Ω–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è

### –ó–∞–¥–∞—á–∞

–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è 100x100 –ø—ñ–∫—Å–µ–ª—ñ–≤, RGB (16,777,216 –º–æ–∂–ª–∏–≤–∏—Ö –∫–æ–ª—å–æ—Ä—ñ–≤).

**–ú–µ—Ç–∞:** –∑–º–µ–Ω—à–∏—Ç–∏ –¥–æ $K=16$ –∫–æ–ª—å–æ—Ä—ñ–≤ (—Å—Ç–∏—Å–Ω–µ–Ω–Ω—è).

### –ü—ñ–¥—Ö—ñ–¥

1. –ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–∏ –∫–æ–∂–µ–Ω –ø—ñ–∫—Å–µ–ª—å —è–∫ —Ç–æ—á–∫—É –≤ 3D –ø—Ä–æ—Å—Ç–æ—Ä—ñ: $[R, G, B]$
2. –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ K-Means –∑ $K=16$
3. –ó–∞–º—ñ–Ω–∏—Ç–∏ –∫–æ–∂–µ–Ω –ø—ñ–∫—Å–µ–ª—å –Ω–∞ —Ü–µ–Ω—Ç—Ä–æ—ó–¥ –π–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞

### –†–µ–∑—É–ª—å—Ç–∞—Ç

**–î–æ:** 10,000 –ø—ñ–∫—Å–µ–ª—ñ–≤ √ó 3 –±–∞–π—Ç–∏ = 30,000 –±–∞–π—Ç
**–ü—ñ—Å–ª—è:** 10,000 —ñ–Ω–¥–µ–∫—Å—ñ–≤ (4 –±—ñ—Ç–∏) + 16 —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤ √ó 3 –±–∞–π—Ç–∏ = 5,048 –±–∞–π—Ç

**–°—Ç–∏—Å–Ω–µ–Ω–Ω—è:** ~83% üéâ

### –ö–æ–¥ (–ø—Ä–∏–∫–ª–∞–¥)

```python
from sklearn.cluster import KMeans
import numpy as np
from PIL import Image

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
img = Image.open('image.jpg')
img_array = np.array(img)  # shape: (height, width, 3)

# Reshape –¥–æ (n_pixels, 3)
pixels = img_array.reshape(-1, 3)

# K-Means –∑ 16 –∫–æ–ª—å–æ—Ä–∞–º–∏
kmeans = KMeans(n_clusters=16, random_state=42, n_init=10)
kmeans.fit(pixels)

# –ó–∞–º—ñ–Ω–∏—Ç–∏ –∫–æ–∂–µ–Ω –ø—ñ–∫—Å–µ–ª—å –Ω–∞ —Ü–µ–Ω—Ç—Ä–æ—ó–¥
compressed_pixels = kmeans.cluster_centers_[kmeans.labels_]

# Reshape –Ω–∞–∑–∞–¥ –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
compressed_img = compressed_pixels.reshape(img_array.shape).astype(np.uint8)

# –ó–±–µ—Ä–µ–≥—Ç–∏
Image.fromarray(compressed_img).save('compressed.jpg')
```

---

## –ö–æ–¥ (Python + scikit-learn)

### –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
X, y_true = make_blobs(
    n_samples=300,
    centers=4,
    cluster_std=0.60,
    random_state=42
)

# 2. K-Means
kmeans = KMeans(
    n_clusters=4,        # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
    init='k-means++',    # –ú–µ—Ç–æ–¥ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó (—Ä–æ–∑—É–º–Ω–∏–π –≤–∏–±—ñ—Ä)
    n_init=10,           # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø—É—Å–∫—ñ–≤ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞–º–∏
    max_iter=300,        # –ú–∞–∫—Å–∏–º—É–º —ñ—Ç–µ—Ä–∞—Ü—ñ–π
    random_state=42
)

# 3. –ù–∞–≤—á–∞–Ω–Ω—è
kmeans.fit(X)

# 4. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏
labels = kmeans.labels_              # –ú—ñ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ç–æ—á–∫–∏
centroids = kmeans.cluster_centers_  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤
inertia = kmeans.inertia_            # –°—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ –≤—ñ–¥—Å—Ç–∞–Ω–µ–π (WCSS)

print(f"Inertia (WCSS): {inertia:.2f}")
print(f"Number of iterations: {kmeans.n_iter_}")

# 5. –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
X_new = np.array([[0, 0], [4, 4]])
predicted_labels = kmeans.predict(X_new)
print(f"Predicted clusters: {predicted_labels}")

# 6. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(12, 5))

# –î–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó
plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.6)
plt.title('Before K-Means', fontsize=14, fontweight='bold')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True, alpha=0.3)

# –ü—ñ—Å–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó
plt.subplot(1, 2, 2)
plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, alpha=0.6, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], 
            c='red', s=200, marker='X', edgecolors='black', linewidths=2,
            label='Centroids')
plt.title('After K-Means', fontsize=14, fontweight='bold')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### –ü–æ–≤–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: –°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç—ñ–≤

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –ø—Ä–æ –∫–ª—ñ—î–Ω—Ç—ñ–≤
np.random.seed(42)
n_customers = 500

data = {
    'Age': np.concatenate([
        np.random.normal(25, 5, 150),   # –ú–æ–ª–æ–¥—ñ
        np.random.normal(45, 8, 200),   # –°–µ—Ä–µ–¥–Ω—ñ–π –≤—ñ–∫
        np.random.normal(65, 7, 150)    # –°—Ç–∞—Ä—à—ñ
    ]),
    'Income': np.concatenate([
        np.random.normal(35, 8, 150),   # –ù–∏–∑—å–∫–∏–π –¥–æ—Ö—ñ–¥
        np.random.normal(65, 12, 200),  # –°–µ—Ä–µ–¥–Ω—ñ–π –¥–æ—Ö—ñ–¥
        np.random.normal(95, 15, 150)   # –í–∏—Å–æ–∫–∏–π –¥–æ—Ö—ñ–¥
    ]),
    'Spending_Score': np.concatenate([
        np.random.normal(30, 10, 150),
        np.random.normal(50, 15, 200),
        np.random.normal(75, 12, 150)
    ])
}

df = pd.DataFrame(data)

# –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∏—Ö –º–µ–∂–∞—Ö
df['Age'] = df['Age'].clip(18, 80)
df['Income'] = df['Income'].clip(20, 150)
df['Spending_Score'] = df['Spending_Score'].clip(1, 100)

print("=== Dataset Info ===")
print(df.describe())

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for idx, col in enumerate(['Age', 'Income', 'Spending_Score']):
    axes[idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7)
    axes[idx].set_xlabel(col, fontsize=11)
    axes[idx].set_ylabel('Frequency', fontsize=11)
    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è (–í–ê–ñ–õ–ò–í–û –¥–ª—è K-Means!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[['Age', 'Income', 'Spending_Score']])

# K-Means –∑ —Ä—ñ–∑–Ω–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
K_range = range(2, 11)
inertias = []
silhouette_scores = []

from sklearn.metrics import silhouette_score

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))

# Elbow Method —Ç–∞ Silhouette Score
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Elbow plot
axes[0].plot(K_range, inertias, 'o-', linewidth=2, markersize=8)
axes[0].set_xlabel('Number of Clusters (K)', fontsize=12)
axes[0].set_ylabel('Inertia (WCSS)', fontsize=12)
axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].axvline(x=4, color='red', linestyle='--', alpha=0.5, label='Optimal K=4')
axes[0].legend()

# Silhouette score
axes[1].plot(K_range, silhouette_scores, 's-', linewidth=2, markersize=8, color='green')
axes[1].set_xlabel('Number of Clusters (K)', fontsize=12)
axes[1].set_ylabel('Silhouette Score', fontsize=12)
axes[1].set_title('Silhouette Score vs K', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)
axes[1].axvline(x=4, color='red', linestyle='--', alpha=0.5, label='Optimal K=4')
axes[1].legend()

plt.tight_layout()
plt.show()

print(f"\nOptimal K (Elbow): ~4")
print(f"Optimal K (Silhouette): {K_range[np.argmax(silhouette_scores)]}")

# –§—ñ–Ω–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å –∑ K=4
optimal_k = 4
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans_final.fit_predict(X_scaled)

# –ê–Ω–∞–ª—ñ–∑ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
print("\n" + "="*70)
print("=== Cluster Analysis ===")
print("="*70)

for cluster in range(optimal_k):
    cluster_data = df[df['Cluster'] == cluster]
    print(f"\nCluster {cluster} (n={len(cluster_data)}):")
    print(cluster_data[['Age', 'Income', 'Spending_Score']].mean())

# –ù–∞–∑–≤–∏ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
cluster_names = {
    0: "Young Low Income",
    1: "Middle Age Medium Income",
    2: "Senior High Income",
    3: "Young High Spenders"
}

df['Segment'] = df['Cluster'].map(cluster_names)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
fig = plt.figure(figsize=(16, 12))

# 3D scatter
ax1 = fig.add_subplot(2, 2, 1, projection='3d')
scatter = ax1.scatter(df['Age'], df['Income'], df['Spending_Score'],
                     c=df['Cluster'], cmap='viridis', s=50, alpha=0.6)
ax1.set_xlabel('Age', fontsize=11)
ax1.set_ylabel('Income', fontsize=11)
ax1.set_zlabel('Spending Score', fontsize=11)
ax1.set_title('3D Cluster Visualization', fontsize=13, fontweight='bold')
plt.colorbar(scatter, ax=ax1, label='Cluster')

# Age vs Income
ax2 = fig.add_subplot(2, 2, 2)
for cluster in range(optimal_k):
    cluster_data = df[df['Cluster'] == cluster]
    ax2.scatter(cluster_data['Age'], cluster_data['Income'],
               label=f'Cluster {cluster}', s=50, alpha=0.6)
ax2.set_xlabel('Age', fontsize=11)
ax2.set_ylabel('Income', fontsize=11)
ax2.set_title('Age vs Income', fontsize=13, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Income vs Spending
ax3 = fig.add_subplot(2, 2, 3)
for cluster in range(optimal_k):
    cluster_data = df[df['Cluster'] == cluster]
    ax3.scatter(cluster_data['Income'], cluster_data['Spending_Score'],
               label=f'Cluster {cluster}', s=50, alpha=0.6)
ax3.set_xlabel('Income', fontsize=11)
ax3.set_ylabel('Spending Score', fontsize=11)
ax3.set_title('Income vs Spending Score', fontsize=13, fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

# Cluster sizes
ax4 = fig.add_subplot(2, 2, 4)
cluster_sizes = df['Cluster'].value_counts().sort_index()
ax4.bar(cluster_sizes.index, cluster_sizes.values, color='skyblue', edgecolor='black')
ax4.set_xlabel('Cluster', fontsize=11)
ax4.set_ylabel('Number of Customers', fontsize=11)
ax4.set_title('Cluster Sizes', fontsize=13, fontweight='bold')
ax4.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

# –ü—Ä–æ—Ñ—ñ–ª—ñ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
print("\n" + "="*70)
print("=== Customer Segments Profiles ===")
print("="*70)

for cluster in range(optimal_k):
    print(f"\n{cluster_names[cluster]}:")
    cluster_profile = df[df['Cluster'] == cluster][['Age', 'Income', 'Spending_Score']].describe()
    print(cluster_profile.loc[['mean', 'std']])
```

---

## –í–∏–±—ñ—Ä –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ K

### –ü—Ä–æ–±–ª–µ–º–∞

**K-Means –ø–æ—Ç—Ä–µ–±—É—î –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –∑–∞–¥–∞–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ $K$!**

–Ø–∫ –≤–∏–±—Ä–∞—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–µ $K$?

### 1. Elbow Method (–ú–µ—Ç–æ–¥ –ª—ñ–∫—Ç—è)

**–Ü–¥–µ—è:** –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ—ñ–∫ inertia (WCSS) vs $K$ —Ç–∞ –∑–Ω–∞–π—Ç–∏ "–ª—ñ–∫–æ—Ç—å".

```python
inertias = []
K_range = range(1, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(K_range, inertias, 'o-', linewidth=2, markersize=8)
plt.xlabel('Number of Clusters (K)', fontsize=12)
plt.ylabel('Inertia (WCSS)', fontsize=12)
plt.title('Elbow Method', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

**–ì—Ä–∞—Ñ—ñ–∫:**
```
Inertia
    |‚Ä¢
    | ‚Ä¢
    |  ‚Ä¢
    |   ‚Ä¢___  ‚Üê "–õ—ñ–∫–æ—Ç—å" (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π K)
    |       ‚Ä¢___
    |           ‚Ä¢___
    |_______________  K
     1  2  3  4  5  6
```

**–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π K:** —Ç–∞–º, –¥–µ –∫—Ä–∏–≤–∞ "–∑–ª–∞–º—É—î—Ç—å—Å—è" (—Ñ–æ—Ä–º—É—î –ª—ñ–∫–æ—Ç—å).

**–ù–µ–¥–æ–ª—ñ–∫:** –Ω–µ –∑–∞–≤–∂–¥–∏ —á—ñ—Ç–∫–∏–π –ª—ñ–∫–æ—Ç—å.

### 2. Silhouette Score

**Silhouette coefficient** –¥–ª—è —Ç–æ—á–∫–∏ $i$:

$$s_i = \frac{b_i - a_i}{\max(a_i, b_i)}$$

–¥–µ:
- $a_i$ ‚Äî —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å –¥–æ —Ç–æ—á–æ–∫ —Å–≤–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
- $b_i$ ‚Äî —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å –¥–æ —Ç–æ—á–æ–∫ –Ω–∞–π–±–ª–∏–∂—á–æ–≥–æ —ñ–Ω—à–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞

**–î—ñ–∞–ø–∞–∑–æ–Ω:** $[-1, 1]$
- $s_i \approx 1$ ‚Üí –¥–æ–±—Ä–µ –∫–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ ‚úì
- $s_i \approx 0$ ‚Üí –Ω–∞ –º–µ–∂—ñ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
- $s_i < 0$ ‚Üí –º–æ–∂–ª–∏–≤–æ –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—ñ ‚úó

**–°–µ—Ä–µ–¥–Ω—ñ–π Silhouette Score –¥–ª—è –≤—Å—ñ—Ö —Ç–æ—á–æ–∫:**

```python
from sklearn.metrics import silhouette_score

silhouette_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    silhouette_scores.append(score)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 6))
plt.plot(K_range, silhouette_scores, 's-', linewidth=2, markersize=8)
plt.xlabel('Number of Clusters (K)', fontsize=12)
plt.ylabel('Silhouette Score', fontsize=12)
plt.title('Silhouette Score vs K', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"Optimal K: {optimal_k}")
print(f"Best Silhouette Score: {max(silhouette_scores):.4f}")
```

### 3. Silhouette Diagram

**–î–µ—Ç–∞–ª—å–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ $K$:

```python
from sklearn.metrics import silhouette_samples
import matplotlib.cm as cm

# K-Means –∑ K=4
kmeans = KMeans(n_clusters=4, random_state=42)
labels = kmeans.fit_predict(X)

# Silhouette values –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ç–æ—á–∫–∏
silhouette_vals = silhouette_samples(X, labels)

fig, ax = plt.subplots(figsize=(10, 6))

y_lower = 10
for i in range(4):
    # Silhouette values –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ i
    cluster_silhouette_vals = silhouette_vals[labels == i]
    cluster_silhouette_vals.sort()
    
    size_cluster_i = cluster_silhouette_vals.shape[0]
    y_upper = y_lower + size_cluster_i
    
    color = cm.viridis(float(i) / 4)
    ax.fill_betweenx(np.arange(y_lower, y_upper),
                     0, cluster_silhouette_vals,
                     facecolor=color, edgecolor=color, alpha=0.7)
    
    # Label –∫–ª–∞—Å—Ç–µ—Ä–∞
    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
    
    y_lower = y_upper + 10

ax.set_xlabel('Silhouette Coefficient', fontsize=12)
ax.set_ylabel('Cluster', fontsize=12)
ax.set_title('Silhouette Diagram (K=4)', fontsize=14, fontweight='bold')

# –°–µ—Ä–µ–¥–Ω—è –ª—ñ–Ω—ñ—è
avg_score = silhouette_score(X, labels)
ax.axvline(x=avg_score, color="red", linestyle="--", 
           label=f'Average: {avg_score:.3f}')
ax.legend()

plt.tight_layout()
plt.show()
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
- ‚úÖ –¢–æ–≤—Å—Ç—ñ –æ–¥–Ω–∞–∫–æ–≤—ñ "—Å—Ç–æ–≤–ø—á–∏–∫–∏" ‚Üí –¥–æ–±—Ä–µ
- ‚ö†Ô∏è –†—ñ–∑–Ω–∞ —Ç–æ–≤—â–∏–Ω–∞ ‚Üí –∫–ª–∞—Å—Ç–µ—Ä–∏ —Ä—ñ–∑–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É
- ‚ùå –°—Ç–æ–≤–ø—á–∏–∫–∏ –Ω–µ –¥–æ—Ö–æ–¥—è—Ç—å –¥–æ —Å–µ—Ä–µ–¥–Ω—å–æ—ó –ª—ñ–Ω—ñ—ó ‚Üí –ø–æ–≥–∞–Ω–æ

### 4. Gap Statistic

**–ü–æ—Ä—ñ–≤–Ω—é—î inertia –∑ –≤–∏–ø–∞–¥–∫–æ–≤–∏–º–∏ –¥–∞–Ω–∏–º–∏:**

$$\text{Gap}(k) = E[\log(W_k^*)] - \log(W_k)$$

–¥–µ:
- $W_k$ ‚Äî inertia –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–∏—Ö
- $W_k^*$ ‚Äî inertia –¥–ª—è –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

**–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π $K$:** –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π gap.

### 5. Davies-Bouldin Index

$$DB = \frac{1}{K} \sum_{i=1}^{K} \max_{j \neq i} \left(\frac{s_i + s_j}{d_{ij}}\right)$$

–¥–µ:
- $s_i$ ‚Äî —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å —Ç–æ—á–æ–∫ –¥–æ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ $i$
- $d_{ij}$ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞–º–∏ $i$ —Ç–∞ $j$

**–ú–µ–Ω—à–µ –∑–Ω–∞—á–µ–Ω–Ω—è ‚Üí –∫—Ä–∞—â–µ!**

```python
from sklearn.metrics import davies_bouldin_score

db_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    score = davies_bouldin_score(X, labels)
    db_scores.append(score)

optimal_k = K_range[np.argmin(db_scores)]
print(f"Optimal K (Davies-Bouldin): {optimal_k}")
```

---

## –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤

### –ü—Ä–æ–±–ª–µ–º–∞

**–í–∏–ø–∞–¥–∫–æ–≤–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è** –º–æ–∂–µ –ø—Ä–∏–∑–≤–µ—Å—Ç–∏ –¥–æ:
- –ü–æ–≤—ñ–ª—å–Ω–æ—ó –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ
- –õ–æ–∫–∞–ª—å–Ω–∏—Ö –º—ñ–Ω—ñ–º—É–º—ñ–≤ (–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω–∏–π –æ–ø—Ç–∏–º—É–º)

### 1. Random Initialization

**–ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º:** –≤–∏–ø–∞–¥–∫–æ–≤–æ –≤–∏–±—Ä–∞—Ç–∏ $K$ —Ç–æ—á–æ–∫ –∑ –¥–∞–Ω–∏—Ö.

**–ù–µ–¥–æ–ª—ñ–∫:** –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ luck.

### 2. K-Means++ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ ‚úì)

**–†–æ–∑—É–º–Ω–∏–π –≤–∏–±—ñ—Ä –ø–æ—á–∞—Ç–∫–æ–≤–∏—Ö —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤:**

1. –í–∏–±—Ä–∞—Ç–∏ –ø–µ—Ä—à–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥ –≤–∏–ø–∞–¥–∫–æ–≤–æ
2. –î–ª—è –∫–æ–∂–Ω–æ—ó –Ω–∞—Å—Ç—É–ø–Ω–æ—ó –ø–æ–∑–∏—Ü—ñ—ó:
   - –û–±—á–∏—Å–ª–∏—Ç–∏ –≤—ñ–¥—Å—Ç–∞–Ω—å $D(x)$ –≤—ñ–¥ –∫–æ–∂–Ω–æ—ó —Ç–æ—á–∫–∏ –¥–æ –Ω–∞–π–±–ª–∏–∂—á–æ–≥–æ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞
   - –í–∏–±—Ä–∞—Ç–∏ –Ω–æ–≤—É —Ç–æ—á–∫—É –∑ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—é $\propto D(x)^2$
   - (–¢–æ—á–∫–∏ –¥–∞–ª—ñ –≤—ñ–¥ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤ –º–∞—é—Ç—å –≤–∏—â—É –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å)

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –®–≤–∏–¥—à–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å
- ‚úÖ –ö—Ä–∞—â—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
- ‚úÖ –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º —É scikit-learn

```python
kmeans = KMeans(n_clusters=4, init='k-means++')  # –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
# –∞–±–æ
kmeans = KMeans(n_clusters=4, init='random')     # –í–∏–ø–∞–¥–∫–æ–≤–æ
```

### 3. Multiple Runs (n_init)

**–ó–∞–ø—É—Å—Ç–∏—Ç–∏ K-Means –∫—ñ–ª—å–∫–∞ —Ä–∞–∑—ñ–≤** –∑ —Ä—ñ–∑–Ω–∏–º–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è–º–∏ —Ç–∞ –≤–∏–±—Ä–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ inertia).

```python
kmeans = KMeans(n_clusters=4, n_init=10)  # 10 –∑–∞–ø—É—Å–∫—ñ–≤
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–±–µ—Ä–µ –Ω–∞–π–∫—Ä–∞—â–∏–π
```

**–ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º:** `n_init=10` —É scikit-learn.

---

## –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ K-Means

### –û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
KMeans(
    n_clusters=8,           # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
    init='k-means++',       # –ú–µ—Ç–æ–¥ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
    n_init=10,              # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø—É—Å–∫—ñ–≤
    max_iter=300,           # –ú–∞–∫—Å–∏–º—É–º —ñ—Ç–µ—Ä–∞—Ü—ñ–π
    tol=1e-4,               # –ö—Ä–∏—Ç–µ—Ä—ñ–π –∑—É–ø–∏–Ω–∫–∏
    random_state=42,        # –í—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
    algorithm='lloyd'       # –ê–ª–≥–æ—Ä–∏—Ç–º ('lloyd', 'elkan')
)
```

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å | –¢–∏–ø–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è |
|----------|------|-----------------|
| **n_clusters** | –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ $K$ | 2-10 (–≤–∏–∑–Ω–∞—á–∏—Ç–∏ —á–µ—Ä–µ–∑ Elbow/Silhouette) |
| **init** | –ú–µ—Ç–æ–¥ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó | 'k-means++' (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ), 'random' |
| **n_init** | –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø—É—Å–∫—ñ–≤ | 10 (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º) |
| **max_iter** | –ú–∞–∫—Å. —ñ—Ç–µ—Ä–∞—Ü—ñ–π | 300 |
| **tol** | –ö—Ä–∏—Ç–µ—Ä—ñ–π –∑—É–ø–∏–Ω–∫–∏ | 1e-4 |
| **random_state** | Seed –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ | 42 |

### –ê–ª–≥–æ—Ä–∏—Ç–º–∏

**Lloyd (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π):**
- –ö–ª–∞—Å–∏—á–Ω–∏–π K-Means –∞–ª–≥–æ—Ä–∏—Ç–º
- $O(nKdi)$ –¥–µ $d$ ‚Äî —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å, $i$ ‚Äî —ñ—Ç–µ—Ä–∞—Ü—ñ—ó

**Elkan:**
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î triangle inequality –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
- –®–≤–∏–¥—à–µ –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö –∑ –±–∞–≥–∞—Ç—å–º–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
- –ü—Ä–∞—Ü—é—î —Ç—ñ–ª—å–∫–∏ –∑ Euclidean distance

```python
# –î–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
kmeans = KMeans(algorithm='elkan')
```

---

## Mini-Batch K-Means

### –ü—Ä–æ–±–ª–µ–º–∞

**K-Means –ø–æ–≤—ñ–ª—å–Ω–∏–π –Ω–∞ –¥—É–∂–µ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö** (–º—ñ–ª—å–π–æ–Ω–∏ —Ç–æ—á–æ–∫).

### –†—ñ—à–µ–Ω–Ω—è: Mini-Batch K-Means

**–Ü–¥–µ—è:** –Ω–∞ –∫–æ–∂–Ω—ñ–π —ñ—Ç–µ—Ä–∞—Ü—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –≤–∏–ø–∞–¥–∫–æ–≤—É –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—É (mini-batch) –∑–∞–º—ñ—Å—Ç—å –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö.

### –ê–ª–≥–æ—Ä–∏—Ç–º

1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏
2. –ü–æ–≤—Ç–æ—Ä—é–≤–∞—Ç–∏:
   - –í–∏–±—Ä–∞—Ç–∏ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π mini-batch —Ä–æ–∑–º—ñ—Ä—É $b$
   - –ü—Ä–∏–∑–Ω–∞—á–∏—Ç–∏ —Ç–æ—á–∫–∏ batch –¥–æ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
   - –û–Ω–æ–≤–∏—Ç–∏ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ (–∑ –≤—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö)
3. –î–æ –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ

### –ö–æ–¥

```python
from sklearn.cluster import MiniBatchKMeans

# –î–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
mb_kmeans = MiniBatchKMeans(
    n_clusters=4,
    batch_size=100,      # –†–æ–∑–º—ñ—Ä mini-batch
    max_iter=100,
    random_state=42
)

mb_kmeans.fit(X)
labels = mb_kmeans.labels_

print(f"Mini-Batch K-Means completed in {mb_kmeans.n_iter_} iterations")
```

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | K-Means | Mini-Batch K-Means |
|----------------|---------|---------------------|
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **–¢–æ—á–Ω—ñ—Å—Ç—å** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **–ü–∞–º'—è—Ç—å** | –ë—ñ–ª—å—à–µ | –ú–µ–Ω—à–µ |
| **–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è** | < 100K —Ç–æ—á–æ–∫ | > 100K —Ç–æ—á–æ–∫ |

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Mini-Batch:**
- ‚úÖ –î–∞–Ω—ñ –Ω–µ –≤–º—ñ—â—É—é—Ç—å—Å—è –≤ –ø–∞–º'—è—Ç—å
- ‚úÖ > 100,000 —Ç–æ—á–æ–∫
- ‚úÖ –ü–æ—Ç—Ä—ñ–±–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å > —Ç–æ—á–Ω—ñ—Å—Ç—å

---

## Preprocessing –¥–ª—è K-Means

### 1. Scaling (–ö–†–ò–¢–ò–ß–ù–û! ‚ö†Ô∏è)

**–ü—Ä–æ–±–ª–µ–º–∞:** K-Means –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Euclidean distance ‚Üí —á—É—Ç–ª–∏–≤–∏–π –¥–æ –º–∞—Å—à—Ç–∞–±—É.

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–í—ñ–∫: 20-80 (–¥—ñ–∞–ø–∞–∑–æ–Ω: 60)
–î–æ—Ö—ñ–¥: 20,000-150,000 (–¥—ñ–∞–ø–∞–∑–æ–Ω: 130,000)

–ë–µ–∑ scaling: –¥–æ—Ö—ñ–¥ –¥–æ–º—ñ–Ω—É—î!
```

**–†—ñ—à–µ–Ω–Ω—è: StandardScaler**

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=4)
kmeans.fit(X_scaled)  # ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π scaled –¥–∞–Ω—ñ
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏:**
- MinMaxScaler (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω –¥—ñ–∞–ø–∞–∑–æ–Ω [0, 1])
- RobustScaler (–¥–ª—è –¥–∞–Ω–∏—Ö –∑ outliers)

### 2. Feature Selection

**–í–∏–¥–∞–ª–∏—Ç–∏ –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω—ñ/–∑–∞—à—É–º–ª–µ–Ω—ñ –æ–∑–Ω–∞–∫–∏:**

```python
from sklearn.feature_selection import VarianceThreshold

# –í–∏–¥–∞–ª–∏—Ç–∏ –æ–∑–Ω–∞–∫–∏ –∑ –Ω–∏–∑—å–∫–æ—é variance
selector = VarianceThreshold(threshold=0.1)
X_selected = selector.fit_transform(X)
```

### 3. Dimensionality Reduction

**PCA –ø–µ—Ä–µ–¥ K-Means –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –∞–±–æ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è:**

```python
from sklearn.decomposition import PCA

# –ó–º–µ–Ω—à–∏—Ç–∏ –¥–æ 2D –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

kmeans = KMeans(n_clusters=4)
kmeans.fit(X_pca)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels_, cmap='viridis')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()
```

### 4. Outlier Removal

**–í–∏–∫–∏–¥–∏ –º–æ–∂—É—Ç—å –∑—ñ–ø—Å—É–≤–∞—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—é:**

```python
from sklearn.ensemble import IsolationForest

# –í–∏–¥–∞–ª–∏—Ç–∏ outliers
iso = IsolationForest(contamination=0.1, random_state=42)
outliers = iso.fit_predict(X_scaled)

X_clean = X_scaled[outliers == 1]  # –¢—ñ–ª—å–∫–∏ normal points
```

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ü–µ—Ä–µ–≤–∞–≥–∏ ‚úì

| –ü–µ—Ä–µ–≤–∞–≥–∞ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|----------|-----------|
| **–ü—Ä–æ—Å—Ç–æ—Ç–∞** | –õ–µ–≥–∫–æ –∑—Ä–æ–∑—É–º—ñ—Ç–∏ —Ç–∞ —Ä–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ |
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | –î—É–∂–µ —à–≤–∏–¥–∫–∏–π, $O(nKdi)$ |
| **–ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ—Å—Ç—å** | –ü—Ä–∞—Ü—é—î –∑ –≤–µ–ª–∏–∫–∏–º–∏ –¥–∞–Ω–∏–º–∏ (Mini-Batch) |
| **–ì–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å** | –ó–∞–≤–∂–¥–∏ –∑–±—ñ–≥–∞—î—Ç—å—Å—è (–¥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –º—ñ–Ω—ñ–º—É–º—É) |
| **–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ—Å—Ç—å** | –ü—Ä–∞—Ü—é—î –≤ —Ä—ñ–∑–Ω–∏—Ö –∑–∞–¥–∞—á–∞—Ö |
| **–õ–µ–≥–∫–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è** | –¶–µ–Ω—Ç—Ä–æ—ó–¥–∏ –º–∞—é—Ç—å —á—ñ—Ç–∫–∏–π –∑–º—ñ—Å—Ç |

### –ù–µ–¥–æ–ª—ñ–∫–∏ ‚úó

| –ù–µ–¥–æ–ª—ñ–∫ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|---------|-----------|
| **–ü–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞—Ç–∏ $K$** | –ù–µ –∑–Ω–∞—î —Å–∫—ñ–ª—å–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó** | –ú–æ–∂–µ –∑–∞—Å—Ç—Ä—è–≥—Ç–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º—ñ–Ω—ñ–º—É–º–∞—Ö |
| **–°—Ñ–µ—Ä–∏—á–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏** | –ü–µ—Ä–µ–¥–±–∞—á–∞—î –∫—Ä—É–≥–ª—É —Ñ–æ—Ä–º—É |
| **–û–¥–Ω–∞–∫–æ–≤–∏–π —Ä–æ–∑–º—ñ—Ä** | –ü–æ–≥–∞–Ω–æ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Ä–æ–∑–º—ñ—Ä–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ outliers** | –í–∏–∫–∏–¥–∏ –∑–º—ñ—â—É—é—Ç—å —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏ |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –º–∞—Å—à—Ç–∞–±—É** | –ü–æ—Ç—Ä—ñ–±–µ–Ω scaling |
| **–¢—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –¥–∞–Ω—ñ** | –ù–µ –ø—Ä–∞—Ü—é—î –∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏–º–∏ |

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó

| –ú–µ—Ç–æ–¥ | –ü–æ—Ç—Ä—ñ–±–Ω–æ $K$? | –§–æ—Ä–º–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ | Outliers | –®–≤–∏–¥–∫—ñ—Å—Ç—å | –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è |
|-------|---------------|-----------------|----------|-----------|--------------|
| **K-Means** | ‚úÖ –¢–∞–∫ | –°—Ñ–µ—Ä–∏—á–Ω—ñ | ‚ùå –ß—É—Ç–ª–∏–≤–∏–π | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ó–∞–≥–∞–ª—å–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è |
| **Hierarchical** | ‚ùå –ù—ñ | –ë—É–¥—å-—è–∫–∞ | ‚ö†Ô∏è –ß—É—Ç–ª–∏–≤–∏–π | ‚≠ê‚≠ê | –Ü—î—Ä–∞—Ä—Ö—ñ—è, –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–∏ |
| **DBSCAN** | ‚ùå –ù—ñ | –ë—É–¥—å-—è–∫–∞ | ‚úÖ –†–æ–±–∞—Å—Ç–Ω–∏–π | ‚≠ê‚≠ê‚≠ê | –°–∫–ª–∞–¥–Ω–∞ —Ñ–æ—Ä–º–∞, outliers |
| **GMM** | ‚úÖ –¢–∞–∫ | –ï–ª—ñ–ø—Ç–∏—á–Ω—ñ | ‚ö†Ô∏è –°–µ—Ä–µ–¥–Ω—å–æ | ‚≠ê‚≠ê‚≠ê | Soft clustering, –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ |

---

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ K-Means

### –Ü–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å ‚úì

- **–ó–Ω–∞—î–º–æ –ø—Ä–∏–±–ª–∏–∑–Ω–æ $K$** ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≥—Ä—É–ø –∑—Ä–æ–∑—É–º—ñ–ª–∞
- **–ö–ª–∞—Å—Ç–µ—Ä–∏ —Å—Ñ–µ—Ä–∏—á–Ω—ñ** ‚Äî –ø—Ä–∏–±–ª–∏–∑–Ω–æ –∫—Ä—É–≥–ª—ñ
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** ‚Äî —à–≤–∏–¥–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞
- **–ß–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏** ‚Äî –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω—ñ –∑–º—ñ–Ω–Ω—ñ
- –ö–ª–∞—Å—Ç–µ—Ä–∏ **–ø—Ä–∏–±–ª–∏–∑–Ω–æ –æ–¥–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É**
- **–ü–µ—Ä—à–∏–º –∫—Ä–æ–∫–æ–º** ‚Äî quick baseline

### –ö—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à–µ ‚úó

- **–ù–µ –∑–Ω–∞—î–º–æ $K$** ‚Üí Hierarchical, DBSCAN
- **–°–∫–ª–∞–¥–Ω–∞ —Ñ–æ—Ä–º–∞** –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí DBSCAN, GMM
- **–†—ñ–∑–Ω—ñ —Ä–æ–∑–º—ñ—Ä–∏** –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí DBSCAN
- **–ë–∞–≥–∞—Ç–æ outliers** ‚Üí DBSCAN
- **–ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ** ‚Üí K-Modes
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ **—ñ—î—Ä–∞—Ä—Ö—ñ—è** ‚Üí Hierarchical Clustering
- –ü–æ—Ç—Ä—ñ–±–Ω—ñ **–π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ** ‚Üí Gaussian Mixture Models

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ó–ê–í–ñ–î–ò scaling!

```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
kmeans.fit(X)

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
kmeans.fit(X_scaled)
```

### 2. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Elbow + Silhouette

```python
# –ù–µ –ø–æ–∫–ª–∞–¥–∞–π—Å—è —Ç—ñ–ª—å–∫–∏ –Ω–∞ –æ–¥–∏–Ω –º–µ—Ç–æ–¥
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X_scaled)
    print(f"K={k}: Inertia={kmeans.inertia_:.0f}, "
          f"Silhouette={silhouette_score(X_scaled, kmeans.labels_):.3f}")
```

### 3. –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

```python
# –ó–ê–í–ñ–î–ò –≤—ñ–∑—É–∞–ª—ñ–∑—É–π (–Ω–∞–≤—ñ—Ç—å —è–∫—â–æ > 2D, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π PCA)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], 
            c='red', marker='X', s=200)
plt.show()
```

### 4. –ü–µ—Ä–µ–≤—ñ—Ä—è–π —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å

```python
# –ó–∞–ø—É—Å—Ç–∏ –∫—ñ–ª—å–∫–∞ —Ä–∞–∑—ñ–≤ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
labels_list = []
for i in range(10):
    kmeans = KMeans(n_clusters=4, random_state=i)
    labels_list.append(kmeans.fit_predict(X_scaled))

# –Ø–∫—â–æ labels —Å–∏–ª—å–Ω–æ –≤—ñ–¥—Ä—ñ–∑–Ω—è—é—Ç—å—Å—è ‚Üí –ø–æ–≥–∞–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è
```

### 5. Domain knowledge

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–π –∫–ª–∞—Å—Ç–µ—Ä–∏ –∑ —Ç–æ—á–∫–∏ –∑–æ—Ä—É –±—ñ–∑–Ω–µ—Å—É:**

```python
# –ü—Ä–æ—Ñ—ñ–ª—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
for cluster in range(K):
    print(f"\nCluster {cluster}:")
    print(df[df['Cluster'] == cluster][features].describe())
    # –ß–ò –ú–ê–Ñ –°–ï–ù–° —Ü—è –≥—Ä—É–ø–∞?
```

### 6. n_init=10 –º—ñ–Ω—ñ–º—É–º

```python
# –ó–∞–≤–∂–¥–∏ –∫—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤ –¥–ª—è –Ω–∞–¥—ñ–π–Ω–æ—Å—Ç—ñ
kmeans = KMeans(n_clusters=4, n_init=10)  # –ú—ñ–Ω—ñ–º—É–º
# –ê–±–æ –±—ñ–ª—å—à–µ –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –∑–∞–¥–∞—á
kmeans = KMeans(n_clusters=4, n_init=50)
```

### 7. Mini-Batch –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö

```python
# –Ø–∫—â–æ > 100K —Ç–æ—á–æ–∫
if len(X) > 100000:
    from sklearn.cluster import MiniBatchKMeans
    kmeans = MiniBatchKMeans(n_clusters=4, batch_size=1000)
```

### 8. –í–∏–¥–∞–ª–∏ outliers —Å–ø–æ—á–∞—Ç–∫—É

```python
# Outliers –∑—ñ–ø—Å—É—é—Ç—å —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏
from sklearn.ensemble import IsolationForest

iso = IsolationForest(contamination=0.05)
mask = iso.fit_predict(X_scaled) == 1
X_clean = X_scaled[mask]
```

### 9. –ó–±–µ—Ä—ñ–≥–∞–π scaler!

```python
import joblib

# –ó–±–µ—Ä–µ–≥—Ç–∏ scaler —Ç–∞ model —Ä–∞–∑–æ–º
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(kmeans, 'kmeans.pkl')

# –î–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
scaler = joblib.load('scaler.pkl')
kmeans = joblib.load('kmeans.pkl')

X_new_scaled = scaler.transform(X_new)
labels_new = kmeans.predict(X_new_scaled)
```

### 10. –ù–∞–∑–≤–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤

```python
# –î–∞–π –∫–ª–∞—Å—Ç–µ—Ä–∞–º –∑—Ä–æ–∑—É–º—ñ–ª—ñ –Ω–∞–∑–≤–∏
cluster_names = {
    0: "Budget Shoppers",
    1: "High-Value Customers",
    2: "Occasional Buyers",
    3: "New Users"
}

df['Segment'] = df['Cluster'].map(cluster_names)
```

---

## –†–µ–∞–ª—å–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

### 1. Customer Segmentation (–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç—ñ–≤)

**–ó–∞–¥–∞—á–∞:** –†–æ–∑–¥—ñ–ª–∏—Ç–∏ –∫–ª—ñ—î–Ω—Ç—ñ–≤ –Ω–∞ –≥—Ä—É–ø–∏ –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–æ–≤–∞–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É.

**–û–∑–Ω–∞–∫–∏:**
- RFM (Recency, Frequency, Monetary)
- –î–µ–º–æ–≥—Ä–∞—Ñ—ñ—è (–≤—ñ–∫, —Å—Ç–∞—Ç—å, –ª–æ–∫–∞—Ü—ñ—è)
- –ü–æ–≤–µ–¥—ñ–Ω–∫–∞ (–∫–ª—ñ–∫-—Ä–µ–π—Ç, —á–∞—Å –Ω–∞ —Å–∞–π—Ç—ñ)

**–ü—Ä–∏–∫–ª–∞–¥ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤:**
- VIP –∫–ª—ñ—î–Ω—Ç–∏ (–≤–∏—Å–æ–∫—ñ –ø–æ–∫—É–ø–∫–∏)
- –ê–∫—Ç–∏–≤–Ω—ñ (—á–∞—Å—Ç—ñ –≤—ñ–∑–∏—Ç–∏)
- –ù–µ–∞–∫—Ç–∏–≤–Ω—ñ (—Ä—ñ–¥–∫–æ –∫—É–ø—É—é—Ç—å)
- –ù–æ–≤—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ

### 2. Image Compression (–°—Ç–∏—Å–Ω–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å)

**–ó–∞–¥–∞—á–∞:** –ó–º–µ–Ω—à–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª—å–æ—Ä—ñ–≤ —É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ.

**–ü—ñ–¥—Ö—ñ–¥:**
- –ö–æ–∂–µ–Ω –ø—ñ–∫—Å–µ–ª—å = —Ç–æ—á–∫–∞ –≤ RGB –ø—Ä–æ—Å—Ç–æ—Ä—ñ
- K-Means –≥—Ä—É–ø—É—î —Å—Ö–æ–∂—ñ –∫–æ–ª—å–æ—Ä–∏
- –ó–∞–º—ñ–Ω–∏—Ç–∏ –∫–æ–ª—å–æ—Ä–∏ –Ω–∞ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ $K$ –∫–æ–ª—å–æ—Ä—ñ–≤ –∑–∞–º—ñ—Å—Ç—å –º—ñ–ª—å–π–æ–Ω—ñ–≤.

### 3. Document Clustering (–ì—Ä—É–ø—É–≤–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤)

**–ó–∞–¥–∞—á–∞:** –ó–≥—Ä—É–ø—É–≤–∞—Ç–∏ —Å—Ö–æ–∂—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏/—Å—Ç–∞—Ç—Ç—ñ.

**–ü—ñ–¥—Ö—ñ–¥:**
- TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É
- K-Means –Ω–∞ vectors
- –ö–æ–∂–µ–Ω –∫–ª–∞—Å—Ç–µ—Ä = —Ç–µ–º–∞

### 4. Anomaly Detection (–í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π)

**–ó–∞–¥–∞—á–∞:** –ó–Ω–∞–π—Ç–∏ –Ω–µ–∑–≤–∏—á–∞–π–Ω—ñ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó/–ø–æ–≤–µ–¥—ñ–Ω–∫—É.

**–ü—ñ–¥—Ö—ñ–¥:**
- –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ
- –¢–æ—á–∫–∏ –¥–∞–ª–µ–∫–æ –≤—ñ–¥ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤ = –∞–Ω–æ–º–∞–ª—ñ—ó
- Threshold –Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å

### 5. Recommendation Systems

**–ó–∞–¥–∞—á–∞:** –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ö–æ–∂–æ—Å—Ç—ñ.

**–ü—ñ–¥—Ö—ñ–¥:**
- –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤/—Ç–æ–≤–∞—Ä–∏
- –†–µ–∫–æ–º–µ–Ω–¥—É–≤–∞—Ç–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ñ items —É –∫–ª–∞—Å—Ç–µ—Ä—ñ

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –ù–µ —Ä–æ–±–∏—Ç–∏ scaling

```python
# ‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê
kmeans = KMeans(n_clusters=3)
kmeans.fit(df[['Age', 'Income']])  # Age: 0-100, Income: 0-150000

# Income –¥–æ–º—ñ–Ω—É—î —á–µ—Ä–µ–∑ –≤–µ–ª–∏–∫–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω!
```

### 2. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö

```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
df['Gender'] = df['Gender'].map({'M': 0, 'F': 1})  # –ù–µ –º–∞—î —Å–µ–Ω—Å—É –¥–ª—è K-Means
kmeans.fit(df)

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π One-Hot Encoding + K-Modes –∞–±–æ —ñ–Ω—à–∏–π –º–µ—Ç–æ–¥
```

### 3. –ù–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—Ç–∏ $K$

```python
# ‚ùå –ü—Ä–æ—Å—Ç–æ –≤–∏–±—Ä–∞—Ç–∏ K=3 –±–µ–∑ –∞–Ω–∞–ª—ñ–∑—É
kmeans = KMeans(n_clusters=3)

# ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Elbow/Silhouette
```

### 4. –Ü–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ outliers

```python
# Outliers —Å–∏–ª—å–Ω–æ –∑–º—ñ—â—É—é—Ç—å —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∏!
# ‚úÖ –í–∏–¥–∞–ª–∏ —ó—Ö —Å–ø–æ—á–∞—Ç–∫—É
```

### 5. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –±–µ–∑ domain knowledge

```python
# ‚ùå "–ö–ª–∞—Å—Ç–µ—Ä 0 = –≥—Ä—É–ø–∞ 1, –∫–ª–∞—Å—Ç–µ—Ä 1 = –≥—Ä—É–ø–∞ 2"
# ‚úÖ –ü–æ–¥–∏–≤–∏—Å—å –Ω–∞ –ø—Ä–æ—Ñ—ñ–ª—ñ —Ç–∞ –¥–∞–π –∑—Ä–æ–∑—É–º—ñ–ª—ñ –Ω–∞–∑–≤–∏
```

### 6. –û–¥–∏–Ω –∑–∞–ø—É—Å–∫ (n_init=1)

```python
# ‚ùå –†–ò–ó–ò–ö –õ–û–ö–ê–õ–¨–ù–û–ì–û –ú–Ü–ù–Ü–ú–£–ú–£
kmeans = KMeans(n_clusters=4, n_init=1)

# ‚úÖ –ö—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤
kmeans = KMeans(n_clusters=4, n_init=10)
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[02_Hierarchical_Clustering]] ‚Äî –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –º–µ—Ç–æ–¥
- [[03_DBSCAN]] ‚Äî –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö —Ñ–æ—Ä–º
- [[04_Gaussian_Mixture_Models]] ‚Äî probabilistic clustering
- [[05_Clustering_Evaluation]] ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏
- [[PCA]] ‚Äî dimensionality reduction –ø–µ—Ä–µ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—î—é

## –†–µ—Å—É—Ä—Å–∏

- [Scikit-learn: K-Means](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [Original Paper: Lloyd (1982)](https://cs.nyu.edu/~roweis/csc2515-2006/readings/lloyd57.pdf)
- [StatQuest: K-Means](https://www.youtube.com/watch?v=4b5d3muPQmA)
- [K-Means++: Arthur & Vassilvitskii (2007)](http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> K-Means ‚Äî —Ü–µ —ñ—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó, —è–∫–∏–π —Ä–æ–∑–¥—ñ–ª—è—î –¥–∞–Ω—ñ –Ω–∞ $K$ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ —à–ª—è—Ö–æ–º –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó –≤—ñ–¥—Å—Ç–∞–Ω—ñ –≤—ñ–¥ —Ç–æ—á–æ–∫ –¥–æ —Ü–µ–Ω—Ç—Ä–æ—ó–¥—ñ–≤.

**–û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–∏–Ω—Ü–∏–ø–∏:**
- **–Ü—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å:** assignment ‚Üí update ‚Üí repeat
- **–ú—ñ–Ω—ñ–º—ñ–∑—É—î WCSS** (Within-Cluster Sum of Squares)
- **–ü–æ—Ç—Ä–µ–±—É—î $K$** ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å
- **K-Means++** —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è –∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

**–§–æ—Ä–º—É–ª–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞:**
$$\mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i$$

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –°—Ñ–µ—Ä–∏—á–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏ + –∑–Ω–∞—î–º–æ $K$ + —à–≤–∏–¥–∫—ñ—Å—Ç—å = K-Means ‚úì
- –°–∫–ª–∞–¥–Ω–∞ —Ñ–æ—Ä–º–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí DBSCAN ‚úì
- –ù–µ –∑–Ω–∞—î–º–æ $K$ ‚Üí Hierarchical Clustering ‚úì

**–ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–µ:**
- –ó–ê–í–ñ–î–ò —Ä–æ–±–∏—Ç–∏ scaling (StandardScaler)
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Elbow + Silhouette –¥–ª—è –≤–∏–±–æ—Ä—É $K$
- n_init=10 –º—ñ–Ω—ñ–º—É–º –¥–ª—è –Ω–∞–¥—ñ–π–Ω–æ—Å—Ç—ñ
- –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
- Domain knowledge > –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞

---

#ml #unsupervised-learning #clustering #k-means #centroid-based #customer-segmentation
