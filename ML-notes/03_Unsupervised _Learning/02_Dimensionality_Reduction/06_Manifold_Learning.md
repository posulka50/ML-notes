# Manifold Learning (–ù–∞–≤—á–∞–Ω–Ω—è –ú–Ω–æ–≥–æ–≤–∏–¥—ñ–≤)

## –©–æ —Ü–µ?

**Manifold Learning** ‚Äî —Ü–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ **–Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö** –º–µ—Ç–æ–¥—ñ–≤ dimensionality reduction, —è–∫—ñ –ø—Ä–∏–ø—É—Å–∫–∞—é—Ç—å —â–æ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ –¥–∞–Ω—ñ –ª–µ–∂–∞—Ç—å –Ω–∞ –∞–±–æ –±–ª–∏–∑—å–∫–æ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–≥–æ **manifold** (–º–Ω–æ–≥–æ–≤–∏–¥—É) –≤–±—É–¥–æ–≤–∞–Ω–æ–≥–æ —É –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** "—Ä–æ–∑–≥–æ—Ä–Ω—É—Ç–∏" —Å–∫–ª–∞–¥–Ω—É –Ω–µ–ª—ñ–Ω—ñ–π–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –≤–∞–∂–ª–∏–≤—ñ –≥–µ–æ–º–µ—Ç—Ä–∏—á–Ω—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ.

## –©–æ —Ç–∞–∫–µ Manifold?

**Manifold (–º–Ω–æ–≥–æ–≤–∏–¥)** ‚Äî —Ü–µ –ø—Ä–æ—Å—Ç—ñ—Ä, —è–∫–∏–π –ª–æ–∫–∞–ª—å–Ω–æ –≤–∏–≥–ª—è–¥–∞—î —è–∫ Euclidean, –∞–ª–µ –≥–ª–æ–±–∞–ª—å–Ω–æ –º–æ–∂–µ –±—É—Ç–∏ –∑–≥–æ—Ä–Ω—É—Ç–∏–º.

### –ü—Ä–∏–∫–ª–∞–¥–∏

**1D manifold –≤ 3D (–∫—Ä–∏–≤–∞):**
```
    z
    |  /\
    | /  \
    |/    \___
    |________ y
   /
  /
 x

–õ–æ–∫–∞–ª—å–Ω–æ: –ø—Ä—è–º–∞ –ª—ñ–Ω—ñ—è
–ì–ª–æ–±–∞–ª—å–Ω–æ: —Å–∫–ª–∞–¥–Ω–∞ –∫—Ä–∏–≤–∞
```

**2D manifold –≤ 3D (–ø–æ–≤–µ—Ä—Ö–Ω—è):**
```
Swiss Roll:
    z
    |  ‚ï±‚ï≤‚ï±‚ï≤
    | ‚ï±  X  ‚ï≤
    |‚ï±   ‚ïë   ‚ï≤
    |    ‚ïë____‚ï≤_ y
   /
  x

–ó–≥–æ—Ä–Ω—É—Ç–∏–π –∞—Ä–∫—É—à –ø–∞–ø–µ—Ä—É
```

### –Ü–Ω—Ç—É—ó—Ü—ñ—è –≤ ML

**–ü—Ä–∏–∫–ª–∞–¥:** –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ–±–ª–∏—á
- **–í–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä:** 1000√ó1000 pixels = 1,000,000D
- **–§–∞–∫—Ç–∏—á–Ω–∏–π manifold:** ~10-50D (–ø–æ–∑–∏, –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è, –µ–º–æ—Ü—ñ—ó)

–ë—ñ–ª—å—à—ñ—Å—Ç—å –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ –º–∞—é—Ç—å –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É!

---

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–Ω—ñ?

- üåÄ **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏** ‚Äî —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è —Å–∫–ª–∞–¥–Ω–∏—Ö manifolds
- üìä **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** ‚Äî 2D/3D –ø—Ä–æ–µ–∫—Ü—ñ—ó —Å–∫–ª–∞–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
- üéØ **–õ–æ–∫–∞–ª—å–Ω–∞ –≥–µ–æ–º–µ—Ç—Ä—ñ—è** ‚Äî –∑–±–µ—Ä—ñ–≥–∞—î —Å—É—Å—ñ–¥—Å—Ç–≤–æ
- üó∫Ô∏è **Geodesic distances** ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—ñ –≤–∑–¥–æ–≤–∂ manifold
- üß¨ **Exploratory analysis** ‚Äî —Ä–æ–∑—É–º—ñ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
- üé® **–†—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏** ‚Äî —Ä—ñ–∑–Ω—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Äî —Å–∫–ª–∞–¥–Ω—ñ –∑–≥–æ—Ä—Ç–∫–∏, –∫—Ä–∏–≤—ñ –ø–æ–≤–µ—Ä—Ö–Ω—ñ
- **–î–∞–Ω—ñ –ª–µ–∂–∞—Ç—å –Ω–∞ manifold** ‚Äî low intrinsic dimensionality
- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** ‚Äî —Ä–æ–∑—É–º—ñ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
- **Exploratory analysis** ‚Äî –ø–µ—Ä—à–∏–π –ø–æ–≥–ª—è–¥ –Ω–∞ –¥–∞–Ω—ñ
- **–°–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ** (100-10,000 —Ç–æ—á–æ–∫)

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Üí PCA
- **–î—É–∂–µ –≤–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 50,000) ‚Üí UMAP
- **Downstream ML** ‚Üí UMAP, PCA (—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à—ñ)
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å** –∫—Ä–∏—Ç–∏—á–Ω–∞ ‚Üí PCA
- **–ù–æ–≤—ñ –¥–∞–Ω—ñ** –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—É–≤–∞—Ç–∏ ‚Üí PCA, UMAP

---

## –ú–µ—Ç–æ–¥–∏ Manifold Learning

### –û–≥–ª—è–¥

| –ú–µ—Ç–æ–¥ | –©–æ –∑–±–µ—Ä—ñ–≥–∞—î | –®–≤–∏–¥–∫—ñ—Å—Ç—å | –î–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó | Transform –Ω–æ–≤–∏—Ö |
|-------|-------------|-----------|------------------|-----------------|
| **MDS** | –ì–ª–æ–±–∞–ª—å–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ | ‚≠ê‚≠ê | ‚úÖ | ‚ùå |
| **Isomap** | Geodesic –≤—ñ–¥—Å—Ç–∞–Ω—ñ | ‚≠ê‚≠ê | ‚úÖ | ‚ö†Ô∏è |
| **LLE** | –õ–æ–∫–∞–ª—å–Ω—É –≥–µ–æ–º–µ—Ç—Ä—ñ—é | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚ùå |
| **Spectral Embedding** | Graph structure | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚ùå |
| **t-SNE** | –õ–æ–∫–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É | ‚≠ê | ‚úÖ | ‚ùå |
| **UMAP** | –õ–æ–∫–∞–ª—å–Ω—É + –≥–ª–æ–±–∞–ª—å–Ω—É | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ |

---

## 1. MDS (Multidimensional Scaling)

### –©–æ —Ü–µ?

**MDS** ‚Äî –∑–Ω–∞—Ö–æ–¥–∏—Ç—å low-dimensional –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è, —â–æ –∑–±–µ—Ä—ñ–≥–∞—î **–ø–æ–ø–∞—Ä–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ** –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏.

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

**–ú–µ—Ç–∞:** –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ stress function:

$$\text{Stress} = \sqrt{\sum_{i<j} (d_{ij} - \hat{d}_{ij})^2}$$

–¥–µ:
- $d_{ij}$ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏ $i$ —Ç–∞ $j$ —É –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
- $\hat{d}_{ij}$ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—å —É –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ

### –ö–æ–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import MDS
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
digits = load_digits()
X = digits.data
y = digits.target

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# MDS
mds = MDS(
    n_components=2,
    metric=True,        # Metric MDS (–∑–±–µ—Ä—ñ–≥–∞—î –≤—ñ–¥—Å—Ç–∞–Ω—ñ)
    n_init=4,           # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ–π
    max_iter=300,
    random_state=42
)

X_mds = mds.fit_transform(X_scaled)

print(f"Original shape: {X.shape}")   # (1797, 64)
print(f"MDS shape: {X_mds.shape}")    # (1797, 2)
print(f"Stress: {mds.stress_:.2f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_mds[:, 0], X_mds[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
plt.colorbar(scatter, label='Digit')
plt.title('MDS Projection', fontsize=14, fontweight='bold')
plt.xlabel('MDS 1')
plt.ylabel('MDS 2')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### –í–∞—Ä—ñ–∞—Ü—ñ—ó

**Metric MDS:**
- –ó–±–µ—Ä—ñ–≥–∞—î –∞–±—Å–æ–ª—é—Ç–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
- –ü—Ä–∞—Ü—é—î –∑ Euclidean distances

**Non-metric MDS:**
- –ó–±–µ—Ä—ñ–≥–∞—î –ø–æ—Ä—è–¥–æ–∫ –≤—ñ–¥—Å—Ç–∞–Ω–µ–π (rankings)
- –ë—ñ–ª—å—à –≥–Ω—É—á–∫–∏–π

```python
# Non-metric MDS
nmds = MDS(n_components=2, metric=False, random_state=42)
X_nmds = nmds.fit_transform(X_scaled)
```

### –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ö–æ–∂–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö
- –ü—Å–∏—Ö–æ–ª–æ–≥—ñ—á–Ω—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è (similarity judgments)
- –ì–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ –¥–∞–Ω—ñ

---

## 2. Isomap (Isometric Mapping)

### –©–æ —Ü–µ?

**Isomap** ‚Äî —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è MDS, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î **geodesic distances** (–Ω–∞–π–∫–æ—Ä–æ—Ç—à—ñ —à–ª—è—Ö–∏ –≤–∑–¥–æ–≤–∂ manifold) –∑–∞–º—ñ—Å—Ç—å Euclidean.

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**–ü—Ä–æ–±–ª–µ–º–∞ –∑ Euclidean distance:**

```
Swiss Roll:

–¢–æ—á–∫–∏ A —Ç–∞ B:
- Euclidean distance: –∫–æ—Ä–æ—Ç–∫–∞ (–Ω–∞—Å–∫—Ä—ñ–∑—å)
- Geodesic distance: –¥–æ–≤–≥–∞ (–≤–∑–¥–æ–≤–∂ –ø–æ–≤–µ—Ä—Ö–Ω—ñ)

    B
   /|
  / |  ‚Üê Euclidean (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ)
 /  |
A___| ‚Üê Geodesic (–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –≤–∑–¥–æ–≤–∂ –ø–æ–≤–µ—Ä—Ö–Ω—ñ)
```

### –ê–ª–≥–æ—Ä–∏—Ç–º

1. **–ü–æ–±—É–¥—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ k-nearest neighbors**
2. **–û–±—á–∏—Å–ª–∏—Ç–∏ shortest paths** –º—ñ–∂ —É—Å—ñ–º–∞ —Ç–æ—á–∫–∞–º–∏ (Floyd-Warshall –∞–±–æ Dijkstra)
3. **MDS –Ω–∞ geodesic distances**

### –ö–æ–¥

```python
from sklearn.manifold import Isomap

# Isomap
isomap = Isomap(
    n_neighbors=5,      # k –¥–ª—è kNN graph
    n_components=2,     # –í–∏—Ö—ñ–¥–Ω–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å
    metric='minkowski',
    p=2                 # Euclidean distance
)

X_isomap = isomap.fit_transform(X_scaled)

print(f"Isomap shape: {X_isomap.shape}")
print(f"Reconstruction error: {isomap.reconstruction_error():.4f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_isomap[:, 0], X_isomap[:, 1],
                     c=y, cmap='tab10', s=20, alpha=0.6)
plt.colorbar(scatter, label='Digit')
plt.title('Isomap Projection', fontsize=14, fontweight='bold')
plt.xlabel('Isomap 1')
plt.ylabel('Isomap 2')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### –ü—Ä–∏–∫–ª–∞–¥: Swiss Roll

```python
from sklearn.datasets import make_swiss_roll

# –°—Ç–≤–æ—Ä–∏—Ç–∏ Swiss Roll
X_swiss, t = make_swiss_roll(n_samples=1500, noise=0.1, random_state=42)

# PCA (linear) - –ø–æ–≥–∞–Ω–æ
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_swiss)

# Isomap (nonlinear) - –¥–æ–±—Ä–µ
isomap = Isomap(n_neighbors=10, n_components=2)
X_isomap = isomap.fit_transform(X_swiss)

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# 3D Original
axes[0] = fig.add_subplot(131, projection='3d')
axes[0].scatter(X_swiss[:, 0], X_swiss[:, 1], X_swiss[:, 2],
               c=t, cmap='viridis', s=10)
axes[0].set_title('Original Swiss Roll (3D)', fontsize=13, fontweight='bold')

# PCA
axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=t, cmap='viridis', s=10)
axes[1].set_title('PCA (Linear) ‚ùå', fontsize=13, fontweight='bold')
axes[1].set_xlabel('PC1')
axes[1].set_ylabel('PC2')

# Isomap
axes[2].scatter(X_isomap[:, 0], X_isomap[:, 1], c=t, cmap='viridis', s=10)
axes[2].set_title('Isomap (Nonlinear) ‚úì', fontsize=13, fontweight='bold')
axes[2].set_xlabel('Isomap 1')
axes[2].set_ylabel('Isomap 2')

plt.tight_layout()
plt.show()

print("Isomap —É—Å–ø—ñ—à–Ω–æ '—Ä–æ–∑–≥–æ—Ä–Ω—É–≤' Swiss Roll!")
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

**‚úÖ –ü–µ—Ä–µ–≤–∞–≥–∏:**
- –ó–±–µ—Ä—ñ–≥–∞—î geodesic distances
- –î–æ–±—Ä–µ —Ä–æ–∑–≥–æ—Ä—Ç–∞—î manifolds
- –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–æ –æ–±“ë—Ä—É–Ω—Ç–æ–≤–∞–Ω–∏–π

**‚ùå –ù–µ–¥–æ–ª—ñ–∫–∏:**
- –ß—É—Ç–ª–∏–≤–∏–π –¥–æ n_neighbors
- –ü–æ–≤—ñ–ª—å–Ω–∏–π –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö (O(n¬≥))
- –ü–æ–≥–∞–Ω–æ –∑ "holes" —É manifold

---

## 3. LLE (Locally Linear Embedding)

### –©–æ —Ü–µ?

**LLE** ‚Äî –∑–±–µ—Ä—ñ–≥–∞—î **–ª–æ–∫–∞–ª—å–Ω—É –ª—ñ–Ω—ñ–π–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É**: –∫–æ–∂–Ω–∞ —Ç–æ—á–∫–∞ –≤–∏—Ä–∞–∂–∞—î—Ç—å—Å—è —è–∫ –ª—ñ–Ω—ñ–π–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è —Å—É—Å—ñ–¥—ñ–≤.

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**–Ü–¥–µ—è:**
1. –ö–æ–∂–Ω–∞ —Ç–æ—á–∫–∞ ‚âà weighted sum —Å—É—Å—ñ–¥—ñ–≤ (–ª–æ–∫–∞–ª—å–Ω–æ linear)
2. –ó–Ω–∞–π—Ç–∏ –≤–∞–≥–∏ –≤ high-dim
3. –ó–±–µ—Ä–µ–≥—Ç–∏ —Ç—ñ –∂ –≤–∞–≥–∏ –≤ low-dim

```
High-dimensional:
    x‚ÇÉ
    ‚Üó ‚Üë ‚Üñ
   /  |  \
  x‚ÇÅ  x  x‚ÇÇ
      ‚Üì
x ‚âà w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + w‚ÇÉx‚ÇÉ

Low-dimensional:
–ó–±–µ—Ä–µ–≥—Ç–∏ —Ü—ñ –≤–∞–≥–∏!
```

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

**–ö—Ä–æ–∫ 1:** –ó–Ω–∞–π—Ç–∏ –≤–∞–≥–∏ $w_{ij}$ —â–æ –º—ñ–Ω—ñ–º—ñ–∑—É—é—Ç—å:

$$\sum_i \left\| x_i - \sum_j w_{ij} x_j \right\|^2$$

–∑ —É–º–æ–≤–æ—é $\sum_j w_{ij} = 1$

**–ö—Ä–æ–∫ 2:** –ó–Ω–∞–π—Ç–∏ $y_i$ —â–æ –º—ñ–Ω—ñ–º—ñ–∑—É—é—Ç—å:

$$\sum_i \left\| y_i - \sum_j w_{ij} y_j \right\|^2$$

### –ö–æ–¥

```python
from sklearn.manifold import LocallyLinearEmbedding

# LLE
lle = LocallyLinearEmbedding(
    n_neighbors=10,
    n_components=2,
    method='standard',  # 'standard', 'modified', 'hessian', 'ltsa'
    random_state=42
)

X_lle = lle.fit_transform(X_scaled)

print(f"LLE shape: {X_lle.shape}")
print(f"Reconstruction error: {lle.reconstruction_error_:.4f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_lle[:, 0], X_lle[:, 1],
                     c=y, cmap='tab10', s=20, alpha=0.6)
plt.colorbar(scatter, label='Digit')
plt.title('LLE Projection', fontsize=14, fontweight='bold')
plt.xlabel('LLE 1')
plt.ylabel('LLE 2')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### –í–∞—Ä—ñ–∞—Ü—ñ—ó LLE

**Standard LLE:**
- –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –º–µ—Ç–æ–¥

**Modified LLE:**
- –ë—ñ–ª—å—à —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π
- –ö—Ä–∞—â–µ –¥–ª—è –º–∞–ª–∏—Ö n_neighbors

**Hessian LLE (HLLE):**
- –í—Ä–∞—Ö–æ–≤—É—î –ª–æ–∫–∞–ª—å–Ω—É –∫—Ä–∏–≤–∏–∑–Ω—É
- –ö—Ä–∞—â–µ –¥–ª—è –∫—Ä–∏–≤–æ–ª—ñ–Ω—ñ–π–Ω–∏—Ö manifolds

**LTSA (Local Tangent Space Alignment):**
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î tangent space approximation

```python
# Modified LLE
mlle = LocallyLinearEmbedding(
    n_neighbors=10,
    n_components=2,
    method='modified',
    random_state=42
)

X_mlle = mlle.fit_transform(X_scaled)
```

### –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

- Face recognition (eigenfaces)
- Spectroscopy data
- Image analysis

---

## 4. Spectral Embedding (Laplacian Eigenmaps)

### –©–æ —Ü–µ?

**Spectral Embedding** ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î **graph Laplacian** –¥–ª—è –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è embedding.

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

**1. –ü–æ–±—É–¥—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ —Å—Ö–æ–∂–æ—Å—Ç—ñ:**
$$W_{ij} = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right) \text{ —è–∫—â–æ } j \in \text{neighbors}(i)$$

**2. Graph Laplacian:**
$$L = D - W$$

–¥–µ $D$ ‚Äî diagonal degree matrix.

**3. –ó–Ω–∞–π—Ç–∏ –≤–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ $L$:**

Embedding = –≤–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ –∑ –Ω–∞–π–º–µ–Ω—à–∏–º–∏ –≤–ª–∞—Å–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏.

### –ö–æ–¥

```python
from sklearn.manifold import SpectralEmbedding

# Spectral Embedding
spectral = SpectralEmbedding(
    n_components=2,
    n_neighbors=10,
    affinity='nearest_neighbors',  # –∞–±–æ 'rbf'
    random_state=42
)

X_spectral = spectral.fit_transform(X_scaled)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_spectral[:, 0], X_spectral[:, 1],
                     c=y, cmap='tab10', s=20, alpha=0.6)
plt.colorbar(scatter, label='Digit')
plt.title('Spectral Embedding', fontsize=14, fontweight='bold')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

- Clustering (spectral clustering)
- Graph partitioning
- Semi-supervised learning

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö –º–µ—Ç–æ–¥—ñ–≤

### Swiss Roll Test

```python
from sklearn.datasets import make_swiss_roll
from sklearn.decomposition import PCA
from sklearn.manifold import (
    MDS, Isomap, LocallyLinearEmbedding, 
    SpectralEmbedding, TSNE
)
import umap

# –°—Ç–≤–æ—Ä–∏—Ç–∏ Swiss Roll
X_swiss, t = make_swiss_roll(n_samples=1500, noise=0.1, random_state=42)

# –í—Å—ñ –º–µ—Ç–æ–¥–∏
methods = {
    'PCA': PCA(n_components=2),
    'MDS': MDS(n_components=2, max_iter=100, n_init=1),
    'Isomap': Isomap(n_neighbors=10, n_components=2),
    'LLE': LocallyLinearEmbedding(n_neighbors=10, n_components=2),
    'Spectral': SpectralEmbedding(n_neighbors=10, n_components=2),
    't-SNE': TSNE(n_components=2, random_state=42),
    'UMAP': umap.UMAP(n_components=2, random_state=42)
}

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig = plt.figure(figsize=(18, 12))

# Original 3D
ax = fig.add_subplot(3, 3, 1, projection='3d')
ax.scatter(X_swiss[:, 0], X_swiss[:, 1], X_swiss[:, 2],
          c=t, cmap='viridis', s=10)
ax.set_title('Original Swiss Roll (3D)', fontsize=12, fontweight='bold')

# –í—Å—ñ –º–µ—Ç–æ–¥–∏
for idx, (name, method) in enumerate(methods.items(), start=2):
    print(f"Running {name}...")
    
    X_transformed = method.fit_transform(X_swiss)
    
    ax = fig.add_subplot(3, 3, idx)
    scatter = ax.scatter(X_transformed[:, 0], X_transformed[:, 1],
                        c=t, cmap='viridis', s=10, alpha=0.6)
    ax.set_title(name, fontsize=12, fontweight='bold')
    ax.set_xlabel('Component 1', fontsize=9)
    ax.set_ylabel('Component 2', fontsize=9)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\n=== Swiss Roll Results ===")
print("‚úÖ Good unrolling: Isomap, LLE, t-SNE, UMAP")
print("‚ùå Poor unrolling: PCA (linear)")
```

### S-Curve Test

```python
from sklearn.datasets import make_s_curve

# S-Curve
X_s, t_s = make_s_curve(n_samples=1500, noise=0.1, random_state=42)

# –ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ –¥–ª—è S-curve
# ... (–∞–Ω–∞–ª–æ–≥—ñ—á–Ω–∏–π –∫–æ–¥)
```

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

### Digits Dataset

```python
import time

# Digits dataset
digits = load_digits()
X = digits.data
y = digits.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –≤—Å—ñ –º–µ—Ç–æ–¥–∏
methods = {
    'PCA': PCA(n_components=2),
    'MDS': MDS(n_components=2, max_iter=100, n_init=1),
    'Isomap': Isomap(n_neighbors=10, n_components=2),
    'LLE': LocallyLinearEmbedding(n_neighbors=10, n_components=2),
    'Spectral': SpectralEmbedding(n_neighbors=10, n_components=2),
    't-SNE': TSNE(n_components=2, random_state=42),
    'UMAP': umap.UMAP(n_components=2, random_state=42)
}

results = {}

for name, method in methods.items():
    print(f"\nRunning {name}...")
    
    start = time.time()
    X_transformed = method.fit_transform(X_scaled)
    elapsed = time.time() - start
    
    results[name] = {
        'time': elapsed,
        'embedding': X_transformed
    }
    
    print(f"  Time: {elapsed:.2f}s")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—Å—ñ—Ö
fig, axes = plt.subplots(2, 4, figsize=(20, 10))
axes = axes.ravel()

for idx, (name, result) in enumerate(results.items()):
    axes[idx].scatter(
        result['embedding'][:, 0],
        result['embedding'][:, 1],
        c=y, cmap='tab10', s=10, alpha=0.6
    )
    axes[idx].set_title(
        f"{name}\nTime: {result['time']:.2f}s",
        fontsize=11, fontweight='bold'
    )
    axes[idx].grid(True, alpha=0.3)

# Hide last subplot
axes[-1].axis('off')

plt.tight_layout()
plt.show()

# –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
print("\n=== Performance Comparison ===")
print(f"{'Method':<15} {'Time (s)':<10}")
print("-" * 25)
for name, result in sorted(results.items(), key=lambda x: x[1]['time']):
    print(f"{name:<15} {result['time']:<10.2f}")
```

---

## –í–∏–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

### n_neighbors (–∫—Ä–∏—Ç–∏—á–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä!)

**–í–ø–ª–∏–≤:**

```python
# –ó–∞–Ω–∞–¥—Ç–æ –º–∞–ª–æ (3-5)
# ‚Üí –®—É–º–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
# ‚Üí –†–æ–∑—Ä–∏–≤–∏ –≤ manifold

# –û–ø—Ç–∏–º–∞–ª—å–Ω–æ (10-30)
# ‚Üí –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ
# ‚Üí –ì–ª–∞–¥–∫—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

# –ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ (50+)
# ‚Üí –í—Ç—Ä–∞—Ç–∞ –ª–æ–∫–∞–ª—å–Ω–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
# ‚Üí –ù–∞–±–ª–∏–∂–∞—î—Ç—å—Å—è –¥–æ –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –º–µ—Ç–æ–¥—ñ–≤
```

**–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç:**

```python
n_neighbors_values = [5, 10, 20, 50]

fig, axes = plt.subplots(2, 2, figsize=(14, 12))
axes = axes.ravel()

for idx, n_neighbors in enumerate(n_neighbors_values):
    isomap = Isomap(n_neighbors=n_neighbors, n_components=2)
    X_transformed = isomap.fit_transform(X_scaled)
    
    axes[idx].scatter(X_transformed[:, 0], X_transformed[:, 1],
                     c=y, cmap='tab10', s=15, alpha=0.6)
    axes[idx].set_title(f'n_neighbors = {n_neighbors}',
                       fontsize=12, fontweight='bold')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
- **–ú–∞–ª—ñ –¥–∞–Ω—ñ** (< 500): n_neighbors = 5-10
- **–°–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ** (500-5000): n_neighbors = 10-20
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 5000): n_neighbors = 20-50

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ó–∞–≥–∞–ª—å–Ω—ñ –ø–µ—Ä–µ–≤–∞–≥–∏ manifold methods ‚úì

- ‚úÖ –ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ transformations
- ‚úÖ –í–∏—è–≤–ª—è—é—Ç—å —Å–∫–ª–∞–¥–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
- ‚úÖ –î–æ–±—Ä–µ –¥–ª—è exploratory analysis
- ‚úÖ –†—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∑–∞–¥–∞—á

### –ó–∞–≥–∞–ª—å–Ω—ñ –Ω–µ–¥–æ–ª—ñ–∫–∏ ‚úó

- ‚ùå –ü–æ–≤—ñ–ª—å–Ω—ñ –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
- ‚ùå –ß—É—Ç–ª–∏–≤—ñ –¥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
- ‚ùå –ù–µ–º–∞—î .transform() –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (–∫—Ä—ñ–º Isomap —á–∞—Å—Ç–∫–æ–≤–æ)
- ‚ùå –õ–æ–∫–∞–ª—å–Ω—ñ –º—ñ–Ω—ñ–º—É–º–∏ (–¥–µ—è–∫—ñ –º–µ—Ç–æ–¥–∏)
- ‚ùå –í–∞–∂–∫–æ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –æ—Å—ñ

### –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è

| –ú–µ—Ç–æ–¥ | –®–≤–∏–¥–∫—ñ—Å—Ç—å | –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å | –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | –õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ |
|-------|-----------|--------------|---------------------|-------------------|
| **MDS** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Isomap** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **LLE** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Spectral** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **t-SNE** | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **UMAP** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## –ö–æ–ª–∏ —è–∫–∏–π –º–µ—Ç–æ–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏

### Decision Tree

```
–ß–∏ –¥–∞–Ω—ñ –ª—ñ–Ω—ñ–π–Ω—ñ?
‚îú‚îÄ –¢–∞–∫ ‚Üí PCA
‚îî‚îÄ –ù—ñ (–Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ)
   ‚îÇ
   –ß–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å?
   ‚îú‚îÄ –¢–∞–∫ ‚Üí UMAP
   ‚îî‚îÄ –ù—ñ
      ‚îÇ
      –©–æ –≤–∞–∂–ª–∏–≤—ñ—à–µ?
      ‚îú‚îÄ –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Üí Isomap –∞–±–æ MDS
      ‚îú‚îÄ –õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Üí LLE –∞–±–æ Spectral
      ‚îú‚îÄ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí t-SNE –∞–±–æ UMAP
      ‚îî‚îÄ Exploratory analysis ‚Üí –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –∫—ñ–ª—å–∫–∞!
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑–∞ —Ç–∏–ø–æ–º –¥–∞–Ω–∏—Ö

**Images:**
- –í–µ–ª–∏–∫—ñ: UMAP
- –°–µ—Ä–µ–¥–Ω—ñ: Isomap, t-SNE
- –ú–∞–ª—ñ: LLE

**Text (TF-IDF):**
- UMAP (–Ω–∞–π–∫—Ä–∞—â–µ)
- t-SNE
- PCA (baseline)

**Biological data (gene expression):**
- UMAP
- Spectral Embedding
- Diffusion Maps

**Graph data:**
- Spectral Embedding
- Graph Neural Networks

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ó–∞–≤–∂–¥–∏ –ø–æ—á–Ω–∏ –∑ PCA baseline

```python
# –°–ø–æ—á–∞—Ç–∫—É PCA –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# –ü–æ—Ç—ñ–º manifold methods
isomap = Isomap(n_components=2)
X_isomap = isomap.fit_transform(X_scaled)

# –ü–æ—Ä—ñ–≤–Ω—è–π –≤—ñ–∑—É–∞–ª—å–Ω–æ
```

### 2. Scaling –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π

```python
# ‚úÖ –ó–ê–í–ñ–î–ò
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# –ü–æ—Ç—ñ–º manifold learning
```

### 3. –°–ø—Ä–æ–±—É–π —Ä—ñ–∑–Ω—ñ n_neighbors

```python
# –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π
for n in [5, 10, 20, 30]:
    isomap = Isomap(n_neighbors=n, n_components=2)
    X_transformed = isomap.fit_transform(X_scaled)
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–π
```

### 4. Subsampling –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö

```python
# –Ø–∫—â–æ > 10,000 —Ç–æ—á–æ–∫
if len(X) > 10000:
    indices = np.random.choice(len(X), 5000, replace=False)
    X_sample = X[indices]
else:
    X_sample = X

# Manifold learning –Ω–∞ sample
```

### 5. PCA preprocessing –¥–ª—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è

```python
# –Ø–∫—â–æ –±–∞–≥–∞—Ç–æ features
if X.shape[1] > 50:
    # PCA —Å–ø–æ—á–∞—Ç–∫—É
    pca = PCA(n_components=50)
    X_pca = pca.fit_transform(X_scaled)
    
    # –ü–æ—Ç—ñ–º manifold
    isomap = Isomap(n_components=2)
    X_isomap = isomap.fit_transform(X_pca)
```

### 6. –ü–æ—Ä—ñ–≤–Ω—è–π –∫—ñ–ª—å–∫–∞ –º–µ—Ç–æ–¥—ñ–≤

```python
# –ù–µ –æ–±–º–µ–∂—É–π—Å—è –æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º!
methods = [
    ('Isomap', Isomap(n_components=2)),
    ('LLE', LocallyLinearEmbedding(n_components=2)),
    ('t-SNE', TSNE(n_components=2))
]

for name, method in methods:
    X_transformed = method.fit_transform(X_scaled)
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π
```

### 7. –ü–µ—Ä–µ–≤—ñ—Ä—è–π reconstruction error

```python
# –î–ª—è –º–µ—Ç–æ–¥—ñ–≤ —â–æ –º–∞—é—Ç—å —Ü–µ
isomap = Isomap(n_components=2)
X_isomap = isomap.fit_transform(X_scaled)

error = isomap.reconstruction_error()
print(f"Reconstruction error: {error:.4f}")

# –ú–µ–Ω—à–µ = –∫—Ä–∞—â–µ
```

### 8. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥–ª—è exploratory, –Ω–µ production

```python
# ‚úÖ Exploratory analysis
# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π manifold learning –¥–ª—è —Ä–æ–∑—É–º—ñ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏

# ‚ùå Production ML pipeline
# –ö—Ä–∞—â–µ PCA –∞–±–æ UMAP (–º–∞—é—Ç—å .transform())
```

### 9. –í—ñ–∑—É–∞–ª—ñ–∑—É–π 3D –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è

```python
# 2D –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ
isomap = Isomap(n_components=3)
X_3d = isomap.fit_transform(X_scaled)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2],
                    c=y, cmap='tab10', s=20)
plt.colorbar(scatter)
plt.show()
```

### 10. –î–æ–∫—É–º–µ–Ω—Ç—É–π –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
# –ó–∞–ø–∏—à–∏ —è–∫—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—Ä–∞—Ü—é–≤–∞–ª–∏ –Ω–∞–π–∫—Ä–∞—â–µ
best_params = {
    'method': 'Isomap',
    'n_neighbors': 15,
    'n_components': 2,
    'reconstruction_error': 0.234
}
```

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö –±–µ–∑ sampling

```python
# ‚ùå –ë—É–¥–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –≥–æ–¥–∏–Ω–∞–º–∏
X_huge = np.random.randn(100000, 100)
isomap = Isomap()
X_isomap = isomap.fit_transform(X_huge)  # –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–æ!

# ‚úÖ Sample —Å–ø–æ—á–∞—Ç–∫—É
indices = np.random.choice(len(X_huge), 5000)
X_sample = X_huge[indices]
X_isomap = isomap.fit_transform(X_sample)
```

### 2. –ù–µ —Ä–æ–±–∏—Ç–∏ scaling

```python
# ‚ùå Features –≤ —Ä—ñ–∑–Ω–∏—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö
isomap.fit_transform(X)

# ‚úÖ Scaling
X_scaled = StandardScaler().fit_transform(X)
isomap.fit_transform(X_scaled)
```

### 3. –û–¥–∏–Ω n_neighbors –±–µ–∑ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤

```python
# ‚ùå Default –º–æ–∂–µ –±—É—Ç–∏ –ø–æ–≥–∞–Ω–∏–º
isomap = Isomap()  # n_neighbors=5 default

# ‚úÖ –°–ø—Ä–æ–±—É–π —Ä—ñ–∑–Ω—ñ
for n in [5, 10, 20]:
    isomap = Isomap(n_neighbors=n)
    # –ü–æ—Ä—ñ–≤–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
```

### 4. –û—á—ñ–∫—É–≤–∞—Ç–∏ .transform() –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

```python
# ‚ùå –ë—ñ–ª—å—à—ñ—Å—Ç—å –º–µ—Ç–æ–¥—ñ–≤ –Ω–µ –º–∞—é—Ç—å .transform()
lle = LocallyLinearEmbedding()
lle.fit(X_train)
# X_test_transformed = lle.transform(X_test)  # AttributeError!

# ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π UMAP –∞–±–æ PCA —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω transform
```

### 5. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –æ—Å—ñ

```python
# ‚ùå "–í—ñ—Å—å 1 –æ–∑–Ω–∞—á–∞—î..."
# –û—Å—ñ manifold methods –Ω–µ –º–∞—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è!

# ‚úÖ –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–π —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏ —Ç–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
```

### 6. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –¥–ª—è production ML

```python
# ‚ùå –í production pipeline
# Manifold methods –≤–∞–∂–∫–æ re-apply –¥–æ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

# ‚úÖ –î–ª—è exploratory –∞–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π UMAP/PCA
```

---

## –†–µ–∞–ª—å–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

### 1. Face Recognition

**–ó–∞–¥–∞—á–∞:** –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±–ª–∏—á –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–æ–∑–∞–º–∏/–æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è–º.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# Isomap –Ω–∞ face images
# Manifold captures: pose, lighting, expression

isomap = Isomap(n_neighbors=10, n_components=50)
face_embeddings = isomap.fit_transform(face_images)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è nearest neighbor matching
```

### 2. Gene Expression Analysis

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—Ç–∏–Ω –∑–∞ –µ–∫—Å–ø—Ä–µ—Å—ñ—î—é –≥–µ–Ω—ñ–≤.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# Spectral Embedding –∞–±–æ UMAP
spectral = SpectralEmbedding(n_neighbors=15, n_components=2)
cell_embedding = spectral.fit_transform(gene_expression)

# –í–∏—è–≤–ª–µ–Ω–Ω—è –∫–ª—ñ—Ç–∏–Ω–Ω–∏—Ö —Ç–∏–ø—ñ–≤ (–∫–ª–∞—Å—Ç–µ—Ä–∏)
```

### 3. Text Visualization

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
from sklearn.feature_extraction.text import TfidfVectorizer

# TF-IDF
vectorizer = TfidfVectorizer(max_features=1000)
X_tfidf = vectorizer.fit_transform(documents)

# UMAP (–Ω–∞–π–∫—Ä–∞—â–µ –¥–ª—è sparse text)
umap_model = umap.UMAP(n_components=2, metric='cosine')
doc_embedding = umap_model.fit_transform(X_tfidf.toarray())
```

### 4. Audio Feature Learning

**–ó–∞–¥–∞—á–∞:** –ó–Ω–∞–π—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ audio features.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# Extract MFCC features
# Apply manifold learning

lle = LocallyLinearEmbedding(n_components=3)
audio_embedding = lle.fit_transform(mfcc_features)
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_PCA]] ‚Äî –ª—ñ–Ω—ñ–π–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- [[02_t-SNE]] ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω–∏–π manifold method
- [[03_UMAP]] ‚Äî —Å—É—á–∞—Å–Ω–∞ —à–≤–∏–¥–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- [[Graph_Theory]] ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è spectral methods
- [[Dimensionality_Reduction]] ‚Äî –∑–∞–≥–∞–ª—å–Ω–∏–π –æ–≥–ª—è–¥

## –†–µ—Å—É—Ä—Å–∏

- [Scikit-learn: Manifold Learning](https://scikit-learn.org/stable/modules/manifold.html)
- [Original Isomap Paper (Tenenbaum et al., 2000)](https://www.science.org/doi/10.1126/science.290.5500.2319)
- [LLE Paper (Roweis & Saul, 2000)](https://www.science.org/doi/10.1126/science.290.5500.2323)
- [A Tutorial on Spectral Clustering (von Luxburg, 2007)](https://arxiv.org/abs/0711.0189)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> Manifold Learning ‚Äî —Ü–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ dimensionality reduction, —è–∫—ñ "—Ä–æ–∑–≥–æ—Ä—Ç–∞—é—Ç—å" —Å–∫–ª–∞–¥–Ω—ñ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ (manifolds) –≤ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –≤–∞–∂–ª–∏–≤—ñ –≥–µ–æ–º–µ—Ç—Ä–∏—á–Ω—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ.

**–û—Å–Ω–æ–≤–Ω–∞ —ñ–¥–µ—è:**
- –í–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ –¥–∞–Ω—ñ —á–∞—Å—Ç–æ –ª–µ–∂–∞—Ç—å –Ω–∞ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É manifold
- –ú–µ—Ç–∞: –∑–Ω–∞–π—Ç–∏ —Ü–µ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
- –†—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å —Ä—ñ–∑–Ω—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ

**–û—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç–æ–¥–∏:**

**MDS:**
- –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—ñ Euclidean distances
- –ü–æ–≤—ñ–ª—å–Ω–∏–π, –∞–ª–µ —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π
- –î–ª—è similarity visualization

**Isomap:**
- –ó–±–µ—Ä—ñ–≥–∞—î geodesic distances (–≤–∑–¥–æ–≤–∂ manifold)
- –î–æ–±—Ä–µ —Ä–æ–∑–≥–æ—Ä—Ç–∞—î Swiss Roll
- –ß—É—Ç–ª–∏–≤–∏–π –¥–æ n_neighbors

**LLE:**
- –ó–±–µ—Ä—ñ–≥–∞—î –ª–æ–∫–∞–ª—å–Ω—É –ª—ñ–Ω—ñ–π–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- –®–≤–∏–¥—à–µ –∑–∞ Isomap
- –ú–æ–∂–µ –º–∞—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏ –∑ instability

**Spectral Embedding:**
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î graph Laplacian
- –ó–≤'—è–∑–æ–∫ –∑—ñ spectral clustering
- –î–æ–±—Ä–µ –¥–ª—è graph-structured data

**–°—É—á–∞—Å–Ω—ñ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏:**
- **t-SNE:** –ö—Ä–∞—â–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è, –¥—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∏–π
- **UMAP:** –®–≤–∏–¥–∫–∏–π, –º–∞—î .transform(), —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ!

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- Exploratory analysis + –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ = Manifold methods ‚úì
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üí UMAP ‚úì
- Production ML ‚Üí PCA –∞–±–æ UMAP (–º–∞—î transform) ‚úì
- –õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ ‚Üí PCA ‚úì

**–ö–ª—é—á–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- **n_neighbors:** –ë–∞–ª–∞–Ω—Å –ª–æ–∫–∞–ª—å–Ω–æ—ó/–≥–ª–æ–±–∞–ª—å–Ω–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ (10-30)
- **n_components:** –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É (2 –¥–ª—è viz, –±—ñ–ª—å—à–µ –¥–ª—è ML)

**–ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–µ:**
- **Scaling –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π**
- **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π –∑ n_neighbors**
- **–ü–æ—Ä—ñ–≤–Ω—é–π –∫—ñ–ª—å–∫–∞ –º–µ—Ç–æ–¥—ñ–≤**
- **Subsampling –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö**
- **–î–ª—è production –∫—Ä–∞—â–µ UMAP –∞–±–æ PCA**
- **Manifold methods = exploratory tools**

---

#ml #unsupervised-learning #dimensionality-reduction #manifold-learning #isomap #lle #mds #spectral-embedding #nonlinear #visualization
