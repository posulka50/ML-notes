# t-SNE (t-Distributed Stochastic Neighbor Embedding)

## –©–æ —Ü–µ?

**t-SNE (t-Distributed Stochastic Neighbor Embedding)** ‚Äî —Ü–µ **–Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏–π** –∞–ª–≥–æ—Ä–∏—Ç–º dimensionality reduction, —è–∫–∏–π —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑—É—î—Ç—å—Å—è –Ω–∞ **–≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó** –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É 2D –∞–±–æ 3D, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ **–ª–æ–∫–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É** (–±–ª–∏–∑—å–∫—ñ —Ç–æ—á–∫–∏ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –±–ª–∏–∑—å–∫–∏–º–∏).

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ –¥–∞–Ω—ñ –≤ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä —Ç–∞–∫, —â–æ–± **–ø–æ–¥—ñ–±–Ω—ñ —Ç–æ—á–∫–∏ –±—É–ª–∏ –±–ª–∏–∑—å–∫–æ, –∞ —Ä—ñ–∑–Ω—ñ ‚Äî –¥–∞–ª–µ–∫–æ**, –æ–ø—Ç–∏–º—ñ–∑—É—é—á–∏ –≤—ñ—Ä–æ–≥—ñ–¥–Ω–æ—Å—Ç—ñ —Å—É—Å—ñ–¥—Å—Ç–≤–∞.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω?

- üé® **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** ‚Äî –≥–æ–ª–æ–≤–Ω–µ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è! –ü–æ–±–∞—á–∏—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö
- üîç **–í–∏—è–≤–ª–µ–Ω–Ω—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** ‚Äî –ø–æ–¥—ñ–±–Ω—ñ –æ–±'—î–∫—Ç–∏ –≥—Ä—É–ø—É—é—Ç—å—Å—è —Ä–∞–∑–æ–º
- üß¨ **Exploratory Data Analysis** ‚Äî —Ä–æ–∑—É–º—ñ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö
- üìä **–Ø–∫—ñ—Å—Ç—å embedding** ‚Äî –∫—Ä–∞—â–∏–π –∑–∞ PCA –¥–ª—è –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
- üéØ **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≥—ñ–ø–æ—Ç–µ–∑** ‚Äî —á–∏ —Å–ø—Ä–∞–≤–¥—ñ —ñ—Å–Ω—É—é—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏?
- üåà **–ö—Ä–∞—Å–∏–≤—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó** ‚Äî –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ–π, —Å—Ç–∞—Ç–µ–π

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**

- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö (–≥–æ–ª–æ–≤–Ω–µ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è!)
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏** ‚Äî —Å–∫–ª–∞–¥–Ω—ñ manifolds
- **–í–∏—è–≤–ª–µ–Ω–Ω—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** –≤—ñ–∑—É–∞–ª—å–Ω–æ
- **Exploratory analysis** ‚Äî –ø–æ–¥–∏–≤–∏—Ç–∏—Å—å –Ω–∞ –¥–∞–Ω—ñ
- –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å **10-1000** features
- –î–∞–Ω—ñ **–Ω–µ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫—ñ** (< 10,000 —Ç–æ—á–æ–∫)

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**

- **Downstream ML tasks** ‚Äî t-SNE –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É ‚Üí UMAP
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –æ—Å–µ–π** ‚Äî –≤—ñ—Å—ñ –Ω–µ –º–∞—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è ‚Üí PCA
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 100,000 —Ç–æ—á–æ–∫) ‚Üí UMAP –∞–±–æ PCA
- **–õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Äî PCA —à–≤–∏–¥—à–µ —Ç–∞ –∫—Ä–∞—â–µ
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞** ‚Üí PCA

---
### –©–æ —Ä–æ–±–∏—Ç—å t-SNE?

**–ö—Ä–æ–∫ 1:** –£ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ –æ–±—á–∏—Å–ª—é—î **–π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ** —Ç–æ–≥–æ, —â–æ —Ç–æ—á–∫–∞ $x_i$ –≤–∏–±–µ—Ä–µ —Ç–æ—á–∫—É $x_j$ —è–∫ "—Å—É—Å—ñ–¥–∞":

$$p_{j|i} = \frac{\exp(-\|x_i - x_j\|^2 / 2\sigma_i^2)}{\sum_{k \neq i} \exp(-\|x_i - x_k\|^2 / 2\sigma_i^2)}$$

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:** –ë–ª–∏–∑—å–∫—ñ —Ç–æ—á–∫–∏ ‚Üí –≤–∏—Å–æ–∫–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å, –¥–∞–ª–µ–∫—ñ ‚Üí –Ω–∏–∑—å–∫–∞.

**–ö—Ä–æ–∫ 2:** –£ –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ (2D) –æ–±—á–∏—Å–ª—é—î **–∞–Ω–∞–ª–æ–≥—ñ—á–Ω—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ** –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ t-—Ä–æ–∑–ø–æ–¥—ñ–ª:

$$q_{ij} = \frac{(1 + \|y_i - y_j\|^2)^{-1}}{\sum_{k \neq l} (1 + \|y_k - y_l\|^2)^{-1}}$$

**–ö—Ä–æ–∫ 3:** –ú—ñ–Ω—ñ–º—ñ–∑—É—î —Ä—ñ–∑–Ω–∏—Ü—é –º—ñ–∂ $p_{ij}$ —Ç–∞ $q_{ij}$ (KL-divergence):

$$KL(P||Q) = \sum_i \sum_j p_{ij} \log \frac{p_{ij}}{q_{ij}}$$

**–ö—Ä–æ–∫ 4:** –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î gradient descent –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –ø–æ–∑–∏—Ü—ñ–π $y_i$.

### –ß–æ–º—É t-—Ä–æ–∑–ø–æ–¥—ñ–ª?

**–ü—Ä–æ–±–ª–µ–º–∞ Gaussian:** "crowding problem" ‚Äî —É –Ω–∏–∑—å–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î –º—ñ—Å—Ü—è –¥–ª—è –≤—Å—ñ—Ö —Ç–æ—á–æ–∫.

```
High-dim: –≤—ñ–¥—Å—Ç–∞–Ω—ñ 1, 2, 3, 4, 5, ...
Low-dim (2D): –≤—Å—ñ —Ç–æ—á–∫–∏ –∑–º—É—à–µ–Ω—ñ –±—É—Ç–∏ –±–ª–∏–∑—å–∫–æ!

Gaussian kernel:
     ‚à©
    / \
   /   \
  /     \___________
–®–≤–∏–¥–∫–æ —Å–ø–∞–¥–∞—î ‚Üí all points clumped

t-distribution:
     ‚à©
    / \
   /   \
  /     \_____
 /           \___
Heavy tails ‚Üí moderate distances preserved
```

**t-—Ä–æ–∑–ø–æ–¥—ñ–ª –º–∞—î "–≤–∞–∂–∫—ñ —Ö–≤–æ—Å—Ç–∏"** ‚Üí –¥–æ–∑–≤–æ–ª—è—î —Ç–æ—á–∫–∞–º –±—É—Ç–∏ –Ω–∞ –ø–æ–º—ñ—Ä–Ω–∏—Ö –≤—ñ–¥—Å—Ç–∞–Ω—è—Ö.

---

## –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

### –£–º–æ–≤–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (high-dimensional)

**Gaussian kernel –∑ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—é —à–∏—Ä–∏–Ω–æ—é:**

$$p_{j|i} = \frac{\exp(-\|x_i - x_j\|^2 / 2\sigma_i^2)}{\sum_{k \neq i} \exp(-\|x_i - x_k\|^2 / 2\sigma_i^2)}$$

–¥–µ $\sigma_i$ –≤–∏–±–∏—Ä–∞—î—Ç—å—Å—è —Ç–∞–∫, —â–æ–± –¥–æ—Å—è–≥—Ç–∏ –∑–∞–¥–∞–Ω–æ—ó **perplexity**.

### Perplexity

**Perplexity** ‚Äî —Ü–µ –º—ñ—Ä–∞ "–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—ó –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å—É—Å—ñ–¥—ñ–≤":

$$\text{Perplexity}(P_i) = 2^{H(P_i)}$$

–¥–µ $H(P_i) = -\sum_j p_{j|i} \log_2 p_{j|i}$ ‚Äî –µ–Ω—Ç—Ä–æ–ø—ñ—è.

**–¢–∏–ø–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:** 5-50 (–∑–∞–∑–≤–∏—á–∞–π 30)

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:**
- Perplexity = 5 ‚Üí –∫–æ–∂–Ω–∞ —Ç–æ—á–∫–∞ –º–∞—î ~5 "–µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏—Ö —Å—É—Å—ñ–¥—ñ–≤"
- Perplexity = 50 ‚Üí ~50 —Å—É—Å—ñ–¥—ñ–≤
- –ë—ñ–ª—å—à–µ perplexity ‚Üí –±—ñ–ª—å—à –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

### –°–∏–º–µ—Ç—Ä–∏–∑–∞—Ü—ñ—è

**–ó—Ä–æ–±–∏—Ç–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ —Å–∏–º–µ—Ç—Ä–∏—á–Ω–∏–º–∏:**

$$p_{ij} = \frac{p_{j|i} + p_{i|j}}{2n}$$

### Low-dimensional –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ (Student t-distribution)

$$q_{ij} = \frac{(1 + \|y_i - y_j\|^2)^{-1}}{\sum_{k \neq l} (1 + \|y_k - y_l\|^2)^{-1}}$$

**–ß–æ–º—É (1 + d¬≤)‚Åª¬π?** –¶–µ Student t-—Ä–æ–∑–ø–æ–¥—ñ–ª –∑ 1 —Å—Ç—É–ø–µ–Ω–µ–º —Å–≤–æ–±–æ–¥–∏.

### –ì—Ä–∞–¥—ñ—î–Ω—Ç (–¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó)

$$\frac{\partial KL}{\partial y_i} = 4 \sum_j (p_{ij} - q_{ij})(y_i - y_j)(1 + \|y_i - y_j\|^2)^{-1}$$

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:**
- $(p_{ij} - q_{ij})$ ‚Äî –Ω–∞—Å–∫—ñ–ª—å–∫–∏ –¥–∞–ª–µ–∫–æ –≤—ñ–¥ —Ü—ñ–ª—å–æ–≤–æ—ó –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
- $(y_i - y_j)$ ‚Äî –Ω–∞–ø—Ä—è–º–æ–∫ —Ä—É—Ö—É
- $(1 + \|y_i - y_j\|^2)^{-1}$ ‚Äî –≤–∞–∂–∫—ñ —Ö–≤–æ—Å—Ç–∏ (–º–æ–¥—É–ª—é—î —Å–∏–ª—É)

---

## –ü—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥: Swiss Roll ‚Üí 2D

### –î–∞–Ω—ñ

**Swiss Roll** ‚Äî –∫–ª–∞—Å–∏—á–Ω–∏–π –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏–π manifold:

```
3D Swiss Roll (side view):
    z
    |  ‚óè‚óè‚óè
    | ‚óè   ‚óè
    |‚óè     ‚óè
    |‚óè     ‚óè
    | ‚óè   ‚óè
    |  ‚óè‚óè‚óè
    |_______ x
    
–ó–≥–æ—Ä–Ω—É—Ç–∏–π –∞—Ä–∫—É—à –ø–∞–ø–µ—Ä—É
```

### PCA (–ø—Ä–æ–≤–∞–ª)

```
PCA –ø—Ä–æ–µ–∫—Ü—ñ—è (–ª—ñ–Ω—ñ–π–Ω–∞):
    PC2
     |
     |‚óè‚óè‚óè‚óè‚óè‚óè‚óè
     |‚óè‚óè‚óè‚óè‚óè‚óè‚óè
     |‚óè‚óè‚óè‚óè‚óè‚óè‚óè
     |_______ PC1
     
–†–æ–∑–≥–æ—Ä–Ω—É—Ç–∏ –Ω–µ –º–æ–∂–µ! ‚ùå
```

### t-SNE (—É—Å–ø—ñ—Ö)

```
t-SNE 2D:
    
    ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
    ‚óè            ‚óè
    ‚óè            ‚óè
    ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
    
–†–æ–∑–≥–æ—Ä–Ω—É–≤ –∞—Ä–∫—É—à! ‚úì
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** t-SNE –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–µ–ª—ñ–Ω—ñ–π–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞ "—Ä–æ–∑–≥–æ—Ä—Ç–∞—î" —ó—ó.

---

## –°–∫–ª–∞–¥–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: MNIST

### –ó–∞–¥–∞—á–∞

MNIST: 70,000 —Ä—É–∫–æ–ø–∏—Å–Ω–∏—Ö —Ü–∏—Ñ—Ä, –∫–æ–∂–Ω–∞ 28√ó28 = 784 –ø—ñ–∫—Å–µ–ª—ñ.

**–ú–µ—Ç–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ 784D ‚Üí 2D, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏ —Ü–∏—Ñ—Ä.

### –†–µ–∑—É–ª—å—Ç–∞—Ç t-SNE

```
t-SNE 2D –ø—Ä–æ–µ–∫—Ü—ñ—è:

        3   2
    5   3  222
   555 333 22
    55  3   2
    
  1111    4444
   11      444
   11       44
   
    0000   9  8
    000   999 888
    000    99  88
   0000   9   8
   
      6    7777
    666     77
    6666     7
     66      7
```

**–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**
- ‚úÖ –ö–æ–∂–Ω–∞ —Ü–∏—Ñ—Ä–∞ —Ñ–æ—Ä–º—É—î —á—ñ—Ç–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä
- ‚úÖ –ü–æ–¥—ñ–±–Ω—ñ —Ü–∏—Ñ—Ä–∏ –±–ª–∏–∑—å–∫–æ (3 —Ç–∞ 8, 4 —Ç–∞ 9)
- ‚úÖ –†—ñ–∑–Ω—ñ —Å—Ç–∏–ª—ñ –Ω–∞–ø–∏—Å–∞–Ω–Ω—è –≤ –º–µ–∂–∞—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞
- ‚úÖ 784 —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ ‚Üí 2D –∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏!

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ PCA

| –ú–µ—Ç–æ–¥ | –ö–ª–∞—Å—Ç–µ—Ä–∏ | –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è | –°—Ç—Ä—É–∫—Ç—É—Ä–∞ |
|-------|----------|------------|-----------|
| PCA | –†–æ–∑–º–∏—Ç—ñ | –ë–∞–≥–∞—Ç–æ | –õ—ñ–Ω—ñ–π–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è |
| t-SNE | –ß—ñ—Ç–∫—ñ | –ú–∞–ª–æ | –ù–µ–ª—ñ–Ω—ñ–π–Ω–µ —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è |

---

## –ö–æ–¥ (Python + scikit-learn)

### –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
digits = load_digits()
X = digits.data  # (1797, 64) - 8x8 –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
y = digits.target

print(f"Original shape: {X.shape}")

# 2. Scaling (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. t-SNE
tsne = TSNE(
    n_components=2,      # 2D –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    perplexity=30,       # ~30 –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏—Ö —Å—É—Å—ñ–¥—ñ–≤
    learning_rate=200,   # —à–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
    n_iter=1000,         # –∫—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π
    random_state=42,
    verbose=1            # –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å
)

X_tsne = tsne.fit_transform(X_scaled)

print(f"t-SNE shape: {X_tsne.shape}")
print(f"KL divergence: {tsne.kl_divergence_:.4f}")

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(12, 10))

# Scatter plot –∑ –∫–æ–ª—å–æ—Ä–∞–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ü–∏—Ñ—Ä–∏
scatter = plt.scatter(
    X_tsne[:, 0], 
    X_tsne[:, 1],
    c=y,
    cmap='tab10',
    s=20,
    alpha=0.7,
    edgecolors='black',
    linewidths=0.5
)

plt.colorbar(scatter, label='Digit', ticks=range(10))
plt.title('t-SNE Visualization of Digits Dataset', 
         fontsize=14, fontweight='bold')
plt.xlabel('t-SNE Component 1', fontsize=12)
plt.ylabel('t-SNE Component 2', fontsize=12)
plt.grid(True, alpha=0.3)

# –î–æ–¥–∞—Ç–∏ –º—ñ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
for digit in range(10):
    mask = y == digit
    center = X_tsne[mask].mean(axis=0)
    plt.annotate(
        str(digit),
        center,
        fontsize=20,
        fontweight='bold',
        color='white',
        bbox=dict(boxstyle='circle', facecolor='black', alpha=0.7)
    )

plt.tight_layout()
plt.show()
```

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è PCA vs t-SNE

```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# t-SNE
tsne = TSNE(n_components=2, random_state=42, verbose=1)
X_tsne = tsne.fit_transform(X_scaled)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# PCA
scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], 
                          c=y, cmap='tab10', s=20, alpha=0.7,
                          edgecolors='black', linewidths=0.5)
axes[0].set_title(
    f'PCA (Explained Variance: {pca.explained_variance_ratio_.sum():.1%})',
    fontsize=13, fontweight='bold'
)
axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=11)
axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=11)
axes[0].grid(True, alpha=0.3)
plt.colorbar(scatter1, ax=axes[0], label='Digit')

# t-SNE
scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1],
                          c=y, cmap='tab10', s=20, alpha=0.7,
                          edgecolors='black', linewidths=0.5)
axes[1].set_title(
    f't-SNE (KL divergence: {tsne.kl_divergence_:.2f})',
    fontsize=13, fontweight='bold'
)
axes[1].set_xlabel('t-SNE Component 1', fontsize=11)
axes[1].set_ylabel('t-SNE Component 2', fontsize=11)
axes[1].grid(True, alpha=0.3)
plt.colorbar(scatter2, ax=axes[1], label='Digit')

plt.tight_layout()
plt.show()

print("\n=== Comparison ===")
print("PCA: Linear projection, fast, interpretable axes")
print("t-SNE: Nonlinear, better clusters, axes not interpretable")
```

### –í–ø–ª–∏–≤ Perplexity

```python
# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä—ñ–∑–Ω—ñ perplexity
perplexity_values = [5, 30, 50, 100]

fig, axes = plt.subplots(2, 2, figsize=(14, 12))
axes = axes.ravel()

for idx, perplexity in enumerate(perplexity_values):
    print(f"\nRunning t-SNE with perplexity={perplexity}...")
    
    tsne = TSNE(
        n_components=2,
        perplexity=perplexity,
        learning_rate=200,
        n_iter=1000,
        random_state=42,
        verbose=0
    )
    
    X_tsne = tsne.fit_transform(X_scaled)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    scatter = axes[idx].scatter(
        X_tsne[:, 0], X_tsne[:, 1],
        c=y, cmap='tab10', s=15, alpha=0.7
    )
    
    axes[idx].set_title(
        f'Perplexity = {perplexity}\nKL div: {tsne.kl_divergence_:.2f}',
        fontsize=12, fontweight='bold'
    )
    axes[idx].set_xlabel('t-SNE 1', fontsize=10)
    axes[idx].set_ylabel('t-SNE 2', fontsize=10)
    axes[idx].grid(True, alpha=0.3)

plt.colorbar(scatter, ax=axes, label='Digit', 
            orientation='horizontal', pad=0.02)
plt.tight_layout()
plt.show()

print("\n=== Perplexity Effects ===")
print("Low (5-10): Local structure, many small clusters")
print("Medium (30-50): Balanced, recommended")
print("High (100+): Global structure, larger clusters")
```

### –ü–æ–≤–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: MNIST –∑ PCA preprocessing

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
import time

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ MNIST (–º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ —á–∞—Å)
print("Loading MNIST dataset...")
mnist = fetch_openml('mnist_784', version=1, parser='auto')
X = mnist.data.to_numpy()
y = mnist.target.to_numpy().astype(int)

# –í–∏–±—Ä–∞—Ç–∏ –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—É (t-SNE –ø–æ–≤—ñ–ª—å–Ω–∏–π –Ω–∞ 70K —Ç–æ—á–æ–∫!)
n_samples = 5000
indices = np.random.choice(len(X), n_samples, replace=False)
X_sample = X[indices]
y_sample = y[indices]

print(f"Using {n_samples} samples")
print(f"Original shape: {X_sample.shape}")

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_sample)

# –°—Ç—Ä–∞—Ç–µ–≥—ñ—è: PCA —Å–ø–æ—á–∞—Ç–∫—É (784D ‚Üí 50D), –ø–æ—Ç—ñ–º t-SNE (50D ‚Üí 2D)
# –¶–µ –Ω–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ –Ω—ñ–∂ –ø—Ä—è–º–µ t-SNE –Ω–∞ 784D!

print("\n=== Step 1: PCA (784D ‚Üí 50D) ===")
pca = PCA(n_components=50)
start = time.time()
X_pca = pca.fit_transform(X_scaled)
pca_time = time.time() - start

print(f"PCA time: {pca_time:.2f}s")
print(f"Explained variance: {pca.explained_variance_ratio_.sum():.2%}")

print("\n=== Step 2: t-SNE (50D ‚Üí 2D) ===")
tsne = TSNE(
    n_components=2,
    perplexity=30,
    learning_rate='auto',
    n_iter=1000,
    random_state=42,
    verbose=1
)

start = time.time()
X_tsne = tsne.fit_transform(X_pca)
tsne_time = time.time() - start

print(f"t-SNE time: {tsne_time:.2f}s")
print(f"Total time: {pca_time + tsne_time:.2f}s")
print(f"KL divergence: {tsne.kl_divergence_:.4f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# PCA 2D
axes[0].scatter(X_pca[:, 0], X_pca[:, 1], 
               c=y_sample, cmap='tab10', s=5, alpha=0.6)
axes[0].set_title('PCA (784D ‚Üí 2D)', fontsize=13, fontweight='bold')
axes[0].set_xlabel('PC1', fontsize=11)
axes[0].set_ylabel('PC2', fontsize=11)
axes[0].grid(True, alpha=0.3)

# t-SNE 2D
scatter = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1],
                         c=y_sample, cmap='tab10', s=5, alpha=0.6)
axes[1].set_title('t-SNE (PCA 50D ‚Üí 2D)', fontsize=13, fontweight='bold')
axes[1].set_xlabel('t-SNE 1', fontsize=11)
axes[1].set_ylabel('t-SNE 2', fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.colorbar(scatter, ax=axes, label='Digit', ticks=range(10))
plt.tight_layout()
plt.show()

# Density plot –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ü–∏—Ñ—Ä–∏
fig, axes = plt.subplots(2, 5, figsize=(16, 7))
axes = axes.ravel()

for digit in range(10):
    mask = y_sample == digit
    
    axes[digit].scatter(
        X_tsne[~mask, 0], X_tsne[~mask, 1],
        c='lightgray', s=1, alpha=0.3
    )
    axes[digit].scatter(
        X_tsne[mask, 0], X_tsne[mask, 1],
        c='red', s=10, alpha=0.7
    )
    
    axes[digit].set_title(f'Digit {digit} (n={np.sum(mask)})',
                         fontsize=11, fontweight='bold')
    axes[digit].axis('off')

plt.suptitle('t-SNE: Individual Digit Clusters', 
            fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# –û—Ü—ñ–Ω–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó
from sklearn.metrics import silhouette_score, calinski_harabasz_score

print("\n=== Clustering Quality Metrics ===")

# –ù–∞ PCA embedding
sil_pca = silhouette_score(X_pca[:, :2], y_sample)
ch_pca = calinski_harabasz_score(X_pca[:, :2], y_sample)

# –ù–∞ t-SNE embedding
sil_tsne = silhouette_score(X_tsne, y_sample)
ch_tsne = calinski_harabasz_score(X_tsne, y_sample)

print(f"\nPCA 2D:")
print(f"  Silhouette Score: {sil_pca:.4f}")
print(f"  Calinski-Harabasz: {ch_pca:.2f}")

print(f"\nt-SNE 2D:")
print(f"  Silhouette Score: {sil_tsne:.4f}")
print(f"  Calinski-Harabasz: {ch_tsne:.2f}")

print("\nHigher = better separation")
print("t-SNE shows much better cluster separation!")
```

### Interactive 3D t-SNE

```python
# t-SNE –≤ 3D (–¥–ª—è —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó)
tsne_3d = TSNE(n_components=3, random_state=42, verbose=1)
X_tsne_3d = tsne_3d.fit_transform(X_pca)

# Plotly –¥–ª—è —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
import plotly.graph_objects as go

fig = go.Figure(data=[go.Scatter3d(
    x=X_tsne_3d[:, 0],
    y=X_tsne_3d[:, 1],
    z=X_tsne_3d[:, 2],
    mode='markers',
    marker=dict(
        size=3,
        color=y_sample,
        colorscale='Viridis',
        showscale=True,
        colorbar=dict(title="Digit")
    ),
    text=[f'Digit: {d}' for d in y_sample],
    hovertemplate='<b>%{text}</b><br>' +
                  't-SNE1: %{x:.2f}<br>' +
                  't-SNE2: %{y:.2f}<br>' +
                  't-SNE3: %{z:.2f}<br>' +
                  '<extra></extra>'
)])

fig.update_layout(
    title='Interactive 3D t-SNE Visualization',
    scene=dict(
        xaxis_title='t-SNE Component 1',
        yaxis_title='t-SNE Component 2',
        zaxis_title='t-SNE Component 3'
    ),
    width=900,
    height=700
)

fig.show()
```

---

## –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ t-SNE

### –û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
TSNE(
    n_components=2,         # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É (2 –∞–±–æ 3)
    perplexity=30.0,        # –ï—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤
    learning_rate=200.0,    # –®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
    n_iter=1000,            # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π
    metric='euclidean',     # –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
    init='pca',             # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è ('random' –∞–±–æ 'pca')
    random_state=42,        # –í—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
    verbose=0               # –í–∏–≤–æ–¥–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å
)
```

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å | –¢–∏–ø–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó |
|----------|------|-----------------|--------------|
| **n_components** | –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É | 2 (–≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è), 3 (—ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞) | –ó–∞–≤–∂–¥–∏ 2 –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ |
| **perplexity** | –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤ | 5-50 | 30 (default), 5-10 –¥–ª—è –º–∞–ª–∏—Ö –¥–∞–Ω–∏—Ö, 50 –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö |
| **learning_rate** | –®–≤–∏–¥–∫—ñ—Å—Ç—å –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó | 10-1000 | 'auto' (=n_samples/12) –∞–±–æ 200 |
| **n_iter** | –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π | 250-2000 | –ú—ñ–Ω—ñ–º—É–º 1000 –¥–ª—è convergence |
| **init** | –ü–æ—á–∞—Ç–∫–æ–≤—ñ –ø–æ–∑–∏—Ü—ñ—ó | 'pca', 'random' | 'pca' —à–≤–∏–¥—à–µ —Ç–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–µ |
| **metric** | –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ | 'euclidean', 'cosine' | 'euclidean' –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –∑–∞–¥–∞—á |

### Perplexity (–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä)

**–©–æ —Ü–µ:** –ë–∞–ª–∞–Ω—Å—É—î –º—ñ–∂ –ª–æ–∫–∞–ª—å–Ω–æ—é —Ç–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é.

**–í–ø–ª–∏–≤:**

```python
# Low perplexity (5-10): —Ñ–æ–∫—É—Å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ
tsne_low = TSNE(perplexity=5)
# ‚Üí –ë–∞–≥–∞—Ç–æ –¥—Ä—ñ–±–Ω–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
# ‚Üí –õ–æ–∫–∞–ª—å–Ω—ñ –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è
# ‚Üí –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ –±—É—Ç–∏ –≤—Ç—Ä–∞—á–µ–Ω–∞

# Medium perplexity (20-50): –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ
tsne_medium = TSNE(perplexity=30)  # ‚Üê –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
# ‚Üí –ë–∞–ª–∞–Ω—Å –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏

# High perplexity (50-100): —Ñ–æ–∫—É—Å –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ
tsne_high = TSNE(perplexity=100)
# ‚Üí –ú–µ–Ω—à–µ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
# ‚Üí –ì–ª–æ–±–∞–ª—å–Ω—ñ –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è
# ‚Üí –õ–æ–∫–∞–ª—å–Ω—ñ –¥–µ—Ç–∞–ª—ñ –º–æ–∂—É—Ç—å –∑–≥–ª–∞–¥–∂—É–≤–∞—Ç–∏—Å—å
```

**–ü—Ä–∞–≤–∏–ª–æ:**
- **–ú–∞–ª—ñ –¥–∞–Ω—ñ** (< 1000): perplexity = 5-20
- **–°–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ** (1000-10000): perplexity = 30-50
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 10000): perplexity = 50-100

**–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞:**
```python
# Perplexity –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –±—ñ–ª—å—à–∏–º –∑–∞ n_samples - 1
max_perplexity = len(X) - 1
recommended = min(30, max_perplexity)
```

### Learning Rate

**–©–æ —Ü–µ:** –®–≤–∏–¥–∫—ñ—Å—Ç—å gradient descent –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó.

**–í–ø–ª–∏–≤:**
- **–ó–∞–Ω–∞–¥—Ç–æ –Ω–∏–∑—å–∫–∞** (< 10): –¥—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è
- **–û–ø—Ç–∏–º–∞–ª—å–Ω–∞** (10-1000): –Ω–æ—Ä–º–∞–ª—å–Ω–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è
- **–ó–∞–Ω–∞–¥—Ç–æ –≤–∏—Å–æ–∫–∞** (> 1000): –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å, –ø–æ–≥–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
```python
# Automatic (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
tsne = TSNE(learning_rate='auto')  # = n_samples / 12

# –ê–±–æ —Ç–∏–ø–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
tsne = TSNE(learning_rate=200)  # Conservative
tsne = TSNE(learning_rate=500)  # Faster
tsne = TSNE(learning_rate=1000) # Aggressive
```

### –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è

**'pca' vs 'random':**

```python
# PCA initialization (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
tsne_pca = TSNE(init='pca')
# ‚úÖ –®–≤–∏–¥—à–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è
# ‚úÖ –ë—ñ–ª—å—à —Å—Ç–∞–±—ñ–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
# ‚úÖ –ú–µ–Ω—à–µ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º—ñ–Ω—ñ–º—É–º—ñ–≤

# Random initialization
tsne_random = TSNE(init='random')
# ‚ùå –ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ
# ‚ùå –ë—ñ–ª—å—à–µ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º—ñ–∂ –∑–∞–ø—É—Å–∫–∞–º–∏
# ‚úÖ –Ü–Ω–æ–¥—ñ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ü—ñ–∫–∞–≤—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
```

---

## –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ç–∞ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è

### 1. PCA Preprocessing (–ö–†–ò–¢–ò–ß–ù–û –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö!)

**–ü—Ä–æ–±–ª–µ–º–∞:** t-SNE –º–∞—î —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å O(n¬≤), –¥—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∏–π –Ω–∞ –≤–∏—Å–æ–∫—ñ–π —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ.

**–†—ñ—à–µ–Ω–Ω—è:** PCA —Å–ø–æ—á–∞—Ç–∫—É –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ.

```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# ‚ùå –ü–æ–≤—ñ–ª—å–Ω–æ: t-SNE –Ω–∞ 784D
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X)  # –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–æ!

# ‚úÖ –®–≤–∏–¥–∫–æ: PCA ‚Üí t-SNE
pca = PCA(n_components=50)  # 784D ‚Üí 50D
X_pca = pca.fit_transform(X)

tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_pca)  # –ù–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ!
```

**–ü—Ä–∞–≤–∏–ª–æ:**
- –Ø–∫—â–æ **d > 50** ‚Üí —Å–ø–æ—á–∞—Ç–∫—É PCA –¥–æ 50D
- –ó–±–µ—Ä—ñ–≥–∞—î 90-95% variance
- t-SNE –ø—Ä–∞—Ü—é—î –Ω–∞ 50D –∑–∞–º—ñ—Å—Ç—å 784D

**–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è:**
```python
import time

# –ë–µ–∑ PCA
start = time.time()
tsne = TSNE(n_components=2, verbose=0)
X_tsne_direct = tsne.fit_transform(X[:1000])
time_direct = time.time() - start

# –ó PCA
start = time.time()
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X[:1000])
tsne = TSNE(n_components=2, verbose=0)
X_tsne_pca = tsne.fit_transform(X_pca)
time_pca = time.time() - start

print(f"Direct t-SNE: {time_direct:.2f}s")
print(f"PCA + t-SNE: {time_pca:.2f}s")
print(f"Speedup: {time_direct/time_pca:.1f}x")
```

### 2. Subsampling –¥–ª—è –¥—É–∂–µ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö

```python
# –Ø–∫—â–æ > 10,000 —Ç–æ—á–æ–∫, –≤–∏–±—Ä–∞—Ç–∏ –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—É
n_samples = 5000
indices = np.random.choice(len(X), n_samples, replace=False)
X_sample = X[indices]
y_sample = y[indices]

# t-SNE –Ω–∞ sample
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_sample)
```

### 3. Barnes-Hut approximation (–≤–±—É–¥–æ–≤–∞–Ω–æ)

**scikit-learn –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Barnes-Hut** –¥–ª—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è:

- **Exact t-SNE:** O(n¬≤) ‚Äî –¥—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–æ
- **Barnes-Hut:** O(n log n) ‚Äî –Ω–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ

```python
# –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Barnes-Hut
tsne = TSNE(n_components=2, method='barnes_hut')

# –ê–±–æ —Ç–æ—á–Ω–∏–π –º–µ—Ç–æ–¥ (–ø–æ–≤—ñ–ª—å–Ω–∏–π, –¥–ª—è –º–∞–ª–∏—Ö –¥–∞–Ω–∏—Ö)
tsne = TSNE(n_components=2, method='exact')
```

### 4. Multicore t-SNE (—Å—Ç–æ—Ä–æ–Ω–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏)

**scikit-learn t-SNE –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–º!**

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏:**

```python
# MulticoreTSNE (—à–≤–∏–¥—à–µ –Ω–∞ –±–∞–≥–∞—Ç–æ—è–¥–µ—Ä–Ω–∏—Ö CPU)
from MulticoreTSNE import MulticoreTSNE as TSNE

tsne = TSNE(n_jobs=4)  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ 4 —è–¥—Ä–∞
X_tsne = tsne.fit_transform(X)

# –ê–±–æ openTSNE (–Ω–∞–π—à–≤–∏–¥—à–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è)
from openTSNE import TSNE

tsne = TSNE(n_jobs=-1)  # –í—Å—ñ —è–¥—Ä–∞
X_tsne = tsne.fit(X)
```

---

## –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ t-SNE

### –©–æ –æ–∑–Ω–∞—á–∞—é—Ç—å –æ—Å—ñ?

**–í–ê–ñ–õ–ò–í–û:** –û—Å—ñ t-SNE **–ù–ï –ú–ê–Æ–¢–¨ –∑–Ω–∞—á–µ–Ω–Ω—è**!

```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
print(f"t-SNE axis 1 represents...")  # –ë–µ–∑–≥–ª—É–∑–¥–æ!

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
print("Clusters in t-SNE space:")
# –í–∞–∂–ª–∏–≤—ñ —Ç—ñ–ª—å–∫–∏ –≤—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏, –Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω—ñ –ø–æ–∑–∏—Ü—ñ—ó
```

**–ß–æ–º—É:**
- t-SNE –æ–ø—Ç–∏–º—ñ–∑—É—î —Ç—ñ–ª—å–∫–∏ **–ª–æ–∫–∞–ª—å–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ**
- –ì–ª–æ–±–∞–ª—å–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ —Ç–∞ –æ—Ä—ñ—î–Ω—Ç–∞—Ü—ñ—è –¥–æ–≤—ñ–ª—å–Ω—ñ
- –û–±–µ—Ä—Ç–∞–Ω–Ω—è/–≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–º—ñ–Ω—é—î —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—é

### –©–æ –º–æ–∂–Ω–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏?

**‚úÖ –ú–æ–∂–Ω–∞:**
1. **–ö–ª–∞—Å—Ç–µ—Ä–∏** ‚Äî —â—ñ–ª—å–Ω—ñ –≥—Ä—É–ø–∏ —Ç–æ—á–æ–∫
2. **–í—ñ–¥–Ω–æ—Å–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ** ‚Äî –±–ª–∏–∑—å–∫—ñ vs –¥–∞–ª–µ–∫—ñ —Ç–æ—á–∫–∏
3. **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** ‚Äî —Å—É—Å—ñ–¥—Å—Ç–≤–æ
4. **Outliers** ‚Äî —ñ–∑–æ–ª—å–æ–≤–∞–Ω—ñ —Ç–æ—á–∫–∏

**‚ùå –ù–µ –º–æ–∂–Ω–∞:**
1. **–ê–±—Å–æ–ª—é—Ç–Ω—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏** ‚Äî –±–µ–∑ –∑–Ω–∞—á–µ–Ω–Ω—è
2. **–í—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏** ‚Äî –Ω–µ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è
3. **–†–æ–∑–º—ñ—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** ‚Äî –º–æ–∂—É—Ç—å –±—É—Ç–∏ –æ–º–∞–Ω–ª–∏–≤–∏–º–∏
4. **–©—ñ–ª—å–Ω—ñ—Å—Ç—å** ‚Äî –º–æ–∂–µ –±—É—Ç–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–º perplexity

### –¢–∏–ø–æ–≤—ñ –ø–∞—Ç—Ç–µ—Ä–Ω–∏

**1. –ß—ñ—Ç–∫—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏:**
```
    ‚óè‚óè‚óè        ‚ñ†‚ñ†‚ñ†
     ‚óè‚óè        ‚ñ†‚ñ†
    ‚óè‚óè‚óè        ‚ñ†‚ñ†‚ñ†
    
–î–æ–±—Ä–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ –∫–ª–∞—Å–∏
```

**2. –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è:**
```
    ‚óè‚óè‚óè
     ‚óè‚óè‚ñ†‚ñ†‚ñ†
    ‚óè‚óè‚ñ†‚ñ†‚ñ†
    
–ö–ª–∞—Å–∏ –∑ –ø–æ–¥—ñ–±–Ω–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
```

**3. Manifold (–∫–æ–Ω—Ç–∏–Ω—É—É–º):**
```
    ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
    ‚óè        ‚óè
    ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
    
–ë–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –æ–±–µ—Ä—Ç–∞–Ω–Ω—è –æ–±'—î–∫—Ç–∞)
```

**4. Outliers:**
```
    ‚óè‚óè‚óè        ‚ñ†‚ñ†‚ñ†
     ‚óè‚óè        ‚ñ†‚ñ†
    ‚óè‚óè‚óè   ‚Ä¢   ‚ñ†‚ñ†‚ñ†
          ‚Üë
        outlier
```

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ü–µ—Ä–µ–≤–∞–≥–∏ ‚úì

| –ü–µ—Ä–µ–≤–∞–≥–∞ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|----------|-----------|
| **–ù–µ–ª—ñ–Ω—ñ–π–Ω–µ –∑–º–µ–Ω—à–µ–Ω–Ω—è** | –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —Å–∫–ª–∞–¥–Ω—ñ manifolds |
| **–ö—Ä–∞—â–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** | –ö–ª–∞—Å—Ç–µ—Ä–∏ —á—ñ—Ç–∫—ñ—à—ñ –Ω—ñ–∂ PCA |
| **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | –ó–±–µ—Ä—ñ–≥–∞—î —Å—É—Å—ñ–¥—Å—Ç–≤–æ —Ç–æ—á–æ–∫ |
| **–ü—Ä–∞—Ü—é—î –∑ –±—É–¥—å-—è–∫–∏–º–∏ –¥–∞–Ω–∏–º–∏** | –ü–æ—Ç—Ä—ñ–±–Ω–∞ —Ç—ñ–ª—å–∫–∏ –º–∞—Ç—Ä–∏—Ü—è –≤—ñ–¥—Å—Ç–∞–Ω–µ–π |
| **–í–∏—è–≤–ª–µ–Ω–Ω—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** | –í—ñ–∑—É–∞–ª—å–Ω–æ —á—ñ—Ç–∫—ñ –≥—Ä—É–ø–∏ |
| **–í—ñ–¥–æ–º–∏–π —Ç–∞ –ø–æ–ø—É–ª—è—Ä–Ω–∏–π** | –ë–∞–≥–∞—Ç–æ –º–∞—Ç–µ—Ä—ñ–∞–ª—ñ–≤, –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ |

### –ù–µ–¥–æ–ª—ñ–∫–∏ ‚úó

| –ù–µ–¥–æ–ª—ñ–∫ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|---------|-----------|
| **–¢—ñ–ª—å–∫–∏ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** | –ù–ï –¥–ª—è downstream ML tasks |
| **–î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∏–π** | O(n¬≤), –ø—Ä–æ–±–ª–µ–º–∏ –Ω–∞ > 10K —Ç–æ—á–æ–∫ |
| **–ù–µ–¥–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π** | –†—ñ–∑–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ –∫–æ–∂–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É |
| **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—Ç—Ä–∞—á–µ–Ω–∞** | –í—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –±–µ–∑–≥–ª—É–∑–¥–æ–≤—ñ |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤** | Perplexity —Å–∏–ª—å–Ω–æ –≤–ø–ª–∏–≤–∞—î |
| **–û—Å—ñ –±–µ–∑ –∑–Ω–∞—á–µ–Ω–Ω—è** | –ù–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–Ω—ñ |
| **Crowding problem** | –Ü–Ω–æ–¥—ñ –∑–∞–Ω–∞–¥—Ç–æ —Å—Ç–∏—Å–∫–∞—î –∫–ª–∞—Å—Ç–µ—Ä–∏ |

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏

| –ú–µ—Ç–æ–¥ | –®–≤–∏–¥–∫—ñ—Å—Ç—å | –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | Downstream ML | –î–µ—Ç–µ—Ä–º—ñ–Ω—ñ–∑–º | –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è |
|-------|-----------|---------------------|---------------|-------------|--------------|
| **t-SNE** | ‚≠ê | ‚ùå | ‚ùå | ‚ùå | –¢—ñ–ª—å–∫–∏ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è |
| **PCA** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚úÖ | –ó–∞–≥–∞–ª—å–Ω–µ –∑–º–µ–Ω—à–µ–Ω–Ω—è |
| **UMAP** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + ML |
| **LDA** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚úÖ | Supervised tasks |
| **Autoencoders** | ‚≠ê‚≠ê | ‚ö†Ô∏è | ‚úÖ | ‚ö†Ô∏è | –°–∫–ª–∞–¥–Ω—ñ –¥–∞–Ω—ñ |

### t-SNE vs PCA

**t-SNE:**
- ‚úÖ –ù–µ–ª—ñ–Ω—ñ–π–Ω–∏–π (—Å–∫–ª–∞–¥–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏)
- ‚úÖ –ö—Ä–∞—â—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏ –≤—ñ–∑—É–∞–ª—å–Ω–æ
- ‚ùå –ü–æ–≤—ñ–ª—å–Ω–∏–π
- ‚ùå –¢—ñ–ª—å–∫–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
- ‚ùå –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—Ç—Ä–∞—á–µ–Ω–∞

**PCA:**
- ‚úÖ –®–≤–∏–¥–∫–∏–π
- ‚úÖ –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- ‚úÖ –î–ª—è downstream tasks
- ‚ùå –¢—ñ–ª—å–∫–∏ –ª—ñ–Ω—ñ–π–Ω–∏–π

**–ö–æ–ª–∏ —â–æ:**
- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** ‚Üí t-SNE ‚úì
- **Preprocessing –¥–ª—è ML** ‚Üí PCA ‚úì
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤** ‚Üí PCA ‚úì

### t-SNE vs UMAP

**t-SNE:**
- ‚úÖ –ë—ñ–ª—å—à –≤—ñ–¥–æ–º–∏–π, –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π —á–∞—Å–æ–º
- ‚úÖ –ö—Ä–∞—â–∞ –ª–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- ‚ùå –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∏–π
- ‚ùå –¢—ñ–ª—å–∫–∏ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

**UMAP:**
- ‚úÖ –ù–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ (10-100x)
- ‚úÖ –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- ‚úÖ –î–ª—è downstream ML
- ‚ö†Ô∏è –ù–æ–≤—ñ—à–∏–π (–º–µ–Ω—à–µ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –°–ø—Ä–æ–±—É–π UMAP —Å–ø–æ—á–∞—Ç–∫—É, –ø–æ—Ç—ñ–º t-SNE –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è.

---

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ t-SNE

### –Ü–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å ‚úì

- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö (–≥–æ–ª–æ–≤–Ω–µ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è!)
- **Exploratory analysis** ‚Äî –ø–æ–¥–∏–≤–∏—Ç–∏—Å—å –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- **–í–∏—è–≤–ª–µ–Ω–Ω—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** –≤—ñ–∑—É–∞–ª—å–Ω–æ
- **–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—ó, —Å—Ç–∞—Ç—Ç—ñ** ‚Äî –∫—Ä–∞—Å–∏–≤—ñ –≥—Ä–∞—Ñ—ñ–∫–∏
- **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≥—ñ–ø–æ—Ç–µ–∑** ‚Äî —á–∏ —î –∫–ª–∞—Å—Ç–µ—Ä–∏?
- **–ù–µ–≤–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (< 10,000 —Ç–æ—á–æ–∫)
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏** ‚Äî manifolds

### –ö—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à–µ ‚úó

- **Downstream ML** (–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è, —Ä–µ–≥—Ä–µ—Å—ñ—è) ‚Üí UMAP, PCA
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 50,000 —Ç–æ—á–æ–∫) ‚Üí UMAP –∞–±–æ PCA ‚Üí t-SNE
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞** ‚Üí PCA, UMAP
- **–ü–æ—Ç—Ä—ñ–±–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** ‚Üí PCA, UMAP
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –æ—Å–µ–π** –≤–∞–∂–ª–∏–≤–∞ ‚Üí PCA, LDA
- **–õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Äî PCA –ø—Ä–æ—Å—Ç—ñ—à–∏–π —Ç–∞ —à–≤–∏–¥—à–∏–π

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ó–ê–í–ñ–î–ò PCA preprocessing –¥–ª—è d > 50

```python
# ‚ùå –ü–æ–≤—ñ–ª—å–Ω–æ
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_784d)  # –ì–æ–¥–∏–Ω–∏!

# ‚úÖ –®–≤–∏–¥–∫–æ
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X_784d)

tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_pca)  # –•–≤–∏–ª–∏–Ω–∏!
```

### 2. –ü–µ—Ä–µ–≤—ñ—Ä—è–π —Ä—ñ–∑–Ω—ñ perplexity

```python
# –°–ø—Ä–æ–±—É–π 3-5 –∑–Ω–∞—á–µ–Ω—å
perplexities = [5, 30, 50, 100]

for perp in perplexities:
    tsne = TSNE(perplexity=perp, random_state=42)
    X_tsne = tsne.fit_transform(X)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–π
    plt.figure()
    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y)
    plt.title(f'Perplexity = {perp}')
    plt.show()
```

### 3. –ó–∞–ø—É—Å–∫–∞–π –∫—ñ–ª—å–∫–∞ —Ä–∞–∑—ñ–≤ (–Ω–µ–¥–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π!)

```python
# t-SNE –¥–∞—î —Ä—ñ–∑–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏!
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for idx in range(3):
    tsne = TSNE(random_state=idx)  # –†—ñ–∑–Ω—ñ random_state
    X_tsne = tsne.fit_transform(X)
    
    axes[idx].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y)
    axes[idx].set_title(f'Run {idx+1}')

plt.show()

# –í–∏–±–µ—Ä–∏ –Ω–∞–π–∫—Ä–∞—â–∏–π –≤—ñ–∑—É–∞–ª—å–Ω–æ
```

### 4. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π init='pca' –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ

```python
# –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
tsne = TSNE(init='pca', random_state=42)
# ‚úÖ –®–≤–∏–¥—à–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è
# ‚úÖ –ë—ñ–ª—å—à —Å—Ç–∞–±—ñ–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
```

### 5. n_iter –º—ñ–Ω—ñ–º—É–º 1000

```python
# ‚ùå –ó–∞–º–∞–ª–æ —ñ—Ç–µ—Ä–∞—Ü—ñ–π
tsne = TSNE(n_iter=250)  # –ú–æ–∂–µ –Ω–µ –∑—ñ–π—Ç–∏—Å—å!

# ‚úÖ –î–æ—Å—Ç–∞—Ç–Ω—å–æ
tsne = TSNE(n_iter=1000)  # –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ

# –î–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
tsne = TSNE(n_iter=2000)
```

### 6. –ü–µ—Ä–µ–≤—ñ—Ä—è–π KL divergence

```python
tsne = TSNE(verbose=1)
X_tsne = tsne.fit_transform(X)

print(f"Final KL divergence: {tsne.kl_divergence_:.4f}")

# –ù–∏–∂—á–µ = –∫—Ä–∞—â–µ (–∑–∞–∑–≤–∏—á–∞–π 1-5)
# –Ø–∫—â–æ > 10 ‚Üí –ø–æ–≥–∞–Ω–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è, —Å–ø—Ä–æ–±—É–π:
#   - –ë—ñ–ª—å—à–µ n_iter
#   - –Ü–Ω—à–∏–π learning_rate
#   - –Ü–Ω—à–∏–π perplexity
```

### 7. Scaling –ø–µ—Ä–µ–¥ t-SNE

```python
# –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ (—Ö–æ—á–∞ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ —è–∫ –¥–ª—è PCA)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

tsne = TSNE()
X_tsne = tsne.fit_transform(X_scaled)
```

### 8. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥–ª—è initial exploration, –Ω–µ –¥–ª—è –æ—Å—Ç–∞—Ç–æ—á–Ω–∏—Ö –≤–∏—Å–Ω–æ–≤–∫—ñ–≤

```python
# ‚úÖ –î–æ–±—Ä–µ
"t-SNE –ø–æ–∫–∞–∑—É—î —â–æ –¥–∞–Ω—ñ –º–∞—é—Ç—å ~3 –∫–ª–∞—Å—Ç–µ—Ä–∏"
"–í—ñ–∑—É–∞–ª—å–Ω–æ —Å—Ö–æ–∂–µ —â–æ –∫–ª–∞—Å–∏ A —Ç–∞ B –ø–æ–¥—ñ–±–Ω—ñ"

# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
"–í—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –ê —Ç–∞ –ë = 5 –æ–¥–∏–Ω–∏—Ü—å"
"–ö–ª–∞—Å—Ç–µ—Ä C –±—ñ–ª—å—à–∏–π –∑–∞ –∫–ª–∞—Å—Ç–µ—Ä D"

# –î–ª—è –∫—ñ–ª—å–∫—ñ—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —ñ–Ω—à—ñ –º–µ—Ç–æ–¥–∏!
```

### 9. Subsampling –¥–ª—è > 10K —Ç–æ—á–æ–∫

```python
# –Ø–∫—â–æ –¥—É–∂–µ –±–∞–≥–∞—Ç–æ –¥–∞–Ω–∏—Ö
if len(X) > 10000:
    indices = np.random.choice(len(X), 10000, replace=False)
    X_sample = X[indices]
    y_sample = y[indices]
else:
    X_sample = X
    y_sample = y

tsne = TSNE()
X_tsne = tsne.fit_transform(X_sample)
```

### 10. –ö–æ–º–±—ñ–Ω—É–π –∑ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—î—é –¥–ª—è validation

```python
# t-SNE –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó + clustering –¥–ª—è –∫—ñ–ª—å–∫—ñ—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
from sklearn.cluster import KMeans

# 1. t-SNE –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X)

# 2. K-Means –Ω–∞ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
kmeans = KMeans(n_clusters=3)
labels = kmeans.fit_predict(X)

# 3. –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ t-SNE –∑ –º—ñ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels)
plt.title('t-SNE colored by K-Means clusters')
plt.show()

# –Ø–∫—â–æ –∫–ª–∞—Å—Ç–µ—Ä–∏ –Ω–∞ t-SNE —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å –∑ K-Means ‚Üí –¥–æ–±—Ä–µ!
```

---

## –†–µ–∞–ª—å–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

### 1. Genomics (–∞–Ω–∞–ª—ñ–∑ –≥–µ–Ω—ñ–≤)

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –µ–∫—Å–ø—Ä–µ—Å—ñ—é –≥–µ–Ω—ñ–≤ —É –∫–ª—ñ—Ç–∏–Ω–∞—Ö.

**–î–∞–Ω—ñ:**
- Single-cell RNA-seq
- 10,000 –∫–ª—ñ—Ç–∏–Ω √ó 20,000 –≥–µ–Ω—ñ–≤

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. PCA preprocessing (20K ‚Üí 50 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤)
pca = PCA(n_components=50)
X_pca = pca.fit_transform(gene_expression)

# 2. t-SNE –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
tsne = TSNE(n_components=2, perplexity=30)
X_tsne = tsne.fit_transform(X_pca)

# 3. –ö–æ–ª—ñ—Ä –ø–æ —Ç–∏–ø—É –∫–ª—ñ—Ç–∏–Ω (—è–∫—â–æ –≤—ñ–¥–æ–º–æ) –∞–±–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cell_types)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –í–∏—è–≤–ª–µ–Ω–Ω—è –ø—ñ–¥—Ç–∏–ø—ñ–≤ –∫–ª—ñ—Ç–∏–Ω
- –¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–∞—Ü—ñ—ó
- –†—ñ–¥–∫—ñ—Å–Ω—ñ –ø–æ–ø—É–ª—è—Ü—ñ—ó

### 2. Word Embeddings

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ word vectors (Word2Vec, GloVe).

**–î–∞–Ω—ñ:**
- 50,000 —Å–ª—ñ–≤ √ó 300D vectors

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# t-SNE –Ω–∞ word embeddings
tsne = TSNE(n_components=2, perplexity=50)
word_tsne = tsne.fit_transform(word_vectors)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∑ –ø—ñ–¥–ø–∏—Å–∞–º–∏
plt.figure(figsize=(20, 20))
plt.scatter(word_tsne[:, 0], word_tsne[:, 1], alpha=0.3)

# –ü—ñ–¥–ø–∏—Å–∞—Ç–∏ —Ü—ñ–∫–∞–≤—ñ —Å–ª–æ–≤–∞
for i, word in enumerate(interesting_words):
    idx = word_to_idx[word]
    plt.annotate(word, word_tsne[idx], fontsize=12)

plt.show()
```

**–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**
- –°–µ–º–∞–Ω—Ç–∏—á–Ω–æ –ø–æ–¥—ñ–±–Ω—ñ —Å–ª–æ–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É—é—Ç—å—Å—è
- –°–∏–Ω–æ–Ω—ñ–º–∏ –±–ª–∏–∑—å–∫–æ –æ–¥–∏–Ω –¥–æ –æ–¥–Ω–æ–≥–æ
- –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó (–∫—Ä–∞—ó–Ω–∏, —Ç–≤–∞—Ä–∏–Ω–∏) —Ñ–æ—Ä–º—É—é—Ç—å –≥—Ä—É–ø–∏

### 3. Image Retrieval

**–ó–∞–¥–∞—á–∞:** –ù–∞–≤—ñ–≥–∞—Ü—ñ—è –ø–æ –≤–µ–ª–∏–∫—ñ–π –∫–æ–ª–µ–∫—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å.

**–î–∞–Ω—ñ:**
- 100,000 –∑–æ–±—Ä–∞–∂–µ–Ω—å
- CNN features (ResNet) 2048D

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. Extract CNN features
features = resnet_model.predict(images)  # (100K, 2048)

# 2. PCA preprocessing
pca = PCA(n_components=50)
features_pca = pca.fit_transform(features)

# 3. t-SNE –Ω–∞ –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—ñ
sample_idx = np.random.choice(len(features), 5000)
features_sample = features_pca[sample_idx]

tsne = TSNE(n_components=2)
features_tsne = tsne.fit_transform(features_sample)

# 4. –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∑ thumbnail –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –í—ñ–∑—É–∞–ª—å–Ω–∞ –Ω–∞–≤—ñ–≥–∞—Ü—ñ—è –ø–æ –∫–æ–ª–µ–∫—Ü—ñ—ó
- –ü–æ–¥—ñ–±–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≥—Ä—É–ø—É—é—Ç—å—Å—è
- –í–∏—è–≤–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤

### 4. Customer Segmentation

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç–∏ –∫–ª—ñ—î–Ω—Ç—ñ–≤.

**–î–∞–Ω—ñ:**
- 50,000 –∫–ª—ñ—î–Ω—Ç—ñ–≤
- 100 features (–ø–æ–≤–µ–¥—ñ–Ω–∫–∞, –¥–µ–º–æ–≥—Ä–∞—Ñ—ñ—è)

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. Feature engineering + scaling
X_scaled = scaler.fit_transform(customer_features)

# 2. PCA preprocessing
pca = PCA(n_components=30)
X_pca = pca.fit_transform(X_scaled)

# 3. t-SNE
tsne = TSNE(n_components=2, perplexity=50)
X_tsne = tsne.fit_transform(X_pca)

# 4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –Ω–∞ t-SNE –ø—Ä–æ—Å—Ç–æ—Ä—ñ
from sklearn.cluster import DBSCAN
clusters = DBSCAN(eps=0.5).fit_predict(X_tsne)

# 5. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters, cmap='tab10')
```

### 5. Drug Discovery

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ö—ñ–º—ñ—á–Ω–∏—Ö —Å–ø–æ–ª—É–∫.

**–î–∞–Ω—ñ:**
- Molecular fingerprints (1024-bit vectors)
- –¢–∏—Å—è—á—ñ –º–æ–ª–µ–∫—É–ª

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# t-SNE –Ω–∞ molecular fingerprints
tsne = TSNE(n_components=2, metric='jaccard')  # Jaccard –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–∏—Ö
mol_tsne = tsne.fit_transform(fingerprints)

# –ö–æ–ª—ñ—Ä –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
plt.scatter(mol_tsne[:, 0], mol_tsne[:, 1], 
           c=biological_activity, cmap='RdYlGn')
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –°—Ö–æ–∂—ñ –º–æ–ª–µ–∫—É–ª–∏ –≥—Ä—É–ø—É—é—Ç—å—Å—è
- –í–∏—è–≤–ª–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤
- Structure-activity relationships

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ t-SNE –¥–ª—è downstream ML

```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_train)

# –ù–∞–≤—á–∏—Ç–∏ classifier –Ω–∞ t-SNE features
classifier.fit(X_tsne, y_train)

# –ù–∞ test:
X_test_tsne = tsne.fit_transform(X_test)  # –ü–û–ú–ò–õ–ö–ê!
# t-SNE –ù–ï –º–∞—î transform –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö!

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π PCA –∞–±–æ UMAP
pca = PCA(n_components=50)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)  # ‚úì –ü—Ä–∞—Ü—é—î
```

### 2. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –≤—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏

```python
# ‚ùå "–ö–ª–∞—Å—Ç–µ—Ä A —Ç–∞ B –±–ª–∏–∑—å–∫—ñ, —Ç–æ–º—É –ø–æ–¥—ñ–±–Ω—ñ"
# ‚ùå "–ö–ª–∞—Å—Ç–µ—Ä C –¥–∞–ª–µ–∫–æ, —Ç–æ–º—É –¥—É–∂–µ –≤—ñ–¥–º—ñ–Ω–Ω–∏–π"

# t-SNE –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ!
# –¢—ñ–ª—å–∫–∏ –ª–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–∞—î –∑–Ω–∞—á–µ–Ω–Ω—è.

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
# "–ö–ª–∞—Å—Ç–µ—Ä–∏ A —Ç–∞ B —ñ—Å–Ω—É—é—Ç—å"
# "–¢–æ—á–∫–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∞ C –ø–æ–¥—ñ–±–Ω—ñ –º—ñ–∂ —Å–æ–±–æ—é"
```

### 3. –ù–µ —Ä–æ–±–∏—Ç–∏ PCA preprocessing

```python
# ‚ùå t-SNE –Ω–∞ 784D MNIST
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X_784d)  # –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–æ!

# ‚úÖ PCA —Å–ø–æ—á–∞—Ç–∫—É
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X_784d)
X_tsne = tsne.fit_transform(X_pca)  # –ù–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ!
```

### 4. –û–¥–∏–Ω –∑–∞–ø—É—Å–∫ –±–µ–∑ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ

```python
# ‚ùå –û–¥–∏–Ω –∑–∞–ø—É—Å–∫
tsne = TSNE(random_state=42)
X_tsne = tsne.fit_transform(X)
# –ú–æ–∂–ª–∏–≤–æ, –ø–æ–≥–∞–Ω–∏–π –ª–æ–∫–∞–ª—å–Ω–∏–π –º—ñ–Ω—ñ–º—É–º!

# ‚úÖ –ö—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤
best_kl = float('inf')
best_result = None

for seed in range(5):
    tsne = TSNE(random_state=seed)
    X_tsne = tsne.fit_transform(X)
    
    if tsne.kl_divergence_ < best_kl:
        best_kl = tsne.kl_divergence_
        best_result = X_tsne

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –Ω–∞–π–∫—Ä–∞—â–∏–π
```

### 5. –ù–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—Ç–∏ —Ä—ñ–∑–Ω—ñ perplexity

```python
# ‚ùå –¢—ñ–ª—å–∫–∏ default perplexity=30
tsne = TSNE(perplexity=30)

# ‚úÖ –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –∫—ñ–ª—å–∫–∞
for perp in [5, 30, 50]:
    tsne = TSNE(perplexity=perp)
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è—Ç–∏
```

### 6. –û—á—ñ–∫—É–≤–∞—Ç–∏ —à–≤–∏–¥–∫—ñ—Å—Ç—å

```python
# ‚ùå t-SNE –Ω–∞ 100,000 —Ç–æ—á–∫–∞—Ö
# –ú–æ–∂–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –≥–æ–¥–∏–Ω–∏/–¥–Ω—ñ!

# ‚úÖ Sampling —Å–ø–æ—á–∞—Ç–∫—É
n_samples = min(10000, len(X))
indices = np.random.choice(len(X), n_samples)
X_sample = X[indices]

tsne = TSNE()
X_tsne = tsne.fit_transform(X_sample)
```

### 7. –ü–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏ —Ä–æ–∑–º—ñ—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤

```python
# ‚ùå "–ö–ª–∞—Å—Ç–µ—Ä A –±—ñ–ª—å—à–∏–π –∑–∞ –∫–ª–∞—Å—Ç–µ—Ä B"
# –†–æ–∑–º—ñ—Ä–∏ –Ω–∞ t-SNE –º–æ–∂—É—Ç—å –±—É—Ç–∏ –æ–º–∞–Ω–ª–∏–≤–∏–º–∏!

# Perplexity –≤–ø–ª–∏–≤–∞—î –Ω–∞ —â—ñ–ª—å–Ω—ñ—Å—Ç—å
# –í–µ–ª–∏–∫—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏ –º–æ–∂—É—Ç—å –∑–¥–∞–≤–∞—Ç–∏—Å—å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —ñ –Ω–∞–≤–ø–∞–∫–∏

# ‚úÖ –ü–æ—Ä–∞—Ö—É–π —Ç–æ—á–∫–∏
cluster_sizes = np.bincount(labels)
print(f"Actual sizes: {cluster_sizes}")
```

### 8. –ù–µ –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ learning_rate

```python
# ‚ùå Default –º–æ–∂–µ –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –¥–ª—è –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö
tsne = TSNE()

# –Ø–∫—â–æ –±–∞—á–∏—à "gradient descent did not converge"
# ‚úÖ –ù–∞–ª–∞—à—Ç—É–π learning_rate
tsne = TSNE(learning_rate='auto')  # –ê–±–æ
tsne = TSNE(learning_rate=500)
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_PCA]] ‚Äî –ª—ñ–Ω—ñ–π–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- [[03_UMAP]] ‚Äî —à–≤–∏–¥—à–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ t-SNE
- [[04_LDA]] ‚Äî supervised dimensionality reduction
- [[05_Autoencoders]] ‚Äî neural network approach
- [[06_Manifold_Learning]] ‚Äî —ñ–Ω—à—ñ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –º–µ—Ç–æ–¥–∏
- [[Clustering_Evaluation]] ‚Äî –æ—Ü—ñ–Ω–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤

## –†–µ—Å—É—Ä—Å–∏

- [Original Paper: van der Maaten & Hinton (2008)](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)
- [How to Use t-SNE Effectively (Distill)](https://distill.pub/2016/misread-tsne/)
- [Scikit-learn: t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)
- [StatQuest: t-SNE](https://www.youtube.com/watch?v=NEaUSP4YerM)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> t-SNE ‚Äî —Ü–µ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö, —è–∫–∏–π –∑–±–µ—Ä—ñ–≥–∞—î –ª–æ–∫–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–±–ª–∏–∑—å–∫—ñ —Ç–æ—á–∫–∏ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –±–ª–∏–∑—å–∫–∏–º–∏) –º—ñ–Ω—ñ–º—ñ–∑—É—é—á–∏ KL-divergence –º—ñ–∂ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏ –≤ high-dimensional —Ç–∞ low-dimensional –ø—Ä–æ—Å—Ç–æ—Ä–∞—Ö.

**–û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–∏–Ω—Ü–∏–ø–∏:**
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω–∏–π:** –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Å–∫–ª–∞–¥–Ω—ñ manifolds
- **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:** –∑–±–µ—Ä—ñ–≥–∞—î —Å—É—Å—ñ–¥—Å—Ç–≤–æ
- **Probabilistic:** –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è—Ö —Å—É—Å—ñ–¥—Å—Ç–≤–∞
- **t-—Ä–æ–∑–ø–æ–¥—ñ–ª:** –≤–∏—Ä—ñ—à—É—î crowding problem

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. –û–±—á–∏—Å–ª–∏—Ç–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –≤ high-dim (Gaussian)
2. –û–±—á–∏—Å–ª–∏—Ç–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –≤ low-dim (t-distribution)
3. –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ KL-divergence gradient descent
4. –ü–æ–≤—Ç–æ—Ä—é–≤–∞—Ç–∏ –¥–æ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—ó

**–ö–ª—é—á–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- **Perplexity** (5-50, –∑–∞–∑–≤–∏—á–∞–π 30) ‚Äî –±–∞–ª–∞–Ω—Å –ª–æ–∫–∞–ª—å–Ω–æ—ó/–≥–ª–æ–±–∞–ª—å–Ω–æ—ó —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
- **Learning rate** ('auto' –∞–±–æ 200) ‚Äî —à–≤–∏–¥–∫—ñ—Å—Ç—å –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
- **n_iter** (–º—ñ–Ω—ñ–º—É–º 1000) ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π
- **init** ('pca' —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ) ‚Äî –ø–æ—á–∞—Ç–∫–æ–≤–∞ –ø–æ–∑–∏—Ü—ñ—è

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ + exploratory = t-SNE ‚úì
- Downstream ML ‚Üí UMAP, PCA ‚úì
- –í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ + —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üí UMAP ‚úì
- –õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ ‚Üí PCA ‚úì

**–ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–µ:**
- **–¢—ñ–ª—å–∫–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó!** –ù–ï –¥–ª—è ML tasks
- **PCA preprocessing** —è–∫—â–æ d > 50 (–∫—Ä–∏—Ç–∏—á–Ω–æ!)
- **Perplexity** ‚Äî –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä
- **–ù–µ–¥–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π** ‚Äî –∑–∞–ø—É—Å–∫–∞–π –∫—ñ–ª—å–∫–∞ —Ä–∞–∑—ñ–≤
- **–û—Å—ñ –±–µ–∑ –∑–Ω–∞—á–µ–Ω–Ω—è** ‚Äî —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–π —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏
- **Sampling** –¥–ª—è > 10K —Ç–æ—á–æ–∫
- –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è

---

#ml #unsupervised-learning #dimensionality-reduction #tsne #visualization #manifold-learning #nonlinear #exploratory-analysis
