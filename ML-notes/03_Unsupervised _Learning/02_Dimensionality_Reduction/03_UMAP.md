# UMAP (Uniform Manifold Approximation and Projection)

## –©–æ —Ü–µ?

**UMAP (Uniform Manifold Approximation and Projection)** ‚Äî —Ü–µ —Å—É—á–∞—Å–Ω–∏–π **–Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏–π** –∞–ª–≥–æ—Ä–∏—Ç–º dimensionality reduction, —è–∫–∏–π –ø—Ä–∞—Ü—é—î **—à–≤–∏–¥—à–µ –∑–∞ t-SNE** —ñ –∑–±–µ—Ä—ñ–≥–∞—î —è–∫ **–ª–æ–∫–∞–ª—å–Ω—É**, —Ç–∞–∫ —ñ **–≥–ª–æ–±–∞–ª—å–Ω—É** —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–∏—Ö. –ü—ñ–¥—Ö–æ–¥–∏—Ç—å —è–∫ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó, —Ç–∞–∫ —ñ –¥–ª—è downstream ML tasks.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ –∑–≤'—è–∑–∫—ñ–≤ —É –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ, –ø–æ—Ç—ñ–º –æ–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ low-dimensional –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è —â–æ–± –∑–±–µ—Ä–µ–≥—Ç–∏ —Ü—é —Ç–æ–ø–æ–ª–æ–≥—ñ—á–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω?

- ‚ö° **–®–≤–∏–¥–∫—ñ—Å—Ç—å** ‚Äî 10-100x —à–≤–∏–¥—à–µ –∑–∞ t-SNE
- üé® **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** ‚Äî —á—É–¥–æ–≤—ñ 2D/3D –ø—Ä–æ–µ–∫—Ü—ñ—ó
- üîÑ **Downstream ML** ‚Äî –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è supervised learning
- üåç **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** ‚Äî –∑–±–µ—Ä—ñ–≥–∞—î –≤–µ–ª–∏–∫–æ–º–∞—Å—à—Ç–∞–±–Ω—ñ –ø–∞—Ç—Ç–µ—Ä–Ω–∏
- üéØ **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** ‚Äî —Ç–∞–∫–æ–∂ –∑–±–µ—Ä—ñ–≥–∞—î –±–ª–∏–∑—å–∫—ñ—Å—Ç—å
- üìä **–ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ—Å—Ç—å** ‚Äî –ø—Ä–∞—Ü—é—î –Ω–∞ –º—ñ–ª—å–π–æ–Ω–∞—Ö —Ç–æ—á–æ–∫
- üîß **–ì–Ω—É—á–∫—ñ—Å—Ç—å** ‚Äî custom metrics, supervised mode

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + downstream ML** ‚Äî —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –º–µ—Ç–æ–¥
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 10,000 —Ç–æ—á–æ–∫) ‚Äî —à–≤–∏–¥—à–µ –∑–∞ t-SNE
- **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** –≤–∞–∂–ª–∏–≤–∞ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏** ‚Äî —Å–∫–ª–∞–¥–Ω—ñ manifolds
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ **–Ω–æ–≤–∏–∑–Ω–∞** ‚Äî cutting-edge –º–µ—Ç–æ–¥
- **–†—ñ–∑–Ω—ñ —Ç–∏–ø–∏ –¥–∞–Ω–∏—Ö** ‚Äî —á–∏—Å–ª–æ–≤—ñ, –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ, –∑–º—ñ—à–∞–Ω—ñ

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Äî PCA –ø—Ä–æ—Å—Ç—ñ—à–∏–π
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤** –≤–∞–∂–ª–∏–≤–∞ ‚Üí PCA, LDA
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å** ‚Üí PCA (UMAP —á–∞—Å—Ç–∫–æ–≤–æ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∏–π)
- **–î—É–∂–µ –º–∞–ª—ñ –¥–∞–Ω—ñ** (< 100) ‚Äî t-SNE –º–æ–∂–µ –±—É—Ç–∏ –∫—Ä–∞—â–∏–º

---

## –Ø–∫ –ø—Ä–∞—Ü—é—î UMAP?

### –Ü–Ω—Ç—É—ó—Ü—ñ—è: –¢–æ–ø–æ–ª–æ–≥—ñ—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥

**–ö—Ä–æ–∫ 1:** –£—è–≤–∏ –¥–∞–Ω—ñ —è–∫ —Ç–æ—á–∫–∏ –Ω–∞ –¥–µ—Ñ–æ—Ä–º–æ–≤–∞–Ω–æ–º—É manifold (–ø–æ–≤–µ—Ä—Ö–Ω—ñ):

```
High-dimensional manifold:
    
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
   /       \
  ‚óè         ‚óè
   \       /
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    
–°–∫–ª–∞–¥–Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω—è
```

**–ö—Ä–æ–∫ 2:** –ü–æ–±—É–¥—É–π –≥—Ä–∞—Ñ –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤:

```
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    ‚îÇ\ ‚îÇ /‚îÇ
    ‚óè \‚óè/ ‚óè
    ‚îÇ /‚îÇ\ ‚îÇ
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    
Edges = –∑–≤'—è–∑–∫–∏
```

**–ö—Ä–æ–∫ 3:** –ó–Ω–∞–π–¥–∏ low-dimensional –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è, —â–æ –∑–±–µ—Ä—ñ–≥–∞—î —Ü—ñ –∑–≤'—è–∑–∫–∏:

```
2D projection:
    
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    ‚îÇ  ‚îÇ  ‚îÇ
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    ‚îÇ  ‚îÇ  ‚îÇ
    ‚óè‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚óè
    
–†–æ–∑–≥–æ—Ä–Ω—É—Ç–æ –∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –ø—Ä–æ—Ü–µ—Å

**–ï—Ç–∞–ø 1: High-dimensional graph**

–î–ª—è –∫–æ–∂–Ω–æ—ó —Ç–æ—á–∫–∏ $x_i$:
1. –ó–Ω–∞–π—Ç–∏ k –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤
2. –û–±—á–∏—Å–ª–∏—Ç–∏ –ª–æ–∫–∞–ª—å–Ω—É –º–µ—Ç—Ä–∏–∫—É –≤—ñ–¥—Å—Ç–∞–Ω—ñ
3. –°—Ç–≤–æ—Ä–∏—Ç–∏ fuzzy simplicial set (–Ω–µ—á—ñ—Ç–∫–∏–π –≥—Ä–∞—Ñ)

**–í–∞–≥–∞ —Ä–µ–±—Ä–∞:**
$$w_{ij} = \exp\left(-\frac{d(x_i, x_j) - \rho_i}{\sigma_i}\right)$$

–¥–µ:
- $\rho_i$ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—å –¥–æ –Ω–∞–π–±–ª–∏–∂—á–æ–≥–æ —Å—É—Å—ñ–¥–∞
- $\sigma_i$ ‚Äî –ª–æ–∫–∞–ª—å–Ω–∞ –º–∞—Å—à—Ç–∞–±—É—é—á–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞

**–ï—Ç–∞–ø 2: Low-dimensional optimization**

–ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ —Ä—ñ–∑–Ω–∏—Ü—é –º—ñ–∂ high-dim —Ç–∞ low-dim –≥—Ä–∞—Ñ–∞–º–∏:

$$CE = \sum_{ij} w_{ij}^{high} \log\frac{w_{ij}^{high}}{w_{ij}^{low}} + (1-w_{ij}^{high})\log\frac{1-w_{ij}^{high}}{1-w_{ij}^{low}}$$

**Low-dimensional –≤–∞–≥–∞:**
$$w_{ij}^{low} = \frac{1}{1 + a \|y_i - y_j\|_2^{2b}}$$

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:** Stochastic gradient descent

### –í—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤—ñ–¥ t-SNE

| –ê—Å–ø–µ–∫—Ç | t-SNE | UMAP |
|--------|-------|------|
| **–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ –æ—Å–Ω–æ–≤–∞** | –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ (KL-divergence) | –¢–æ–ø–æ–ª–æ–≥—ñ—è (cross-entropy) |
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | O(n¬≤) ‚Üí O(n log n) | O(n log n) |
| **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | ‚ùå –í—Ç—Ä–∞—á–∞—î—Ç—å—Å—è | ‚úÖ –ó–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è |
| **Transform –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö** | ‚ùå –ù–µ–º–∞—î | ‚úÖ –Ñ (.transform()) |
| **–î–ª—è ML tasks** | ‚ùå –ù—ñ | ‚úÖ –¢–∞–∫ |

---

## –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞

### Fuzzy Topological Representation

**High-dimensional fuzzy set:**

–î–ª—è —Ç–æ—á–∫–∏ $x_i$, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –∑–≤'—è–∑–∫—É –∑ $x_j$:

$$v_i(x_j) = \exp\left(-\frac{\max(0, d(x_i, x_j) - \rho_i)}{\sigma_i}\right)$$

–¥–µ:
- $\rho_i$ = –≤—ñ–¥—Å—Ç–∞–Ω—å –¥–æ 1-–≥–æ —Å—É—Å—ñ–¥–∞ (local connectivity)
- $\sigma_i$ –≤–∏–±–∏—Ä–∞—î—Ç—å—Å—è —á–µ—Ä–µ–∑ fixed perplexity

**–°–∏–º–µ—Ç—Ä–∏–∑–∞—Ü—ñ—è:**

$$w_{ij} = v_i(x_j) + v_j(x_i) - v_i(x_j) \cdot v_j(x_i)$$

### Low-dimensional –≤–∞–≥–∞

**–§—É–Ω–∫—Ü—ñ—è —Å—Ö–æ–∂–∞ –Ω–∞ t-—Ä–æ–∑–ø–æ–¥—ñ–ª:**

$$\psi(y_i, y_j) = \frac{1}{1 + a\|y_i - y_j\|^{2b}}$$

–¢–∏–ø–æ–≤–æ: $a \approx 1.58$, $b \approx 0.88$ (–ø—ñ–¥—ñ–±—Ä–∞–Ω—ñ –µ–º–ø—ñ—Ä–∏—á–Ω–æ)

### Cross-entropy loss

$$CE = \sum_{i,j} \left[w_{ij} \log\left(\frac{w_{ij}}{\psi_{ij}}\right) + (1-w_{ij})\log\left(\frac{1-w_{ij}}{1-\psi_{ij}}\right)\right]$$

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:**
- –ü–µ—Ä—à–∏–π —á–ª–µ–Ω: –ø—Ä–∏—Ç—è–≥—É—î –±–ª–∏–∑—å–∫—ñ —Ç–æ—á–∫–∏
- –î—Ä—É–≥–∏–π —á–ª–µ–Ω: –≤—ñ–¥—à—Ç–æ–≤—Ö—É—î –¥–∞–ª–µ–∫—ñ —Ç–æ—á–∫–∏

### Gradient

$$\nabla_{y_i} CE = \sum_j \left[2ab\|y_i - y_j\|^{2b-2}w_{ij}(y_i - y_j) - 2b(1-w_{ij})\frac{\psi_{ij}}{1+a\|y_i-y_j\|^{2b}}(y_i - y_j)\right]$$

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:** Stochastic gradient descent –∑ momentum

---

## –ü—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥: Iris Dataset

### –î–∞–Ω—ñ

Iris: 150 –∫–≤—ñ—Ç—ñ–≤, 4 features, 3 –≤–∏–¥–∏.

### –ö–æ–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
import umap

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
iris = load_iris()
X = iris.data
y = iris.target

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# UMAP
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=15,
    min_dist=0.1,
    random_state=42
)

X_umap = reducer.fit_transform(X_scaled)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(
    X_umap[:, 0], 
    X_umap[:, 1],
    c=y,
    cmap='viridis',
    s=50,
    alpha=0.7,
    edgecolors='black',
    linewidths=0.5
)
plt.colorbar(scatter, label='Species', ticks=[0, 1, 2])
plt.title('UMAP Projection of Iris Dataset', fontsize=14, fontweight='bold')
plt.xlabel('UMAP 1', fontsize=12)
plt.ylabel('UMAP 2', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç

```
UMAP 2D:
    
    Setosa
      ‚óè‚óè‚óè
       ‚óè‚óè
      ‚óè‚óè‚óè
    
        Versicolor
          ‚ñ†‚ñ†‚ñ†
           ‚ñ†‚ñ†
          ‚ñ†‚ñ†‚ñ†
    
              Virginica
                ‚ñ≤‚ñ≤‚ñ≤
                 ‚ñ≤‚ñ≤
                ‚ñ≤‚ñ≤‚ñ≤

–¢—Ä–∏ –≤–∏–¥–∏ —á—ñ—Ç–∫–æ —Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ!
```

---

## –°–∫–ª–∞–¥–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: MNIST

### –ó–∞–¥–∞—á–∞

MNIST: 70,000 —Ü–∏—Ñ—Ä, 784 features (28√ó28 –ø—ñ–∫—Å–µ–ª—ñ).

**–ú–µ—Ç–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ + —Å—Ç–≤–æ—Ä–∏—Ç–∏ features –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞.

### –ö–æ–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import umap
import time

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ MNIST
print("Loading MNIST...")
mnist = fetch_openml('mnist_784', version=1, parser='auto')
X = mnist.data.to_numpy()
y = mnist.target.to_numpy().astype(int)

# –ü—ñ–¥–º–Ω–æ–∂–∏–Ω–∞ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
n_samples = 10000
indices = np.random.RandomState(42).choice(len(X), n_samples, replace=False)
X_sample = X[indices]
y_sample = y[indices]

print(f"Using {n_samples} samples")
print(f"Original shape: {X_sample.shape}")

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_sample)

# UMAP
print("\nRunning UMAP...")
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=15,
    min_dist=0.1,
    metric='euclidean',
    random_state=42,
    verbose=True
)

start = time.time()
X_umap = reducer.fit_transform(X_scaled)
umap_time = time.time() - start

print(f"UMAP time: {umap_time:.2f}s")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(12, 10))
scatter = plt.scatter(
    X_umap[:, 0],
    X_umap[:, 1],
    c=y_sample,
    cmap='tab10',
    s=10,
    alpha=0.6
)
plt.colorbar(scatter, label='Digit', ticks=range(10))
plt.title('UMAP Visualization of MNIST', fontsize=14, fontweight='bold')
plt.xlabel('UMAP 1', fontsize=12)
plt.ylabel('UMAP 2', fontsize=12)
plt.grid(True, alpha=0.3)

# –î–æ–¥–∞—Ç–∏ labels
for digit in range(10):
    mask = y_sample == digit
    center = X_umap[mask].mean(axis=0)
    plt.annotate(
        str(digit),
        center,
        fontsize=16,
        fontweight='bold',
        color='white',
        bbox=dict(boxstyle='circle', facecolor='black', alpha=0.8)
    )

plt.tight_layout()
plt.show()
```

### –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥–ª—è ML

```python
# UMAP —è–∫ feature extraction –¥–ª—è classifier

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_sample, test_size=0.3, random_state=42
)

# UMAP –Ω–∞ train
reducer = umap.UMAP(n_components=50, random_state=42)
X_train_umap = reducer.fit_transform(X_train)

# Transform test (–Ω–∞ –≤—ñ–¥–º—ñ–Ω—É –≤—ñ–¥ t-SNE!)
X_test_umap = reducer.transform(X_test)

# Classifier –Ω–∞ UMAP features
print("\nTraining classifier on UMAP features...")
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train_umap, y_train)

# Predict
y_pred = clf.predict(X_test_umap)
accuracy_umap = accuracy_score(y_test, y_pred)

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ original features
clf_original = RandomForestClassifier(n_estimators=100, random_state=42)
clf_original.fit(X_train, y_train)
y_pred_original = clf_original.predict(X_test)
accuracy_original = accuracy_score(y_test, y_pred_original)

print(f"\n=== Classification Results ===")
print(f"Original features (784D): {accuracy_original:.4f}")
print(f"UMAP features (50D): {accuracy_umap:.4f}")
print(f"Dimension reduction: {784/50:.1f}x")
```

---

## –ö–æ–¥ (Python + umap-learn)

### –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

```bash
pip install umap-learn
```

### –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler
import umap

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
digits = load_digits()
X = digits.data  # (1797, 64)
y = digits.target

# Scaling (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# UMAP
reducer = umap.UMAP(
    n_components=2,       # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É
    n_neighbors=15,       # –õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (5-50)
    min_dist=0.1,         # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å (0.0-0.99)
    metric='euclidean',   # –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
    random_state=42
)

X_umap = reducer.fit_transform(X_scaled)

print(f"Original shape: {X.shape}")
print(f"UMAP shape: {X_umap.shape}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.7)
plt.colorbar(scatter, label='Digit', ticks=range(10))
plt.title('UMAP Projection', fontsize=14, fontweight='bold')
plt.xlabel('UMAP 1', fontsize=12)
plt.ylabel('UMAP 2', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### Transform –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (–∫–ª—é—á–æ–≤–∞ –ø–µ—Ä–µ–≤–∞–≥–∞!)

```python
# Fit –Ω–∞ train
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

reducer = umap.UMAP(n_components=2, random_state=42)
X_train_umap = reducer.fit_transform(X_train)

# Transform test (–ù–ê –í–Ü–î–ú–Ü–ù–£ –í–Ü–î t-SNE!)
X_test_umap = reducer.transform(X_test)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è train + test
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X_train_umap[:, 0], X_train_umap[:, 1], 
           c=y_train, cmap='tab10', s=20, alpha=0.6)
plt.title('Train Set', fontsize=13, fontweight='bold')
plt.xlabel('UMAP 1')
plt.ylabel('UMAP 2')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.scatter(X_test_umap[:, 0], X_test_umap[:, 1],
           c=y_test, cmap='tab10', s=20, alpha=0.6)
plt.title('Test Set (transformed)', fontsize=13, fontweight='bold')
plt.xlabel('UMAP 1')
plt.ylabel('UMAP 2')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è PCA, t-SNE, UMAP

```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
import time

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA
print("Running PCA...")
start = time.time()
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
time_pca = time.time() - start

# t-SNE
print("Running t-SNE...")
start = time.time()
tsne = TSNE(n_components=2, random_state=42, verbose=0)
X_tsne = tsne.fit_transform(X_scaled)
time_tsne = time.time() - start

# UMAP
print("Running UMAP...")
start = time.time()
reducer = umap.UMAP(n_components=2, random_state=42)
X_umap = reducer.fit_transform(X_scaled)
time_umap = time.time() - start

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# PCA
axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', s=15, alpha=0.6)
axes[0].set_title(f'PCA\nTime: {time_pca:.2f}s', fontsize=13, fontweight='bold')
axes[0].set_xlabel('PC1')
axes[0].set_ylabel('PC2')
axes[0].grid(True, alpha=0.3)

# t-SNE
axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=15, alpha=0.6)
axes[1].set_title(f't-SNE\nTime: {time_tsne:.2f}s', fontsize=13, fontweight='bold')
axes[1].set_xlabel('t-SNE 1')
axes[1].set_ylabel('t-SNE 2')
axes[1].grid(True, alpha=0.3)

# UMAP
scatter = axes[2].scatter(X_umap[:, 0], X_umap[:, 1], 
                         c=y, cmap='tab10', s=15, alpha=0.6)
axes[2].set_title(f'UMAP\nTime: {time_umap:.2f}s', fontsize=13, fontweight='bold')
axes[2].set_xlabel('UMAP 1')
axes[2].set_ylabel('UMAP 2')
axes[2].grid(True, alpha=0.3)

plt.colorbar(scatter, ax=axes, label='Digit', ticks=range(10))
plt.tight_layout()
plt.show()

print(f"\n=== Speed Comparison ===")
print(f"PCA: {time_pca:.2f}s (fastest, linear)")
print(f"UMAP: {time_umap:.2f}s (fast, nonlinear)")
print(f"t-SNE: {time_tsne:.2f}s (slow, nonlinear)")
print(f"\nUMAP is {time_tsne/time_umap:.1f}x faster than t-SNE!")
```

### –í–ø–ª–∏–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

```python
# n_neighbors: –ª–æ–∫–∞–ª—å–Ω–∞ vs –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
fig, axes = plt.subplots(2, 2, figsize=(14, 12))
axes = axes.ravel()

n_neighbors_values = [5, 15, 50, 100]

for idx, n_neighbors in enumerate(n_neighbors_values):
    print(f"Running UMAP with n_neighbors={n_neighbors}")
    
    reducer = umap.UMAP(
        n_components=2,
        n_neighbors=n_neighbors,
        min_dist=0.1,
        random_state=42
    )
    
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[idx].scatter(X_umap[:, 0], X_umap[:, 1],
                     c=y, cmap='tab10', s=15, alpha=0.6)
    axes[idx].set_title(f'n_neighbors = {n_neighbors}', 
                       fontsize=12, fontweight='bold')
    axes[idx].set_xlabel('UMAP 1')
    axes[idx].set_ylabel('UMAP 2')
    axes[idx].grid(True, alpha=0.3)

plt.suptitle('Effect of n_neighbors Parameter', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n=== n_neighbors Effects ===")
print("Low (5): Focus on very local structure")
print("Medium (15): Balanced (default, recommended)")
print("High (50-100): Focus on global structure")

# min_dist: —â—ñ–ª—å–Ω—ñ—Å—Ç—å vs —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω–Ω—è
fig, axes = plt.subplots(2, 2, figsize=(14, 12))
axes = axes.ravel()

min_dist_values = [0.0, 0.1, 0.5, 0.9]

for idx, min_dist in enumerate(min_dist_values):
    print(f"Running UMAP with min_dist={min_dist}")
    
    reducer = umap.UMAP(
        n_components=2,
        n_neighbors=15,
        min_dist=min_dist,
        random_state=42
    )
    
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[idx].scatter(X_umap[:, 0], X_umap[:, 1],
                     c=y, cmap='tab10', s=15, alpha=0.6)
    axes[idx].set_title(f'min_dist = {min_dist}', 
                       fontsize=12, fontweight='bold')
    axes[idx].set_xlabel('UMAP 1')
    axes[idx].set_ylabel('UMAP 2')
    axes[idx].grid(True, alpha=0.3)

plt.suptitle('Effect of min_dist Parameter', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n=== min_dist Effects ===")
print("0.0: Dense clusters, points can overlap")
print("0.1: Balanced (default)")
print("0.5-0.9: More spread out, better separation")
```

### Supervised UMAP

```python
# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ labels –¥–ª—è –∫—Ä–∞—â–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó

# Unsupervised
reducer_unsup = umap.UMAP(n_components=2, random_state=42)
X_umap_unsup = reducer_unsup.fit_transform(X_scaled)

# Supervised (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î y)
reducer_sup = umap.UMAP(n_components=2, random_state=42)
X_umap_sup = reducer_sup.fit_transform(X_scaled, y=y)

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

axes[0].scatter(X_umap_unsup[:, 0], X_umap_unsup[:, 1],
               c=y, cmap='tab10', s=15, alpha=0.6)
axes[0].set_title('Unsupervised UMAP', fontsize=13, fontweight='bold')
axes[0].set_xlabel('UMAP 1')
axes[0].set_ylabel('UMAP 2')
axes[0].grid(True, alpha=0.3)

scatter = axes[1].scatter(X_umap_sup[:, 0], X_umap_sup[:, 1],
                         c=y, cmap='tab10', s=15, alpha=0.6)
axes[1].set_title('Supervised UMAP (uses labels)', 
                 fontsize=13, fontweight='bold')
axes[1].set_xlabel('UMAP 1')
axes[1].set_ylabel('UMAP 2')
axes[1].grid(True, alpha=0.3)

plt.colorbar(scatter, ax=axes, label='Digit', ticks=range(10))
plt.tight_layout()
plt.show()

print("Supervised UMAP uses labels to create better separation!")
```

### Custom metrics

```python
# UMAP –ø—ñ–¥—Ç—Ä–∏–º—É—î –±–∞–≥–∞—Ç–æ –º–µ—Ç—Ä–∏–∫!

# Euclidean (default)
reducer_euclidean = umap.UMAP(metric='euclidean', random_state=42)

# Cosine (–¥–ª—è text data)
reducer_cosine = umap.UMAP(metric='cosine', random_state=42)

# Manhattan
reducer_manhattan = umap.UMAP(metric='manhattan', random_state=42)

# Hamming (–¥–ª—è binary data)
reducer_hamming = umap.UMAP(metric='hamming', random_state=42)

# Custom metric function
def custom_metric(x, y):
    return np.sum(np.abs(x - y))

reducer_custom = umap.UMAP(metric=custom_metric, random_state=42)

# Visualize different metrics
metrics = ['euclidean', 'cosine', 'manhattan']
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, metric in enumerate(metrics):
    reducer = umap.UMAP(metric=metric, random_state=42)
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[idx].scatter(X_umap[:, 0], X_umap[:, 1],
                     c=y, cmap='tab10', s=15, alpha=0.6)
    axes[idx].set_title(f'Metric: {metric}', fontsize=13, fontweight='bold')
    axes[idx].set_xlabel('UMAP 1')
    axes[idx].set_ylabel('UMAP 2')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ UMAP

### –û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
umap.UMAP(
    n_components=2,         # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É
    n_neighbors=15,         # –õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
    min_dist=0.1,           # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å
    metric='euclidean',     # –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
    random_state=None,      # –í—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
    n_epochs=None,          # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
    learning_rate=1.0,      # –®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
    init='spectral',        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
    verbose=False           # –ü–æ–∫–∞–∑—É–≤–∞—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å
)
```

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å | –¢–∏–ø–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó |
|----------|------|-----------------|--------------|
| **n_components** | –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É | 2, 3, 10-100 | 2 –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó, >2 –¥–ª—è ML |
| **n_neighbors** | –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤ | 5-100 | 15 (default), –±—ñ–ª—å—à–µ –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ—ó |
| **min_dist** | –ú—ñ–Ω. –≤—ñ–¥—Å—Ç–∞–Ω—å –≤ embedding | 0.0-0.99 | 0.1 (default), 0.0 –¥–ª—è —â—ñ–ª—å–Ω–∏—Ö |
| **metric** | –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ | 'euclidean', 'cosine', ... | –ó–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –¥–∞–Ω–∏—Ö |

### n_neighbors (–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π)

**–©–æ —Ü–µ:** –ë–∞–ª–∞–Ω—Å –º—ñ–∂ –ª–æ–∫–∞–ª—å–Ω–æ—é —Ç–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é.

**–í–ø–ª–∏–≤:**

```python
# Low n_neighbors (2-5): –¥—É–∂–µ –ª–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
reducer_local = umap.UMAP(n_neighbors=5)
# ‚Üí –ë–∞–≥–∞—Ç–æ –¥—Ä—ñ–±–Ω–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
# ‚Üí –õ–æ–∫–∞–ª—å–Ω—ñ –¥–µ—Ç–∞–ª—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è
# ‚Üí –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ –±—É—Ç–∏ —à—É–º–Ω–æ—é

# Medium n_neighbors (10-20): –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ
reducer_balanced = umap.UMAP(n_neighbors=15)  # ‚Üê –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
# ‚Üí –ë–∞–ª–∞–Ω—Å –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ—ó

# High n_neighbors (50-100): –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
reducer_global = umap.UMAP(n_neighbors=100)
# ‚Üí –ú–µ–Ω—à–µ –¥–µ—Ç–∞–ª–µ–π, –±—ñ–ª—å—à –≥–ª–∞–¥–∫–æ
# ‚Üí –§–æ–∫—É—Å –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
```

**–ü—Ä–∞–≤–∏–ª–æ:**
- **–ú–∞–ª—ñ –¥–∞–Ω—ñ** (< 1000): n_neighbors = 5-10
- **–°–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ** (1000-10000): n_neighbors = 15-30
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 10000): n_neighbors = 30-100

### min_dist

**–©–æ —Ü–µ:** –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–æ–∑–≤–æ–ª–µ–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏ –≤ embedding.

**–í–ø–ª–∏–≤:**

```python
# min_dist = 0.0: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —â—ñ–ª—å–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏
reducer_dense = umap.UMAP(min_dist=0.0)
# ‚Üí –¢–æ—á–∫–∏ –º–æ–∂—É—Ç—å –Ω–∞–∫–ª–∞–¥–∞—Ç–∏—Å—å
# ‚Üí –ß—ñ—Ç–∫—ñ –∫–æ–º–ø–∞–∫—Ç–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏
# ‚Üí –ö—Ä–∞—â–µ –¥–ª—è topology

# min_dist = 0.1: –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ
reducer_balanced = umap.UMAP(min_dist=0.1)  # ‚Üê –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
# ‚Üí –ü–æ–º—ñ—Ä–Ω–∞ —â—ñ–ª—å–Ω—ñ—Å—Ç—å

# min_dist = 0.5-0.99: —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω—ñ —Ç–æ—á–∫–∏
reducer_spread = umap.UMAP(min_dist=0.8)
# ‚Üí –ë—ñ–ª—å—à–µ –ø—Ä–æ—Å—Ç–æ—Ä—É –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏
# ‚Üí –õ–µ–≥—à–µ –±–∞—á–∏—Ç–∏ –æ–∫—Ä–µ–º—ñ points
```

**–ö–æ–ª–∏ —â–æ:**
- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤** ‚Üí min_dist = 0.0-0.1
- **–†–æ–∑–≥–ª—è–¥–∞—Ç–∏ –æ–∫—Ä–µ–º—ñ —Ç–æ—á–∫–∏** ‚Üí min_dist = 0.3-0.5
- **Downstream ML** ‚Üí min_dist = 0.1 (default)

### metric

**–î–æ—Å—Ç—É–ø–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏:**

| –ú–µ—Ç—Ä–∏–∫–∞ | –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è |
|---------|--------------|
| **euclidean** | –ß–∏—Å–ª–æ–≤—ñ features (default) |
| **manhattan** | Robust –¥–æ outliers |
| **cosine** | Text, high-dimensional sparse |
| **correlation** | Gene expression |
| **hamming** | Binary/categorical |
| **jaccard** | Set data |
| Custom function | –ë—É–¥—å-—è–∫–∞ –≤–ª–∞—Å–Ω–∞ |

---

## Supervised UMAP

### –©–æ —Ü–µ?

**Supervised UMAP** –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î labels (—è–∫—â–æ —î) –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∫–ª–∞—Å—ñ–≤.

### –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏

```python
# Unsupervised
reducer_unsup = umap.UMAP(n_components=2)
X_umap_unsup = reducer_unsup.fit_transform(X)

# Supervised (–ø–µ—Ä–µ–¥–∞–π y!)
reducer_sup = umap.UMAP(n_components=2)
X_umap_sup = reducer_sup.fit_transform(X, y=y)

# Semi-supervised (—á–∞—Å—Ç–∫–æ–≤–æ labeled)
# y –º—ñ—Å—Ç–∏—Ç—å -1 –¥–ª—è unlabeled points
y_partial = y.copy()
y_partial[np.random.rand(len(y)) < 0.5] = -1

reducer_semi = umap.UMAP(n_components=2)
X_umap_semi = reducer_semi.fit_transform(X, y=y_partial)
```

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

```python
from sklearn.metrics import silhouette_score

# Unsupervised
sil_unsup = silhouette_score(X_umap_unsup, y)

# Supervised
sil_sup = silhouette_score(X_umap_sup, y)

print(f"Unsupervised Silhouette: {sil_unsup:.4f}")
print(f"Supervised Silhouette: {sil_sup:.4f}")
print(f"Improvement: {(sil_sup - sil_unsup)/sil_unsup*100:.1f}%")
```

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- ‚úÖ –Ñ partial labels (semi-supervised)
- ‚úÖ –•–æ—á–µ—à –∫—Ä–∞—â–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∫–ª–∞—Å—ñ–≤
- ‚úÖ Classification task downstream

**–ö–æ–ª–∏ –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- ‚ùå Unsupervised clustering (–Ω–µ–º–∞—î labels)
- ‚ùå Exploratory analysis (–º–æ–∂–µ bias results)

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ü–µ—Ä–µ–≤–∞–≥–∏ ‚úì

| –ü–µ—Ä–µ–≤–∞–≥–∞ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|----------|-----------|
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | 10-100x —à–≤–∏–¥—à–µ –∑–∞ t-SNE |
| **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | –ó–±–µ—Ä—ñ–≥–∞—î –≤—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ |
| **Transform –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö** | –Ñ .transform() –º–µ—Ç–æ–¥! |
| **–î–ª—è ML tasks** | –ú–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è supervised learning |
| **–ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ—Å—Ç—å** | –ü—Ä–∞—Ü—é—î –Ω–∞ –º—ñ–ª—å–π–æ–Ω–∞—Ö —Ç–æ—á–æ–∫ |
| **–ì–Ω—É—á–∫—ñ—Å—Ç—å** | Custom metrics, supervised mode |
| **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | –¢–∞–∫–æ–∂ –∑–±–µ—Ä—ñ–≥–∞—î –±–ª–∏–∑—å–∫—ñ—Å—Ç—å |

### –ù–µ–¥–æ–ª—ñ–∫–∏ ‚úó

| –ù–µ–¥–æ–ª—ñ–∫ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|---------|-----------|
| **–°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω—ñ—Å—Ç—å** | –¢—Ä–æ—Ö–∏ —Ä—ñ–∑–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ –∫–æ–∂–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É |
| **–ù–æ–≤—ñ—à–∏–π –º–µ—Ç–æ–¥** | –ú–µ–Ω—à–µ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π —á–∞—Å–æ–º –Ω—ñ–∂ PCA/t-SNE |
| **–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å** | –°–∫–ª–∞–¥–Ω—ñ—à–µ –∑—Ä–æ–∑—É–º—ñ—Ç–∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫—É |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤** | n_neighbors –≤–ø–ª–∏–≤–∞—î –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç |
| **–û—Å—ñ –±–µ–∑ –∑–Ω–∞—á–µ–Ω–Ω—è** | –Ø–∫ t-SNE, –Ω–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–Ω—ñ |
| **–ü–æ—Ç—Ä–µ–±—É—î tuning** | –¢—Ä–µ–±–∞ –ø—ñ–¥–±–∏—Ä–∞—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ |

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏

### –î–µ—Ç–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è

| –ö—Ä–∏—Ç–µ—Ä—ñ–π | PCA | t-SNE | UMAP | LDA |
|----------|-----|-------|------|-----|
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **–õ–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **–î–ª—è ML** | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ |
| **Transform test** | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ |
| **–î–µ—Ç–µ—Ä–º—ñ–Ω—ñ–∑–º** | ‚úÖ | ‚ùå | ‚ö†Ô∏è | ‚úÖ |
| **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω—ñ—Å—Ç—å** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

### UMAP vs t-SNE (–¥–µ—Ç–∞–ª—å–Ω–æ)

**UMAP –ø–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –ù–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ (10-100x)
- ‚úÖ –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- ‚úÖ .transform() –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
- ‚úÖ –ú–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è ML
- ‚úÖ –ú–∞—Å—à—Ç–∞–±—É—î—Ç—å—Å—è –∫—Ä–∞—â–µ

**t-SNE –ø–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –ë—ñ–ª—å—à –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π —á–∞—Å–æ–º
- ‚úÖ –¢—Ä–æ—Ö–∏ –∫—Ä–∞—â–∞ –ª–æ–∫–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- ‚úÖ –ë—ñ–ª—å—à–µ –º–∞—Ç–µ—Ä—ñ–∞–ª—ñ–≤ —Ç–∞ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:**
- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è:** —Å–ø—Ä–æ–±—É–π –æ–±–∏–¥–≤–∞, UMAP —á–∞—Å—Ç—ñ—à–µ –∫—Ä–∞—â–µ
- **ML preprocessing:** —Ç—ñ–ª—å–∫–∏ UMAP
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ:** —Ç—ñ–ª—å–∫–∏ UMAP
- **–ü—É–±–ª—ñ–∫–∞—Ü—ñ—è:** –º–æ–∂–Ω–∞ –ø–æ–∫–∞–∑–∞—Ç–∏ –æ–±–∏–¥–≤–∞ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

---

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ UMAP

### –Ü–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å ‚úì

- **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + downstream ML** ‚Äî —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π
- **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ** (> 10,000 —Ç–æ—á–æ–∫) ‚Äî —à–≤–∏–¥—à–µ –∑–∞ t-SNE
- **–ü–æ—Ç—Ä—ñ–±–µ–Ω .transform()** ‚Äî –Ω–æ–≤—ñ –¥–∞–Ω—ñ
- **–ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** –≤–∞–∂–ª–∏–≤–∞ ‚Äî –≤—ñ–¥—Å—Ç–∞–Ω—ñ –º—ñ–∂ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞** ‚Äî –Ω–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ t-SNE
- **Custom metrics** ‚Äî text, graphs, —Ç–æ—â–æ
- **Semi-supervised** ‚Äî —î —á–∞—Å—Ç–∫–æ–≤–æ labeled –¥–∞–Ω—ñ

### –ö—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à–µ ‚úó

- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –æ—Å–µ–π** ‚Üí PCA, LDA
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å** ‚Üí PCA
- **–õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ** ‚Üí PCA —à–≤–∏–¥—à–µ —Ç–∞ –ø—Ä–æ—Å—Ç—ñ—à–µ
- **–î—É–∂–µ –º–∞–ª—ñ –¥–∞–Ω—ñ** (< 100) ‚Üí t-SNE –º–æ–∂–µ –±—É—Ç–∏ –∫—Ä–∞—â–∏–º
- **–ü–æ—Ç—Ä—ñ–±–Ω—ñ —Ç–æ—á–Ω—ñ probability scores** ‚Üí t-SNE

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ü–æ—á–Ω–∏ –∑ default –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

```python
# ‚úÖ Default –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–æ–±—Ä—ñ –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –≤–∏–ø–∞–¥–∫—ñ–≤
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=15,
    min_dist=0.1
)
```

### 2. –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π –∑ n_neighbors

```python
# –°–ø—Ä–æ–±—É–π 3-5 –∑–Ω–∞—á–µ–Ω—å
for n_neighbors in [5, 15, 30, 100]:
    reducer = umap.UMAP(n_neighbors=n_neighbors)
    X_umap = reducer.fit_transform(X)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–π
    plt.figure()
    plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y)
    plt.title(f'n_neighbors = {n_neighbors}')
    plt.show()
```

### 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π supervised —è–∫—â–æ —î labels

```python
# –Ø–∫—â–æ —î labels –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
reducer = umap.UMAP(n_components=2)
X_umap = reducer.fit_transform(X, y=y)  # ‚Üê –ü–µ—Ä–µ–¥–∞–π y!
```

### 4. Scaling –¥–ª—è —á–∏—Å–ª–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

```python
# –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ (—Ö–æ—á–∞ UMAP –º–µ–Ω—à —á—É—Ç–ª–∏–≤–∏–π –Ω—ñ–∂ PCA)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

reducer = umap.UMAP()
X_umap = reducer.fit_transform(X_scaled)
```

### 5. –ü—ñ–¥–±–∏—Ä–∞–π metric –¥–æ —Ç–∏–ø—É –¥–∞–Ω–∏—Ö

```python
# Euclidean –¥–ª—è —á–∏—Å–ª–æ–≤–∏—Ö
reducer_num = umap.UMAP(metric='euclidean')

# Cosine –¥–ª—è text/TF-IDF
reducer_text = umap.UMAP(metric='cosine')

# Hamming –¥–ª—è binary
reducer_bin = umap.UMAP(metric='hamming')
```

### 6. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥–ª—è preprocessing –ø–µ—Ä–µ–¥ ML

```python
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

# Pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('umap', umap.UMAP(n_components=20)),
    ('classifier', RandomForestClassifier())
])

pipeline.fit(X_train, y_train)
score = pipeline.score(X_test, y_test)
```

### 7. min_dist –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –∑–∞–¥–∞—á—ñ

```python
# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ ‚Üí 0.0-0.1 (—â—ñ–ª—å–Ω—ñ)
reducer_vis = umap.UMAP(min_dist=0.0)

# –†–æ–∑–≥–ª—è–¥–∞—Ç–∏ –æ–∫—Ä–µ–º—ñ —Ç–æ—á–∫–∏ ‚Üí 0.3-0.5
reducer_points = umap.UMAP(min_dist=0.4)

# ML tasks ‚Üí 0.1 (default)
reducer_ml = umap.UMAP(min_dist=0.1)
```

### 8. –ó–±–µ—Ä—ñ–≥–∞–π trained model

```python
import pickle

# –ó–±–µ—Ä–µ–≥—Ç–∏
with open('umap_model.pkl', 'wb') as f:
    pickle.dump(reducer, f)

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏
with open('umap_model.pkl', 'rb') as f:
    reducer = pickle.load(f)

# Transform –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
X_new_umap = reducer.transform(X_new)
```

### 9. –ü–µ—Ä–µ–≤—ñ—Ä—è–π –∫—ñ–ª—å–∫–∞ random_state

```python
# UMAP —á–∞—Å—Ç–∫–æ–≤–æ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∏–π
results = []

for seed in range(5):
    reducer = umap.UMAP(random_state=seed)
    X_umap = reducer.fit_transform(X)
    
    # –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
    score = silhouette_score(X_umap, y)
    results.append((seed, score, X_umap))

# –í–∏–±–µ—Ä–∏ –Ω–∞–π–∫—Ä–∞—â–∏–π
best_seed, best_score, best_X_umap = max(results, key=lambda x: x[1])
print(f"Best random_state: {best_seed} (score: {best_score:.4f})")
```

### 10. –í—ñ–∑—É–∞–ª—ñ–∑—É–π —ñ —è–∫—ñ—Å–Ω–æ –æ—Ü—ñ–Ω–∏

```python
# –ù–µ –ø–æ–∫–ª–∞–¥–∞–π—Å—è —Ç—ñ–ª—å–∫–∏ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏!
# –ü–æ–¥–∏–≤–∏—Å—å –≤—ñ–∑—É–∞–ª—å–Ω–æ —á–∏ –º–∞—î —Å–µ–Ω—Å

plt.figure(figsize=(12, 10))
scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
plt.colorbar(scatter)
plt.title('UMAP Visualization')
plt.show()

# –ó–∞–ø–∏—Ç–∞–π —Å–µ–±–µ:
# - –ß–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏ –º–∞—é—Ç—å —Å–µ–Ω—Å?
# - –ß–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î domain knowledge?
# - –ß–∏ —î –Ω–µ—Å–ø–æ–¥—ñ–≤–∞–Ω—ñ –ø–∞—Ç—Ç–µ—Ä–Ω–∏?
```

---

## –†–µ–∞–ª—å–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

### 1. Single-cell RNA-seq Analysis

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –∫–ª—ñ—Ç–∏–Ω–∏ –∑–∞ –µ–∫—Å–ø—Ä–µ—Å—ñ—î—é –≥–µ–Ω—ñ–≤.

**–î–∞–Ω—ñ:**
- 50,000 –∫–ª—ñ—Ç–∏–Ω √ó 20,000 –≥–µ–Ω—ñ–≤
- –î—É–∂–µ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ, —Ä–æ–∑—Ä—ñ–¥–∂–µ–Ω—ñ

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. Preprocessing
# Normalize, log-transform

# 2. Feature selection (top variable genes)
from sklearn.feature_selection import SelectKBest
selector = SelectKBest(k=2000)
X_selected = selector.fit_transform(gene_expression, cell_types)

# 3. UMAP
reducer = umap.UMAP(
    n_neighbors=30,
    min_dist=0.3,
    metric='correlation',  # –î–ª—è gene expression
    random_state=42
)

cell_umap = reducer.fit_transform(X_selected)

# 4. Clustering –Ω–∞ UMAP space
from sklearn.cluster import HDBSCAN
clusterer = HDBSCAN(min_cluster_size=50)
clusters = clusterer.fit_predict(cell_umap)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(cell_umap[:, 0], cell_umap[:, 1], 
           c=clusters, cmap='tab20', s=1)
plt.title('Cell Types (UMAP)')
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –í–∏—è–≤–ª–µ–Ω–Ω—è —Ç–∏–ø—ñ–≤ –∫–ª—ñ—Ç–∏–Ω
- –¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–∞—Ü—ñ—ó
- –†—ñ–¥–∫—ñ—Å–Ω—ñ –ø–æ–ø—É–ª—è—Ü—ñ—ó

### 2. Text Document Clustering

**–ó–∞–¥–∞—á–∞:** –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏.

**–î–∞–Ω—ñ:**
- 100,000 –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
- TF-IDF vectors (10,000D)

**–ü—ñ–¥—Ö—ñ–¥:**
```python
from sklearn.feature_extraction.text import TfidfVectorizer

# 1. TF-IDF vectorization
vectorizer = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer.fit_transform(documents)

# 2. UMAP –∑ cosine metric
reducer = umap.UMAP(
    n_neighbors=15,
    min_dist=0.1,
    metric='cosine',  # ‚Üê –í–∞–∂–ª–∏–≤–æ –¥–ª—è text!
    random_state=42
)

doc_umap = reducer.fit_transform(X_tfidf)

# 3. Clustering
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=20)
topics = kmeans.fit_predict(doc_umap)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(doc_umap[:, 0], doc_umap[:, 1], 
           c=topics, cmap='tab20', s=5, alpha=0.5)
plt.title('Document Topics (UMAP)')
```

### 3. Recommendation Systems

**–ó–∞–¥–∞—á–∞:** Embedding –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤/—Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# User-item interaction matrix
# (sparse, high-dimensional)

# UMAP embedding
reducer_users = umap.UMAP(
    n_components=50,  # ‚Üê –ù–µ —Ç—ñ–ª—å–∫–∏ 2D!
    n_neighbors=20,
    metric='cosine'
)

user_embeddings = reducer_users.fit_transform(user_item_matrix)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ embeddings –¥–ª—è nearest neighbors
from sklearn.neighbors import NearestNeighbors

nn = NearestNeighbors(n_neighbors=10, metric='cosine')
nn.fit(user_embeddings)

# –ó–Ω–∞–π—Ç–∏ —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
distances, indices = nn.kneighbors([user_embeddings[user_id]])
similar_users = indices[0]

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑ —ó—Ö–Ω—ñ—Ö —É–ø–æ–¥–æ–±–∞–Ω—å
```

### 4. Image Similarity Search

**–ó–∞–¥–∞—á–∞:** –ù–∞–≤—ñ–≥–∞—Ü—ñ—è –ø–æ –≤–µ–ª–∏–∫—ñ–π –∫–æ–ª–µ–∫—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. CNN features (ResNet, VGG)
from torchvision import models
resnet = models.resnet50(pretrained=True)
# Extract features: (n_images, 2048)

# 2. UMAP –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É
reducer = umap.UMAP(
    n_components=128,  # –ó–º–µ–Ω—à–∏—Ç–∏ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
    n_neighbors=15,
    metric='cosine'
)

image_embeddings = reducer.fit_transform(cnn_features)

# 3. Approximate nearest neighbors (–¥–ª—è –º—ñ–ª—å–π–æ–Ω—ñ–≤)
from annoy import AnnoyIndex

index = AnnoyIndex(128, 'angular')
for i, emb in enumerate(image_embeddings):
    index.add_item(i, emb)
index.build(10)

# 4. –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å
similar_images = index.get_nns_by_item(image_id, 10)
```

### 5. Fraud Detection

**–ó–∞–¥–∞—á–∞:** –í–∏—è–≤–∏—Ç–∏ –∞–Ω–æ–º–∞–ª—å–Ω—ñ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó.

**–ü—ñ–¥—Ö—ñ–¥:**
```python
# 1. Features: amount, time, location, merchant, etc.
X_scaled = scaler.fit_transform(transaction_features)

# 2. UMAP embedding
reducer = umap.UMAP(n_components=2, random_state=42)
trans_umap = reducer.fit_transform(X_scaled)

# 3. Density-based outlier detection
from sklearn.neighbors import LocalOutlierFactor

lof = LocalOutlierFactor(n_neighbors=20)
outlier_labels = lof.fit_predict(trans_umap)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(trans_umap[:, 0], trans_umap[:, 1],
           c=(outlier_labels == -1), cmap='RdYlGn',
           s=10, alpha=0.5)
plt.title('Fraud Detection (UMAP)')
# Outliers = potential fraud
```

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –ù–µ –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
# ‚ùå –ó–∞–≤–∂–¥–∏ default –±–µ–∑ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤
reducer = umap.UMAP()
X_umap = reducer.fit_transform(X)

# ‚úÖ –°–ø—Ä–æ–±—É–π —Ä—ñ–∑–Ω—ñ n_neighbors —Ç–∞ min_dist
for n_neighbors in [5, 15, 50]:
    for min_dist in [0.0, 0.1, 0.5]:
        reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist)
        # –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–π
```

### 2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ç–∏–ø—É –¥–∞–Ω–∏—Ö

```python
# ‚ùå Euclidean –¥–ª—è text/TF-IDF
reducer = umap.UMAP(metric='euclidean')
X_umap = reducer.fit_transform(tfidf_matrix)

# ‚úÖ Cosine –¥–ª—è sparse text
reducer = umap.UMAP(metric='cosine')
X_umap = reducer.fit_transform(tfidf_matrix)
```

### 3. Fit –Ω–∞ –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö (train+test)

```python
# ‚ùå DATA LEAKAGE
X_all = np.vstack([X_train, X_test])
reducer = umap.UMAP()
reducer.fit(X_all)  # ‚Üê Leakage!

# ‚úÖ Fit —Ç—ñ–ª—å–∫–∏ –Ω–∞ train
reducer = umap.UMAP()
reducer.fit(X_train)

X_train_umap = reducer.transform(X_train)
X_test_umap = reducer.transform(X_test)
```

### 4. –ó–∞–±—É—Ç–∏ –ø—Ä–æ scaling

```python
# ‚ùå –ë–µ–∑ scaling (–æ—Å–æ–±–ª–∏–≤–æ –¥–ª—è euclidean)
reducer = umap.UMAP(metric='euclidean')
X_umap = reducer.fit_transform(X)

# ‚úÖ –ó—ñ scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_umap = reducer.fit_transform(X_scaled)
```

### 5. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –æ—Å—ñ

```python
# ‚ùå "UMAP axis 1 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—î..."
# –û—Å—ñ –Ω–µ –º–∞—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è!

# ‚úÖ "–ö–ª–∞—Å—Ç–µ—Ä–∏ –ø–æ–∫–∞–∑—É—é—Ç—å..."
# –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–π —Ç—ñ–ª—å–∫–∏ –≥—Ä—É–ø–∏ —Ç–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ
```

### 6. –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ supervised —è–∫—â–æ —î labels

```python
# ‚ùå Unsupervised –∫–æ–ª–∏ —î labels
reducer = umap.UMAP()
X_umap = reducer.fit_transform(X)

# ‚úÖ Supervised –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
reducer = umap.UMAP()
X_umap = reducer.fit_transform(X, y=y)
```

### 7. –ó–∞–Ω–∞–¥—Ç–æ –º–∞–ª–æ n_neighbors –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö

```python
# ‚ùå n_neighbors=5 –¥–ª—è 100,000 —Ç–æ—á–æ–∫
# –í—Ç—Ä–∞—á–∞—î—Ç—å—Å—è –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

# ‚úÖ –ó–±—ñ–ª—å—à –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
n_neighbors = min(100, len(X) // 100)
reducer = umap.UMAP(n_neighbors=n_neighbors)
```

### 8. –ù–µ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ trained model

```python
# ‚ùå Fit –∑–Ω–æ–≤—É –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
reducer = umap.UMAP()
reducer.fit(X_new)  # –í—Ç—Ä–∞—á–∞—î consistency!

# ‚úÖ Transform –Ω–∞ –≤–∂–µ fitted model
X_new_umap = reducer.transform(X_new)
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_PCA]] ‚Äî –ª—ñ–Ω—ñ–π–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- [[02_t-SNE]] ‚Äî –ø–æ–ø–µ—Ä–µ–¥–Ω–∏–∫ UMAP
- [[04_LDA]] ‚Äî supervised reduction
- [[05_Autoencoders]] ‚Äî neural network approach
- [[06_Manifold_Learning]] ‚Äî —ñ–Ω—à—ñ –º–µ—Ç–æ–¥–∏
- [[Clustering_Methods]] ‚Äî –¥–ª—è downstream tasks

## –†–µ—Å—É—Ä—Å–∏

- [UMAP Documentation](https://umap-learn.readthedocs.io/)
- [Original Paper: McInnes et al. (2018)](https://arxiv.org/abs/1802.03426)
- [Understanding UMAP (Andy Coenen & Adam Pearce)](https://pair-code.github.io/understanding-umap/)
- [How UMAP Works (Leland McInnes)](https://www.youtube.com/watch?v=nq6iPZVUxZU)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> UMAP ‚Äî —Ü–µ —à–≤–∏–¥–∫–∏–π –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º dimensionality reduction –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–æ–ø–æ–ª–æ–≥—ñ—ó, —è–∫–∏–π –∑–±–µ—Ä—ñ–≥–∞—î —è–∫ –ª–æ–∫–∞–ª—å–Ω—É —Ç–∞–∫ —ñ –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ downstream ML tasks.

**–û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–∏–Ω—Ü–∏–ø–∏:**
- **–¢–æ–ø–æ–ª–æ–≥—ñ—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥:** –≥—Ä–∞—Ñ —Å—É—Å—ñ–¥—Å—Ç–≤–∞ ‚Üí optimization
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å:** 10-100x —à–≤–∏–¥—à–µ –∑–∞ t-SNE
- **–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ—Å—Ç—å:** –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + ML + transform
- **–ë–∞–ª–∞–Ω—Å:** –ª–æ–∫–∞–ª—å–Ω–∞ + –≥–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. –ü–æ–±—É–¥—É–≤–∞—Ç–∏ fuzzy simplicial set (–≥—Ä–∞—Ñ) —É high-dim
2. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ low-dim –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
3. –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ cross-entropy –º—ñ–∂ –≥—Ä–∞—Ñ–∞–º–∏
4. Stochastic gradient descent

**–ö–ª—é—á–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- **n_neighbors** (15 default) ‚Äî –±–∞–ª–∞–Ω—Å –ª–æ–∫–∞–ª—å–Ω–æ—ó/–≥–ª–æ–±–∞–ª—å–Ω–æ—ó
- **min_dist** (0.1 default) ‚Äî —â—ñ–ª—å–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
- **metric** ‚Äî –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —Ç–∏–ø—É –¥–∞–Ω–∏—Ö
- **supervised mode** ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π labels —è–∫—â–æ —î

**–ü–µ—Ä–µ–≤–∞–≥–∏ –Ω–∞–¥ t-SNE:**
- ‚ö° –ù–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ
- üåç –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- üîÑ –Ñ .transform() –º–µ—Ç–æ–¥
- üìä –î–ª—è ML tasks

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + ML + –≤–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ = UMAP ‚úì
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üí UMAP ‚úì
- –¢—ñ–ª—å–∫–∏ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è + –º–∞–ª—ñ –¥–∞–Ω—ñ ‚Üí t-SNE —Ç–µ–∂ OK
- –õ—ñ–Ω—ñ–π–Ω—ñ –¥–∞–Ω—ñ ‚Üí PCA –ø—Ä–æ—Å—Ç—ñ—à–µ ‚úì

**–ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–µ:**
- **Default –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–æ–±—Ä—ñ** ‚Äî –ø–æ—á–Ω–∏ –∑ –Ω–∏—Ö
- **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π –∑ n_neighbors** ‚Äî –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä
- **–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π supervised** —è–∫—â–æ —î labels
- **–ü—Ä–∞–≤–∏–ª—å–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞** –¥–ª—è —Ç–∏–ø—É –¥–∞–Ω–∏—Ö
- **–ú–∞—Å—à—Ç–∞–±—É—î—Ç—å—Å—è** –Ω–∞ –º—ñ–ª—å–π–æ–Ω–∏ —Ç–æ—á–æ–∫
- **.transform()** –ø—Ä–∞—Ü—é—î –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö!

---

#ml #unsupervised-learning #dimensionality-reduction #umap #visualization #manifold-learning #nonlinear #topology #fast
