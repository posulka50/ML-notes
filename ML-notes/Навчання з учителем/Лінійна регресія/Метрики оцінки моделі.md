
Метрики оцінки моделі дозволяють **кількісно виміряти, наскільки добре модель передбачає цільову змінну**.  
Вибір метрики залежить від типу задачі та характеру даних.

---

## 1️⃣ MSE (Mean Squared Error)

- Середня квадратична помилка.
- Формула:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

- Інтуїція: карає великі помилки сильніше (квадрат).  
- Використовується для регресії.

---

## 2️⃣ RMSE (Root Mean Squared Error)

- Квадратний корінь із MSE.
- Формула:

$$
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$

- Інтерпретується в **тій же шкалі, що й y**.  
- Зручна для порівняння моделей.

---

## 3️⃣ MAE (Mean Absolute Error)

- Середня абсолютна помилка.
- Формула:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

- Карає великі помилки менш суворо, ніж MSE.  
- Більш **робастна до викидів**.

---

## 4️⃣ R² (Коефіцієнт детермінації)

- Відображає, яку частку дисперсії цільової змінної пояснює модель.
- Формула:

$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

- Значення: 0 → модель не краще середнього, 1 → ідеальна модель.  
- Може бути **від’ємним**, якщо модель гірша за константне середнє.

---

## 5️⃣ Adjusted R² (скоригований R²)

- Враховує кількість ознак, щоб **не переоцінювати модель** при збільшенні числа змінних.
- Формула:

$$
\bar{R}^2 = 1 - \left(1 - R^2\right) \frac{n-1}{n-p-1}
$$

- n — кількість спостережень, p — кількість ознак.  

---

## Інтуїція

- MSE / RMSE → чутливі до великих помилок  
- MAE → більш стабільна при викидах  
- R² → наскільки модель пояснює варіацію даних  
- Adjusted R² → контроль за кількістю ознак

---

## Застосування

- **Регресія** (цільова змінна числова)  
- Порівняння моделей  
- Налаштування гіперпараметрів через cross-validation

---
