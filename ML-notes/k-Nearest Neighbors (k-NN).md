## –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è

**k-Nearest Neighbors (k-NN)** ‚Äî —Ü–µ –ø—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è, —è–∫–∏–π –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—î –æ–±'—î–∫—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª–∞—Å—ñ–≤ –π–æ–≥–æ k –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤ —É –ø—Ä–æ—Å—Ç–æ—Ä—ñ –æ–∑–Ω–∞–∫.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** "–°–∫–∞–∂–∏ –º–µ–Ω—ñ, —Ö—Ç–æ —Ç–≤—ñ–π —Å—É—Å—ñ–¥, —ñ —è —Å–∫–∞–∂—É, —Ö—Ç–æ —Ç–∏" ‚Äî –æ–±'—î–∫—Ç –Ω–∞–ª–µ–∂–∏—Ç—å –¥–æ —Ç–æ–≥–æ –∫–ª–∞—Å—É, —è–∫–∏–π –Ω–∞–π—á–∞—Å—Ç—ñ—à–µ –∑—É—Å—Ç—Ä—ñ—á–∞—î—Ç—å—Å—è —Å–µ—Ä–µ–¥ –π–æ–≥–æ k –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤.

## –ü—Ä–∏–Ω—Ü–∏–ø —Ä–æ–±–æ—Ç–∏

### –ê–ª–≥–æ—Ä–∏—Ç–º

1. **–í–∏–±—Ä–∞—Ç–∏ k** (–∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤)
2. **–û–±—á–∏—Å–ª–∏—Ç–∏ –≤—ñ–¥—Å—Ç–∞–Ω—å** –≤—ñ–¥ –Ω–æ–≤–æ–≥–æ –æ–±'—î–∫—Ç–∞ –¥–æ –≤—Å—ñ—Ö –æ–±'—î–∫—Ç—ñ–≤ —É –Ω–∞–≤—á–∞–ª—å–Ω—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ
3. **–ó–Ω–∞–π—Ç–∏ k –Ω–∞–π–±–ª–∏–∂—á–∏—Ö** —Å—É—Å—ñ–¥—ñ–≤
4. **–î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:** –í–∏–∑–Ω–∞—á–∏—Ç–∏ –∫–ª–∞—Å –∑–∞ –≥–æ–ª–æ—Å—É–≤–∞–Ω–Ω—è–º –±—ñ–ª—å—à–æ—Å—Ç—ñ
5. **–î–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó:** –û–±—á–∏—Å–ª–∏—Ç–∏ —Å–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
```
        ‚óã –ö–ª–∞—Å A
        ‚óè –ö–ª–∞—Å B
        ‚òÖ –ù–æ–≤–∏–π –æ–±'—î–∫—Ç

     ‚óã     ‚óã
       ‚óã ‚òÖ ‚óè
     ‚óã   ‚óè ‚óè
       ‚óè   ‚óè

k=3: –ù–∞–π–±–ª–∏–∂—á—ñ —Å—É—Å—ñ–¥–∏: ‚óè‚óè‚óã
     ‚Üí –ö–ª–∞—Å B (2 –≥–æ–ª–æ—Å–∏ vs 1)

k=5: –ù–∞–π–±–ª–∏–∂—á—ñ —Å—É—Å—ñ–¥–∏: ‚óè‚óè‚óè‚óã‚óã
     ‚Üí –ö–ª–∞—Å B (3 –≥–æ–ª–æ—Å–∏ vs 2)
```

## –ú–µ—Ç—Ä–∏–∫–∏ –≤—ñ–¥—Å—Ç–∞–Ω—ñ

### 1. Euclidean Distance (–ï–≤–∫–ª—ñ–¥–æ–≤–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å)
**–ù–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∞ –º–µ—Ç—Ä–∏–∫–∞**

$$d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}$$

**–ü—Ä–∏–∫–ª–∞–¥:**
```python
x = [1, 2]
y = [4, 6]
d = sqrt((1-4)¬≤ + (2-6)¬≤) = sqrt(9 + 16) = 5
```

### 2. Manhattan Distance (–ú–∞–Ω—Ö–µ—Ç—Ç–µ–Ω—Å—å–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å)
**"–í—ñ–¥—Å—Ç–∞–Ω—å —Ç–∞–∫—Å—ñ"**

$$d(x, y) = \sum_{i=1}^{n}|x_i - y_i|$$

**–ü—Ä–∏–∫–ª–∞–¥:**
```python
x = [1, 2]
y = [4, 6]
d = |1-4| + |2-6| = 3 + 4 = 7
```

### 3. Minkowski Distance (–í—ñ–¥—Å—Ç–∞–Ω—å –ú—ñ–Ω–∫–æ–≤—Å—å–∫–æ–≥–æ)
**–£–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö**

$$d(x, y) = \left(\sum_{i=1}^{n}|x_i - y_i|^p\right)^{1/p}$$

- p=1 ‚Üí Manhattan
- p=2 ‚Üí Euclidean
- p=‚àû ‚Üí Chebyshev

### 4. Cosine Similarity (–ö–æ—Å–∏–Ω—É—Å–Ω–∞ –ø–æ–¥—ñ–±–Ω—ñ—Å—Ç—å)
**–î–ª—è —Ç–µ–∫—Å—Ç—ñ–≤ —Ç–∞ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö**

$$similarity = \frac{x \cdot y}{||x|| \cdot ||y||} = \frac{\sum x_i y_i}{\sqrt{\sum x_i^2} \cdot \sqrt{\sum y_i^2}}$$

### 5. Hamming Distance (–í—ñ–¥—Å—Ç–∞–Ω—å –•–µ–º–º—ñ–Ω–≥–∞)
**–î–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö**

$$d(x, y) = \sum_{i=1}^{n} [x_i \neq y_i]$$

**–ü—Ä–∏–∫–ª–∞–¥:**
```python
x = "karolin"
y = "kathrin"
d = 3  # –í—ñ–¥—Ä—ñ–∑–Ω—è—é—Ç—å—Å—è: o‚Üít, l‚Üíh, i‚Üíi
```

## –ü—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥: –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ñ—Ä—É–∫—Ç—ñ–≤

### –î–∞–Ω—ñ

| –§—Ä—É–∫—Ç | –í–∞–≥–∞ (–≥) | –°–æ–ª–æ–¥–∫—ñ—Å—Ç—å (1-10) | –ö–ª–∞—Å |
|-------|----------|-------------------|------|
| A‚ÇÅ | 150 | 7 | üçé –Ø–±–ª—É–∫–æ |
| A‚ÇÇ | 160 | 6 | üçé –Ø–±–ª—É–∫–æ |
| A‚ÇÉ | 140 | 8 | üçé –Ø–±–ª—É–∫–æ |
| O‚ÇÅ | 180 | 9 | üçä –ê–ø–µ–ª—å—Å–∏–Ω |
| O‚ÇÇ | 190 | 8 | üçä –ê–ø–µ–ª—å—Å–∏–Ω |
| O‚ÇÉ | 170 | 9 | üçä –ê–ø–µ–ª—å—Å–∏–Ω |
| **?** | **165** | **7.5** | **?** |

### –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ (k=3, Euclidean)

**–í—ñ–¥—Å—Ç–∞–Ω—ñ –¥–æ –Ω–æ–≤–æ–≥–æ —Ñ—Ä—É–∫—Ç–∞ (165–≥, 7.5):**

$$d(A‚ÇÅ) = \sqrt{(150-165)^2 + (7-7.5)^2} = \sqrt{225 + 0.25} = 15.01$$
$$d(A‚ÇÇ) = \sqrt{(160-165)^2 + (6-7.5)^2} = \sqrt{25 + 2.25} = 5.22$$
$$d(A‚ÇÉ) = \sqrt{(140-165)^2 + (8-7.5)^2} = \sqrt{625 + 0.25} = 25.01$$
$$d(O‚ÇÅ) = \sqrt{(180-165)^2 + (9-7.5)^2} = \sqrt{225 + 2.25} = 15.08$$
$$d(O‚ÇÇ) = \sqrt{(190-165)^2 + (8-7.5)^2} = \sqrt{625 + 0.25} = 25.01$$
$$d(O‚ÇÉ) = \sqrt{(170-165)^2 + (9-7.5)^2} = \sqrt{25 + 2.25} = 5.22$$

**–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ –≤—ñ–¥—Å—Ç–∞–Ω–Ω—é:**
1. A‚ÇÇ (5.22) ‚Üí üçé
2. O‚ÇÉ (5.22) ‚Üí üçä
3. A‚ÇÅ (15.01) ‚Üí üçé

**k=3 –Ω–∞–π–±–ª–∏–∂—á—ñ:** üçéüçäüçé

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** üçé **–Ø–±–ª—É–∫–æ** (2 –≥–æ–ª–æ—Å–∏ –∑ 3)

## –°–∫–ª–∞–¥–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥—ñ–∞–±–µ—Ç—É

### –î–∞–Ω—ñ –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤

| ID | –ì–ª—é–∫–æ–∑–∞ | BMI | –í—ñ–∫ | –î—ñ–∞–±–µ—Ç |
|----|---------|-----|-----|--------|
| 1 | 85 | 25.0 | 30 | ‚ùå –ù—ñ |
| 2 | 90 | 26.5 | 35 | ‚ùå –ù—ñ |
| 3 | 95 | 28.0 | 40 | ‚ùå –ù—ñ |
| 4 | 140 | 32.0 | 50 | ‚úÖ –¢–∞–∫ |
| 5 | 150 | 35.0 | 55 | ‚úÖ –¢–∞–∫ |
| 6 | 160 | 38.0 | 60 | ‚úÖ –¢–∞–∫ |
| **?** | **120** | **30.0** | **45** | **?** |

### –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó

**–ë–µ–∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó:**
```python
# –ì–ª—é–∫–æ–∑–∞: –¥—ñ–∞–ø–∞–∑–æ–Ω [85, 160] ‚Üí —Ä—ñ–∑–Ω–∏—Ü—è 75
# BMI: –¥—ñ–∞–ø–∞–∑–æ–Ω [25, 38] ‚Üí —Ä—ñ–∑–Ω–∏—Ü—è 13
# –í—ñ–∫: –¥—ñ–∞–ø–∞–∑–æ–Ω [30, 60] ‚Üí —Ä—ñ–∑–Ω–∏—Ü—è 30

# –ì–ª—é–∫–æ–∑–∞ –¥–æ–º—ñ–Ω—É—î —É —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≤—ñ–¥—Å—Ç–∞–Ω—ñ!
d = sqrt((120-85)¬≤ + (30-25)¬≤ + (45-30)¬≤)
    = sqrt(1225 + 25 + 225)
    = sqrt(1475) ‚âà 38.4
```

**–ó –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—î—é (Min-Max scaling):**
```python
# –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è: x' = (x - min) / (max - min)

–ì–ª—é–∫–æ–∑–∞: (120 - 85) / (160 - 85) = 35/75 = 0.467
BMI: (30 - 25) / (38 - 25) = 5/13 = 0.385
–í—ñ–∫: (45 - 30) / (60 - 30) = 15/30 = 0.500

# –¢–µ–ø–µ—Ä –≤—Å—ñ –æ–∑–Ω–∞–∫–∏ –≤ –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ [0, 1]
```

### –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—î—é (k=3)

**–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ:**

| ID | –ì–ª—é–∫–æ–∑–∞' | BMI' | –í—ñ–∫' | –î—ñ–∞–±–µ—Ç |
|----|----------|------|------|--------|
| 1 | 0.00 | 0.00 | 0.00 | ‚ùå |
| 2 | 0.07 | 0.12 | 0.17 | ‚ùå |
| 3 | 0.13 | 0.23 | 0.33 | ‚ùå |
| 4 | 0.73 | 0.54 | 0.67 | ‚úÖ |
| 5 | 0.87 | 0.77 | 0.83 | ‚úÖ |
| 6 | 1.00 | 1.00 | 1.00 | ‚úÖ |
| **?** | **0.47** | **0.38** | **0.50** | **?** |

**–í—ñ–¥—Å—Ç–∞–Ω—ñ:**
$$d‚ÇÅ = \sqrt{(0.47)^2 + (0.38)^2 + (0.50)^2} = 0.75$$
$$d‚ÇÇ = \sqrt{(0.40)^2 + (0.26)^2 + (0.33)^2} = 0.59$$
$$d‚ÇÉ = \sqrt{(0.34)^2 + (0.15)^2 + (0.17)^2} = 0.41$$
$$d‚ÇÑ = \sqrt{(0.26)^2 + (0.16)^2 + (0.17)^2} = 0.35$$
$$d‚ÇÖ = \sqrt{(0.40)^2 + (0.39)^2 + (0.33)^2} = 0.66$$
$$d‚ÇÜ = \sqrt{(0.53)^2 + (0.62)^2 + (0.50)^2} = 0.96$$

**k=3 –Ω–∞–π–±–ª–∏–∂—á—ñ:**
1. d‚ÇÑ (0.35) ‚Üí ‚úÖ –î—ñ–∞–±–µ—Ç
2. d‚ÇÉ (0.41) ‚Üí ‚ùå –ó–¥–æ—Ä–æ–≤–∏–π
3. d‚ÇÇ (0.59) ‚Üí ‚ùå –ó–¥–æ—Ä–æ–≤–∏–π

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** ‚ùå **–ó–¥–æ—Ä–æ–≤–∏–π** (2 –≥–æ–ª–æ—Å–∏ –∑ 3)

## –í–∏–±—ñ—Ä k

### –í–ø–ª–∏–≤ k –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
```
k=1: –ù–∞–π–±–ª–∏–∂—á–∏–π —Å—É—Å—ñ–¥
     ‚úì –ù–∏–∑—å–∫–∞ bias
     ‚úó –í–∏—Å–æ–∫–∞ variance (—á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É)

k=3: –¢—Ä–∏ –Ω–∞–π–±–ª–∏–∂—á—ñ
     –ë–∞–ª–∞–Ω—Å

k=n: –í—Å—ñ –æ–±'—î–∫—Ç–∏
     ‚úì –ù–∏–∑—å–∫–∞ variance
     ‚úó –í–∏—Å–æ–∫–∞ bias (–∑–∞–≤–∂–¥–∏ –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–∏–π –∫–ª–∞—Å)
```

### –ü—Ä–∞–≤–∏–ª–∞ –≤–∏–±–æ—Ä—É k

| k | –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ | –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ |
|---|----------|----------|----------------------|
| **–ú–∞–ª–µ–Ω—å–∫–µ (1-5)** | –ì–Ω—É—á–∫—ñ –º–µ–∂—ñ, –¥–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—è | –ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É | –ß–∏—Å—Ç—ñ –¥–∞–Ω—ñ, —Å–∫–ª–∞–¥–Ω—ñ –º–µ–∂—ñ |
| **–°–µ—Ä–µ–¥–Ω—î (5-20)** | –ë–∞–ª–∞–Ω—Å bias-variance | - | –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä |
| **–í–µ–ª–∏–∫–µ (>20)** | –°—Ç—ñ–π–∫—ñ—Å—Ç—å –¥–æ —à—É–º—É | –ó–≥–ª–∞–¥–∂–µ–Ω—ñ –º–µ–∂—ñ | –ó–∞—à—É–º–ª–µ–Ω—ñ –¥–∞–Ω—ñ |

### –ï–º–ø—ñ—Ä–∏—á–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞

1. **k = ‚àön** (–¥–µ n ‚Äî —Ä–æ–∑–º—ñ—Ä –≤–∏–±—ñ—Ä–∫–∏)
2. **–ù–µ–ø–∞—Ä–Ω–µ k** (–¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –Ω—ñ—á–∏—ó)
3. **Cross-validation** –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ k

### –ü—Ä–∏–∫–ª–∞–¥: –≤–ø–ª–∏–≤ k
```
–î–∞–Ω—ñ: 10 —Ç–æ—á–æ–∫ –∫–ª–∞—Å—É A, 5 —Ç–æ—á–æ–∫ –∫–ª–∞—Å—É B

k=1: –¢–æ—á–Ω—ñ—Å—Ç—å 95% (—á—É—Ç–ª–∏–≤–æ –¥–æ outliers)
k=3: –¢–æ—á–Ω—ñ—Å—Ç—å 92% (–±–∞–ª–∞–Ω—Å)
k=5: –¢–æ—á–Ω—ñ—Å—Ç—å 90% (—Å—Ç–∞–±—ñ–ª—å–Ω–æ)
k=15: –¢–æ—á–Ω—ñ—Å—Ç—å 67% (–∑–∞–≤–∂–¥–∏ –ø–µ—Ä–µ–¥–±–∞—á–∞—î A)
```

## –ó–≤–∞–∂–µ–Ω–∏–π k-NN

### –ü—Ä–æ–±–ª–µ–º–∞ –∑–≤–∏—á–∞–π–Ω–æ–≥–æ k-NN
–í—Å—ñ k —Å—É—Å—ñ–¥—ñ–≤ –º–∞—é—Ç—å –æ–¥–Ω–∞–∫–æ–≤—É –≤–∞–≥—É, –∞–ª–µ **–±–ª–∏–∂—á—ñ —Å—É—Å—ñ–¥–∏ –≤–∞–∂–ª–∏–≤—ñ—à—ñ**.

### Weighted k-NN

**–í–∞–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ:**
$$w_i = \frac{1}{d_i}$$ 
–∞–±–æ
$$w_i = \frac{1}{d_i^2}$$

**–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:**
$$\hat{y} = \frac{\sum_{i=1}^{k} w_i \cdot y_i}{\sum_{i=1}^{k} w_i}$$

### –ü—Ä–∏–∫–ª–∞–¥

**–ù–æ–≤—ñ –¥–∞–Ω—ñ:**
- –°—É—Å—ñ–¥ 1: –≤—ñ–¥—Å—Ç–∞–Ω—å 2.0, –∫–ª–∞—Å A
- –°—É—Å—ñ–¥ 2: –≤—ñ–¥—Å—Ç–∞–Ω—å 5.0, –∫–ª–∞—Å B
- –°—É—Å—ñ–¥ 3: –≤—ñ–¥—Å—Ç–∞–Ω—å 10.0, –∫–ª–∞—Å B

**–ó–≤–∏—á–∞–π–Ω–∏–π k-NN:**
- –ì–æ–ª–æ—Å–∏: A=1, B=2 ‚Üí **–ö–ª–∞—Å B**

**–ó–≤–∞–∂–µ–Ω–∏–π k-NN:**
$$w_1 = 1/2.0 = 0.50$$
$$w_2 = 1/5.0 = 0.20$$
$$w_3 = 1/10.0 = 0.10$$

- –ó–≤–∞–∂–µ–Ω—ñ –≥–æ–ª–æ—Å–∏: A=0.50, B=0.30 ‚Üí **–ö–ª–∞—Å A**

## –†–µ–≥—Ä–µ—Å—ñ—è –∑ k-NN

### –ü—Ä–∏–Ω—Ü–∏–ø
–ó–∞–º—ñ—Å—Ç—å –∫–ª–∞—Å—É –ø–µ—Ä–µ–¥–±–∞—á–∞—î–º–æ **—á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è** —è–∫ —Å–µ—Ä–µ–¥–Ω—î k —Å—É—Å—ñ–¥—ñ–≤.

### –ü—Ä–∏–∫–ª–∞–¥: –¶—ñ–Ω–∞ –±—É–¥–∏–Ω–∫—É

| –ë—É–¥–∏–Ω–æ–∫ | –ü–ª–æ—â–∞ (–º¬≤) | –ö—ñ–º–Ω–∞—Ç | –¶—ñ–Ω–∞ ($1000) |
|---------|------------|--------|--------------|
| 1 | 50 | 2 | 150 |
| 2 | 60 | 2 | 180 |
| 3 | 70 | 3 | 200 |
| 4 | 100 | 3 | 280 |
| 5 | 120 | 4 | 350 |
| **?** | **80** | **3** | **?** |

**k=3 –Ω–∞–π–±–ª–∏–∂—á—ñ (–∑–∞ –ø–ª–æ—â–µ—é):**
1. –ë—É–¥–∏–Ω–æ–∫ 3 (70 –º¬≤): $200k
2. –ë—É–¥–∏–Ω–æ–∫ 2 (60 –º¬≤): $180k
3. Budynok 4 (100 m¬≤): $280k

**–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:**
$$\hat{y} = \frac{200 + 180 + 280}{3} = 220$$

**–í—ñ–¥–ø–æ–≤—ñ–¥—å:** $220,000

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ü–µ—Ä–µ–≤–∞–≥–∏ ‚úì

| –ü–µ—Ä–µ–≤–∞–≥–∞ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|----------|-----------|
| **–ü—Ä–æ—Å—Ç–æ—Ç–∞** | –õ–µ–≥–∫–æ –∑—Ä–æ–∑—É–º—ñ—Ç–∏ —Ç–∞ —Ä–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ |
| **–ë–µ–∑ –Ω–∞–≤—á–∞–Ω–Ω—è** | Lazy learning ‚Äî –Ω–µ–º–∞—î —Ñ–∞–∑–∏ –Ω–∞–≤—á–∞–Ω–Ω—è |
| **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ –º–µ–∂—ñ** | –ú–æ–∂–µ –º–æ–¥–µ–ª—é–≤–∞—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ –º–µ–∂—ñ —Ä—ñ—à–µ–Ω–Ω—è |
| **–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ—Å—Ç—å** | –ü—Ä–∞—Ü—é—î –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —Ä–µ–≥—Ä–µ—Å—ñ—ó |
| **–ê–¥–∞–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∞–¥–∞–ø—Ç—É—î—Ç—å—Å—è –¥–æ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö |
| **–ë–µ–∑ –ø—Ä–∏–ø—É—â–µ–Ω—å** | –ù–µ —Ä–æ–±–∏—Ç—å –ø—Ä–∏–ø—É—â–µ–Ω—å –ø—Ä–æ —Ä–æ–∑–ø–æ–¥—ñ–ª –¥–∞–Ω–∏—Ö |

### –ù–µ–¥–æ–ª—ñ–∫–∏ ‚úó

| –ù–µ–¥–æ–ª—ñ–∫ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|---------|-----------|
| **–ü–æ–≤—ñ–ª—å–Ω–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è** | O(n¬∑d) –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è |
| **–ü–∞–º'—è—Ç—å** | –ó–±–µ—Ä—ñ–≥–∞—î –≤—Å—é –Ω–∞–≤—á–∞–ª—å–Ω—É –≤–∏–±—ñ—Ä–∫—É |
| **–ü—Ä–æ–∫–ª–∞—Ç—Ç—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ** | –ü–æ–≥–∞–Ω–æ –ø—Ä–∞—Ü—é—î –∑ –±–∞–≥–∞—Ç—å–º–∞ –æ–∑–Ω–∞–∫–∞–º–∏ |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –º–∞—Å—à—Ç–∞–±—É** | –ü–æ—Ç—Ä—ñ–±–Ω–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É** | Outliers –≤–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç |
| **–ù–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –∫–ª–∞—Å–∏** | –ú–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–∏–π –∫–ª–∞—Å –¥–æ–º—ñ–Ω—É—î |

## –ü—Ä–æ–∫–ª–∞—Ç—Ç—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ

### –ü—Ä–æ–±–ª–µ–º–∞
–£ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ **–≤—Å—ñ —Ç–æ—á–∫–∏ —Å—Ç–∞—é—Ç—å –¥–∞–ª–µ–∫–∏–º–∏** –æ–¥–Ω–∞ –≤—ñ–¥ –æ–¥–Ω–æ—ó.

### –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è
```python
import numpy as np

# 2D –ø—Ä–æ—Å—Ç—ñ—Ä
points_2d = np.random.rand(100, 2)
distances_2d = np.linalg.norm(points_2d[0] - points_2d, axis=1)
print(f"2D: —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å = {distances_2d.mean():.2f}")
# –í–∏–≤—ñ–¥: 2D: —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å = 0.52

# 100D –ø—Ä–æ—Å—Ç—ñ—Ä
points_100d = np.random.rand(100, 100)
distances_100d = np.linalg.norm(points_100d[0] - points_100d, axis=1)
print(f"100D: —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å = {distances_100d.mean():.2f}")
# –í–∏–≤—ñ–¥: 100D: —Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å—Ç–∞–Ω—å = 5.77

# –£ 100D –≤—Å—ñ —Ç–æ—á–∫–∏ –º–∞–π–∂–µ –æ–¥–Ω–∞–∫–æ–≤–æ –¥–∞–ª–µ–∫—ñ!
```

### –†—ñ—à–µ–Ω–Ω—è
1. **–ó–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ:** PCA, t-SNE, UMAP
2. **–í—ñ–¥–±—ñ—Ä –æ–∑–Ω–∞–∫:** –í–∏–¥–∞–ª–∏—Ç–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –æ–∑–Ω–∞–∫–∏
3. **–†–µ–≥ular–∏–∑–∞—Ü—ñ—è:** –ó–≤–∞–∂—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫

## –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è k-NN

### 1. KD-Tree

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–∏—Ö** –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤.
```python
from sklearn.neighbors import KDTree

tree = KDTree(X_train)
distances, indices = tree.query(X_test, k=3)

# –°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å: O(log n) –∑–∞–º—ñ—Å—Ç—å O(n)
```

**–û–±–º–µ–∂–µ–Ω–Ω—è:** –ü–æ–≥–∞–Ω–æ –ø—Ä–∞—Ü—é—î –ø—Ä–∏ d > 20

### 2. Ball Tree

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ KD-Tree** –¥–ª—è –≤–∏—Å–æ–∫–∏—Ö —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç–µ–π.
```python
from sklearn.neighbors import BallTree

tree = BallTree(X_train)
distances, indices = tree.query(X_test, k=3)
```

### 3. LSH (Locality-Sensitive Hashing)

–ê–ø—Ä–æ–∫—Å–∏–º–∞—Ç–∏–≤–Ω–∏–π –ø–æ—à—É–∫ –¥–ª—è **–¥—É–∂–µ –≤–µ–ª–∏–∫–∏—Ö** –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤.

### 4. Approximate Nearest Neighbors

–ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏: **Annoy**, **Faiss**, **HNSW**
```python
from annoy import AnnoyIndex

# –®–≤–∏–¥—à–µ, –∞–ª–µ –Ω–∞–±–ª–∏–∂–µ–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
index = AnnoyIndex(n_features, 'euclidean')
for i, vector in enumerate(X_train):
    index.add_item(i, vector)
index.build(10)  # 10 –¥–µ—Ä–µ–≤

neighbors = index.get_nns_by_vector(x_test, k=3)
```

## –ü—Ä–∏–∫–ª–∞–¥ –∫–æ–¥—É (scikit-learn)

### –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
from sklearn.datasets import make_classification
X, y = make_classification(
    n_samples=1000,
    n_features=10,
    n_informative=5,
    n_redundant=2,
    random_state=42
)

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è (–û–ë–û–í'–Ø–ó–ö–û–í–û –¥–ª—è k-NN!)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –ú–æ–¥–µ–ª—å
knn = KNeighborsClassifier(
    n_neighbors=5,
    weights='distance',      # –ó–≤–∞–∂–µ–Ω–∏–π k-NN
    metric='euclidean',
    algorithm='auto'         # –ê–≤—Ç–æ–≤–∏–±—ñ—Ä: brute/kd_tree/ball_tree
)

# –ù–∞–≤—á–∞–Ω–Ω—è
knn.fit(X_train_scaled, y_train)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_pred = knn.predict(X_test_scaled)

# –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
y_proba = knn.predict_proba(X_test_scaled)

# –û—Ü—ñ–Ω–∫–∞
print(f"Accuracy: {knn.score(X_test_scaled, y_test):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
```

### –†–µ–≥—Ä–µ—Å—ñ—è
```python
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score

# –ú–æ–¥–µ–ª—å
knn_reg = KNeighborsRegressor(
    n_neighbors=5,
    weights='distance',
    metric='euclidean'
)

# –ù–∞–≤—á–∞–Ω–Ω—è
knn_reg.fit(X_train_scaled, y_train)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_pred = knn_reg.predict(X_test_scaled)

# –û—Ü—ñ–Ω–∫–∞
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.4f}")
print(f"R¬≤ Score: {r2:.4f}")
```

### –ü—ñ–¥–±—ñ—Ä k —á–µ—Ä–µ–∑ Cross-Validation
```python
from sklearn.model_selection import GridSearchCV

# –î—ñ–∞–ø–∞–∑–æ–Ω k –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
param_grid = {
    'n_neighbors': range(1, 31),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# Grid Search
grid_search = GridSearchCV(
    KNeighborsClassifier(),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X_train_scaled, y_train)

# –ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
print(f"Best k: {grid_search.best_params_['n_neighbors']}")
print(f"Best weights: {grid_search.best_params_['weights']}")
print(f"Best metric: {grid_search.best_params_['metric']}")
print(f"Best score: {grid_search.best_score_:.4f}")

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ—ó –º–æ–¥–µ–ª—ñ
best_knn = grid_search.best_estimator_
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–ø–ª–∏–≤—É k
```python
import matplotlib.pyplot as plt

# –¢–µ—Å—Ç —Ä—ñ–∑–Ω–∏—Ö k
k_values = range(1, 31)
train_scores = []
test_scores = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    
    train_scores.append(knn.score(X_train_scaled, y_train))
    test_scores.append(knn.score(X_test_scaled, y_test))

# –ì—Ä–∞—Ñ—ñ–∫
plt.figure(figsize=(12, 6))
plt.plot(k_values, train_scores, label='Train Accuracy', marker='o')
plt.plot(k_values, test_scores, label='Test Accuracy', marker='s')
plt.xlabel('k (Number of Neighbors)', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.title('k-NN: –í–ø–ª–∏–≤ k –Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.xticks(range(1, 31, 2))
plt.tight_layout()
plt.show()

# –û–ø—Ç–∏–º–∞–ª—å–Ω–µ k
optimal_k = k_values[np.argmax(test_scores)]
print(f"Optimal k: {optimal_k}")
```

## –ì—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏

### –û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º | –û–ø–∏—Å |
|----------|---------------------------|------|
| `n_neighbors` | 5 | –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤ (k) |
| `weights` | 'uniform' | 'uniform' –∞–±–æ 'distance' |
| `metric` | 'minkowski' | –ú–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ |
| `p` | 2 | –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è Minkowski (1=Manhattan, 2=Euclidean) |
| `algorithm` | 'auto' | 'auto', 'ball_tree', 'kd_tree', 'brute' |
| `leaf_size` | 30 | –†–æ–∑–º—ñ—Ä –ª–∏—Å—Ç–∫–∞ –¥–ª—è tree –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ |

### –ü—Ä–∏–∫–ª–∞–¥–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è

**–î–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ:**
```python
knn = KNeighborsClassifier(
    n_neighbors=5,
    algorithm='kd_tree',  # –®–≤–∏–¥—à–µ –¥–ª—è d < 20
    leaf_size=20
)
```

**–î–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ:**
```python
knn = KNeighborsClassifier(
    n_neighbors=7,
    weights='distance',   # –ó–≤–∞–∂–µ–Ω—ñ —Å—É—Å—ñ–¥–∏
    metric='minkowski',
    p=1.5                # –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–µ p
)
```

**–î–ª—è –≤–∏—Å–æ–∫–∏—Ö —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç–µ–π:**
```python
knn = KNeighborsClassifier(
    n_neighbors=10,
    algorithm='ball_tree',  # –ö—Ä–∞—â–µ –¥–ª—è d > 20
    metric='manhattan'
)
```

## –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö

### –ß–æ–º—É –≤–∞–∂–ª–∏–≤–∞?

**–ë–µ–∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó:**
```python
# –û–∑–Ω–∞–∫–∞ 1: –î–æ—Ö—ñ–¥ [10000, 100000] ‚Äî –¥—ñ–∞–ø–∞–∑–æ–Ω 90000
# –û–∑–Ω–∞–∫–∞ 2: –í—ñ–∫ [20, 70] ‚Äî –¥—ñ–∞–ø–∞–∑–æ–Ω 50
# –î–æ—Ö—ñ–¥ –¥–æ–º—ñ–Ω—É—î —É —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≤—ñ–¥—Å—Ç–∞–Ω—ñ!
```

### –ú–µ—Ç–æ–¥–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó

#### 1. Min-Max Scaling
$$x' = \frac{x - x_{min}}{x_{max} - x_{min}}$$
```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
# –î—ñ–∞–ø–∞–∑–æ–Ω: [0, 1]
```

#### 2. Standardization (Z-score)
$$x' = \frac{x - \mu}{\sigma}$$
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# –°–µ—Ä–µ–¥–Ω—î: 0, –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è: 1
```

#### 3. Robust Scaling
$$x' = \frac{x - Q_{50}}{Q_{75} - Q_{25}}$$
```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)
# –°—Ç—ñ–π–∫–∞ –¥–æ outliers
```

### –ö–æ–ª–∏ —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

| –ú–µ—Ç–æ–¥ | –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ |
|-------|---------------------|
| **Min-Max** | –î–∞–Ω—ñ –±–µ–∑ outliers, –ø–æ—Ç—Ä—ñ–±–µ–Ω –¥—ñ–∞–ø–∞–∑–æ–Ω [0,1] |
| **Standard** | –ù–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª, –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –≤–∏–ø–∞–¥–∫—ñ–≤ |
| **Robust** | –ë–∞–≥–∞—Ç–æ outliers, –Ω–µ–≥–∞—É—Å—ñ–≤—Å—å–∫–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª |

## –û–±—Ä–æ–±–∫–∞ –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤

### –ü—Ä–æ–±–ª–µ–º–∞
–Ø–∫—â–æ –∫–ª–∞—Å—ñ–≤ A=90, B=10, k-NN –º–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ –ø–µ—Ä–µ–¥–±–∞—á–∞—î A.

### –†—ñ—à–µ–Ω–Ω—è

#### 1. –ó–≤–∞–∂—É–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤
```python
from sklearn.utils.class_weight import compute_sample_weight

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –≤–∞–≥
sample_weights = compute_sample_weight('balanced', y_train)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train, sample_weight=sample_weights)
```

#### 2. Oversampling (SMOTE)
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

knn.fit(X_resampled, y_resampled)
```

#### 3. Undersampling
```python
from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X_train, y_train)
```

#### 4. –ú–µ–Ω—à–µ k
–ú–µ–Ω—à–µ k ‚Üí –º–µ–Ω—à–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å, —â–æ –≤—Å—ñ —Å—É—Å—ñ–¥–∏ –∑ –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–≥–æ –∫–ª–∞—Å—É.

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | k-NN | Decision Tree | Logistic Regression | SVM |
|----------------|------|---------------|---------------------|-----|
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è** | ‚ö°‚ö°‚ö° (–Ω–µ–º–∞—î) | ‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö° |
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è** | ‚ö° (–ø–æ–≤—ñ–ª—å–Ω–æ) | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö° |
| **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω—ñ—Å—Ç—å** | ‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö° |
| **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ –º–µ–∂—ñ** | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ (–∑ kernel) |
| **–í–∏—Å–æ–∫–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å** | ‚ùå | ‚úÖ | ‚úÖ | ‚ö°‚ö° |
| **–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –º–∞—Å—à—Ç–∞–±—É** | ‚úÖ (–¥—É–∂–µ) | ‚ùå | ‚ö°‚ö° | ‚úÖ |
| **