# QDA (Quadratic Discriminant Analysis)

## –©–æ —Ü–µ?

**Quadratic Discriminant Analysis (QDA)** ‚Äî —Ü–µ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è LDA, —è–∫–µ –¥–æ–∑–≤–æ–ª—è—î –∫–æ–∂–Ω–æ–º—É –∫–ª–∞—Å—É –º–∞—Ç–∏ **–≤–ª–∞—Å–Ω—É covariance matrix**, —â–æ –ø—Ä–∏–∑–≤–æ–¥–∏—Ç—å –¥–æ **–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∏—Ö decision boundaries**.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** —Ç–∞–∫ —Å–∞–º–æ —è–∫ LDA, –∞–ª–µ –±–µ–∑ –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è –ø—Ä–æ shared covariance ‚Üí –±—ñ–ª—å—à–µ flexibility, –∞–ª–µ –±—ñ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω?

- üéØ **Quadratic boundaries** ‚Äî –±—ñ–ª—å—à –≥–Ω—É—á–∫—ñ –Ω—ñ–∂ LDA
- üìä **Different covariances** ‚Äî –∫–æ–∂–µ–Ω –∫–ª–∞—Å –º–∞—î —Å–≤–æ—é —Ñ–æ—Ä–º—É
- ‚ö° **Probabilistic** ‚Äî –¥–∞—î –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
- üí° **Flexibility** ‚Äî –º–µ–Ω—à–µ –æ–±–º–µ–∂–µ–Ω—å –Ω—ñ–∂ LDA
- üîß **Gaussian assumption** ‚Äî –ø—Ä–∞—Ü—é—î —è–∫—â–æ –¥–∞–Ω—ñ Gaussian

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**
- –ö–ª–∞—Å–∏ –º–∞—é—Ç—å **—Ä—ñ–∑–Ω—ñ covariances**
- **Quadratic boundaries** –ø–æ—Ç—Ä—ñ–±–Ω—ñ
- –ö–ª–∞—Å–∏ **Gaussian —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω—ñ**
- –î–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö (–±—ñ–ª—å—à–µ –Ω—ñ–∂ –¥–ª—è LDA)

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**
- **–ú–∞–ª—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏** ‚Üí LDA –∫—Ä–∞—â–µ (–º–µ–Ω—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤)
- Shared covariance –ø—Ä–∞—Ü—é—î ‚Üí LDA –ø—Ä–æ—Å—Ç—ñ—à–µ
- **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ non-quadratic** ‚Üí Kernel methods, Tree-based
- **–î—É–∂–µ –≤–∏—Å–æ–∫–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ** ‚Üí LDA, regularization methods

---

## –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ QDA

### –†—ñ–∑–Ω–∏—Ü—è –∑ LDA

**LDA:**
- Shared covariance: $\Sigma$ (–æ–¥–Ω–∞–∫–æ–≤–∞ –¥–ª—è –≤—Å—ñ—Ö)
- **–õ—ñ–Ω—ñ–π–Ω—ñ** decision boundaries

**QDA:**
- Per-class covariance: $\Sigma_k$ (—Å–≤–æ—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É)
- **–ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ñ** decision boundaries

### Discriminant Function

**–î–ª—è –∫–ª–∞—Å—É $k$:**

$$\delta_k(x) = -\frac{1}{2} \log|\Sigma_k| - \frac{1}{2}(x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) + \log(\pi_k)$$

**–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è:**

$$\hat{y} = \arg\max_k \delta_k(x)$$

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ñ–æ—Ä–º—É–ª

**LDA (–ª—ñ–Ω—ñ–π–Ω–∞):**
$$\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log(\pi_k)$$

**QDA (–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞):**
$$\delta_k(x) = -\frac{1}{2} \log|\Sigma_k| - \frac{1}{2}(x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) + \log(\pi_k)$$

**–†—ñ–∑–Ω–∏—Ü—è:** $\Sigma_k$ –∑–∞–º—ñ—Å—Ç—å $\Sigma$ + –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π term $\log|\Sigma_k|$.

---

## –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

### LDA vs QDA

\`\`\`
LDA (linear boundary):        QDA (quadratic boundary):

    Class A (‚Ä¢)                    Class A (‚Ä¢)
      ‚Ä¢  ‚Ä¢  ‚Ä¢                        ‚Ä¢  ‚Ä¢  ‚Ä¢
      ‚Ä¢  ‚Ä¢  ‚Ä¢                        ‚Ä¢  ‚Ä¢  ‚Ä¢
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                      ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤
      √ó  √ó  √ó                      √ó  √ó  √ó
      √ó  √ó  √ó                      √ó  √ó  √ó
    Class B (√ó)                    Class B (√ó)

–ü—Ä—è–º–∞ –ª—ñ–Ω—ñ—è                    –ö—Ä–∏–≤–∞ (–µ–ª—ñ–ø—Ç–∏—á–Ω–∞)
\`\`\`

---

## –ö–æ–¥ (Python + scikit-learn)

### –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

\`\`\`python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# –î–∞–Ω—ñ
iris = load_iris()
X = iris.data
y = iris.target

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# QDA
qda = QuadraticDiscriminantAnalysis()

# –ù–∞–≤—á–∞–Ω–Ω—è
qda.fit(X_train, y_train)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_pred = qda.predict(X_test)
y_pred_proba = qda.predict_proba(X_test)

# –û—Ü—ñ–Ω–∫–∞
print("=== Quadratic Discriminant Analysis ===")
print(f"Train Accuracy: {qda.score(X_train, y_train):.4f}")
print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
print("\n=== Model Parameters ===")
print(f"Priors: {qda.priors_}")
print(f"Means shape: {qda.means_.shape}")
print(f"Number of covariance matrices: {len(qda.covariance_)}")
\`\`\`

### LDA vs QDA –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

\`\`\`python
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# –ù–∞–≤—á–∞–Ω–Ω—è –æ–±–æ—Ö –º–æ–¥–µ–ª–µ–π
lda = LinearDiscriminantAnalysis()
qda = QuadraticDiscriminantAnalysis()

lda.fit(X_train, y_train)
qda.fit(X_train, y_train)

print("="*60)
print("LDA vs QDA")
print("="*60)
print(f"LDA Train: {lda.score(X_train, y_train):.4f}  Test: {lda.score(X_test, y_test):.4f}")
print(f"QDA Train: {qda.score(X_train, y_train):.4f}  Test: {qda.score(X_test, y_test):.4f}")
\`\`\`

---

## –ö–æ–ª–∏ LDA, –∫–æ–ª–∏ QDA?

### Decision Tree

\`\`\`
            –ö–ª–∞—Å–∏ Gaussian —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω—ñ?
                    /           \
                 –ù—ñ             –¢–∞–∫
                  |               |
          –Ü–Ω—à—ñ –º–µ—Ç–æ–¥–∏      Covariances –æ–¥–Ω–∞–∫–æ–≤—ñ?
                            /              \
                         –¢–∞–∫                –ù—ñ
                          |                  |
                        LDA              QDA (—è–∫—â–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö)
                                             |
                                      –ú–∞–ª–∏–π –¥–∞—Ç–∞—Å–µ—Ç?
                                        /        \
                                     –¢–∞–∫          –ù—ñ
                                      |            |
                                    LDA          QDA
\`\`\`

### –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

**–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π LDA –∫–æ–ª–∏:**
- ‚úÖ –ú–∞–ª—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏
- ‚úÖ Covariances —Å—Ö–æ–∂—ñ
- ‚úÖ –ü–æ—Ç—Ä—ñ–±–Ω–∞ –ø—Ä–æ—Å—Ç–æ—Ç–∞
- ‚úÖ Regularization –≤–∞–∂–ª–∏–≤–∞

**–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π QDA –∫–æ–ª–∏:**
- ‚úÖ –î–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö
- ‚úÖ Covariances —è–≤–Ω–æ —Ä—ñ–∑–Ω—ñ
- ‚úÖ –ü–æ—Ç—Ä—ñ–±–Ω—ñ quadratic boundaries
- ‚úÖ LDA underfitting

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

### –ü–µ—Ä–µ–≤–∞–≥–∏ ‚úì

| –ü–µ—Ä–µ–≤–∞–≥–∞ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|----------|-----------|
| **Flexibility** | –†—ñ–∑–Ω—ñ covariances |
| **Quadratic boundaries** | –ë—ñ–ª—å—à–µ –≥–Ω—É—á–∫–æ—Å—Ç—ñ –Ω—ñ–∂ LDA |
| **Probabilistic** | –î–∞—î –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ |
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | –®–≤–∏–¥—à–∏–π –∑–∞ SVM, RF |

### –ù–µ–¥–æ–ª—ñ–∫–∏ ‚úó

| –ù–µ–¥–æ–ª—ñ–∫ | –ü–æ—è—Å–Ω–µ–Ω–Ω—è |
|---------|-----------|
| **–ë—ñ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤** | –ü–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö |
| **Overfitting** | –Ø–∫—â–æ –º–∞–ª–æ –¥–∞–Ω–∏—Ö |
| **Gaussian assumption** | –ü–æ—Ä—É—à–µ–Ω–Ω—è ‚Üí –ø–æ–≥–∞–Ω–æ |
| **High-dimensional** | –ë–∞–≥–∞—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ |

---

## –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

### LDA

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤:** $K \cdot d + \frac{d(d+1)}{2}$

- $K$ means ($K \cdot d$)
- 1 shared covariance ($\frac{d(d+1)}{2}$)

### QDA

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤:** $K \cdot d + K \cdot \frac{d(d+1)}{2}$

- $K$ means ($K \cdot d$)
- $K$ covariances ($K \cdot \frac{d(d+1)}{2}$)

**–ü—Ä–∏–∫–ª–∞–¥:** $K=3$, $d=10$

- LDA: $3 \cdot 10 + 55 = 85$ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
- QDA: $3 \cdot 10 + 3 \cdot 55 = 195$ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

**QDA –ø–æ—Ç—Ä–µ–±—É—î –±—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö!**

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

1. **–ü–æ—á–Ω–∏ –∑ LDA** ‚Äî –ø—Ä–æ—Å—Ç—ñ—à–∞ baseline
2. **–ü–æ—Ä—ñ–≤–Ω—è–π LDA vs QDA** ‚Äî —á–µ—Ä–µ–∑ CV
3. **–î–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö?** ‚Äî QDA –ø–æ—Ç—Ä–µ–±—É—î –±—ñ–ª—å—à–µ
4. **–í—ñ–∑—É–∞–ª—ñ–∑—É–π covariances** ‚Äî —á–∏ –≤–æ–Ω–∏ —Ä—ñ–∑–Ω—ñ?
5. **High-dimensional** ‚Äî LDA –∫—Ä–∞—â–µ (–º–µ–Ω—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤)
6. **Regularization** ‚Äî —è–∫—â–æ QDA overfitting
7. **Gaussian assumption** ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä –≤—ñ–∑—É–∞–ª—å–Ω–æ

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> QDA –¥–æ–∑–≤–æ–ª—è—î —Ä—ñ–∑–Ω—ñ covariances –¥–ª—è –∫–ª–∞—Å—ñ–≤ ‚Üí –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ñ decision boundaries, –∞–ª–µ –ø–æ—Ç—Ä–µ–±—É—î –±—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö.

**LDA vs QDA:**
- **LDA:** shared Œ£ ‚Üí linear boundaries
- **QDA:** per-class Œ£_k ‚Üí quadratic boundaries

**Trade-off:**
- QDA –±—ñ–ª—å—à –≥–Ω—É—á–∫–∏–π, –∞–ª–µ –±—ñ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
- LDA –ø—Ä–æ—Å—Ç—ñ—à–∏–π, –∫—Ä–∞—â–µ –¥–ª—è –º–∞–ª–∏—Ö –¥–∞–Ω–∏—Ö

---

#ml #qda #discriminant-analysis #quadratic #probabilistic
