# Feature Scaling (–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫)

## –©–æ —Ü–µ?

–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ ‚Äî —Ü–µ –ø—Ä–æ—Ü–µ—Å –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥—ñ–∞–ø–∞–∑–æ–Ω—É –Ω–µ–∑–∞–ª–µ–∂–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö (features) —É –Ω–∞–±–æ—Ä—ñ –¥–∞–Ω–∏—Ö. –¶–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ –¥–ª—è –±–∞–≥–∞—Ç—å–æ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ ML.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ?

- üéØ **–®–≤–∏–¥—à–∞ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è** ‚Äî –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫ –ø—Ä–∞—Ü—é—î –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–µ
- ‚öñÔ∏è **–†—ñ–≤–Ω–∏–π –≤–ø–ª–∏–≤ –æ–∑–Ω–∞–∫** ‚Äî –∑–∞–ø–æ–±—ñ–≥–∞—î –¥–æ–º—ñ–Ω—É–≤–∞–Ω–Ω—é –æ–∑–Ω–∞–∫ –∑ –≤–µ–ª–∏–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
- üî¢ **–í–∏–º–æ–≥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤** ‚Äî –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –¥–ª—è KNN, SVM, –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ü–æ—Ç—Ä—ñ–±–Ω–æ:**

- –ê–ª–≥–æ—Ä–∏—Ç–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—ñ–¥—Å—Ç–∞–Ω—ñ (KNN, K-Means, SVM)
- –ì—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫ (–Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ, –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è)
- PCA —Ç–∞ —ñ–Ω—à—ñ –º–µ—Ç–æ–¥–∏ –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ

**–ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ:**

- –î–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å —Ç–∞ —ó—Ö –∞–Ω—Å–∞–º–±–ª—ñ (Random Forest, XGBoost)
- –ù–∞—ó–≤–Ω–∏–π –ë–∞—î—Å

---

## 1. StandardScaler (–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—è)

### –§–æ—Ä–º—É–ª–∞

```
z = (x - Œº) / œÉ
```
–¥–µ:
- `x` ‚Äî –ø–æ—á–∞—Ç–∫–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è
- `Œº` ‚Äî —Å–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è
- `œÉ` ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è

### –†–µ–∑—É–ª—å—Ç–∞—Ç

- –°–µ—Ä–µ–¥–Ω—î = 0
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è = 1
- –†–æ–∑–ø–æ–¥—ñ–ª: –∑–∞–∑–≤–∏—á–∞–π –≤—ñ–¥ -3 –¥–æ +3

### –ö–æ–¥ (scikit-learn)

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ train
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ –î–∞–Ω—ñ –º–∞—é—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –∞–±–æ –±–ª–∏–∑—å–∫–∏–π –¥–æ –Ω—å–æ–≥–æ
‚úÖ –ü—Ä–∏—Å—É—Ç–Ω—ñ –≤–∏–∫–∏–¥–∏ (StandardScaler –º–µ–Ω—à —á—É—Ç–ª–∏–≤–∏–π –¥–æ –Ω–∏—Ö, –Ω—ñ–∂ MinMaxScaler)
‚úÖ –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è, SVM, –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ

---

## 2. MinMaxScaler (–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è)

### –§–æ—Ä–º—É–ª–∞

```
x_scaled = (x - x_min) / (x_max - x_min)
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç

- –í—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ [0, 1]
- –ê–±–æ –≤ –±—É–¥—å-—è–∫–æ–º—É —ñ–Ω—à–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ [a, b] –∑–∞ –ø–æ—Ç—Ä–µ–±–∏

### –ö–æ–¥ (scikit-learn)

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### –ö–∞—Å—Ç–æ–º–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω

```python
scaler = MinMaxScaler(feature_range=(-1, 1))
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ –ü–æ—Ç—Ä—ñ–±–µ–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω—å 0-1)
‚úÖ –î–∞–Ω—ñ –Ω–µ –º–∞—é—Ç—å –≤–∏–∫–∏–¥—ñ–≤ (—á—É—Ç–ª–∏–≤–∏–π –¥–æ –Ω–∏—Ö!)
‚úÖ –ù–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –∑ sigmoid/tanh –∞–∫—Ç–∏–≤–∞—Ü—ñ—è–º–∏

---

## 3. RobustScaler (–†–æ–±–∞—Å—Ç–Ω–µ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è)

### –§–æ—Ä–º—É–ª–∞

```
x_scaled = (x - median) / IQR
```

–¥–µ IQR (Interquartile Range) = Q3 - Q1

### –†–µ–∑—É–ª—å—Ç–∞—Ç

- –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è –Ω–∞–≤–∫–æ–ª–æ –º–µ–¥—ñ–∞–Ω–∏
- –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–≤–∞—Ä—Ç–∏–ª—ñ–≤

### –ö–æ–¥

```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ **–ë–∞–≥–∞—Ç–æ –≤–∏–∫–∏–¥—ñ–≤ —É –¥–∞–Ω–∏—Ö**
‚úÖ –ù–µ—Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
‚úÖ –ö–æ–ª–∏ StandardScaler –Ω–µ –ø—Ä–∞—Ü—é—î —á–µ—Ä–µ–∑ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤

| –ú–µ—Ç–æ–¥ | –î—ñ–∞–ø–∞–∑–æ–Ω | –°–µ—Ä–µ–¥–Ω—î | –ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –≤–∏–∫–∏–¥—ñ–≤ | –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è |
|-------|----------|---------|----------------------|--------------|
| StandardScaler | -‚àû –¥–æ +‚àû | 0 | –°–µ—Ä–µ–¥–Ω—è | –ù–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª |
| MinMaxScaler | 0 –¥–æ 1 | –í–∞—Ä—ñ—é—î—Ç—å—Å—è | –í–∏—Å–æ–∫–∞ | –û–±–º–µ–∂–µ–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω |
| RobustScaler | -‚àû –¥–æ +‚àû | ‚âà0 (–º–µ–¥—ñ–∞–Ω–∞) | –ù–∏–∑—å–∫–∞ | –ë–∞–≥–∞—Ç–æ –≤–∏–∫–∏–¥—ñ–≤ |

---

## –í–∞–∂–ª–∏–≤—ñ –ø—Ä–∞–≤–∏–ª–∞ ‚ö†Ô∏è

### 1. Fit —Ç—ñ–ª—å–∫–∏ –Ω–∞ train

```python
# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
scaler.fit(X_test)  # –í–∏—Ç—ñ–∫ –¥–∞–Ω–∏—Ö!
```

### 2. –û–∫—Ä–µ–º–æ –¥–ª—è –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏

–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –∑–∞—Å—Ç–æ—Å–æ–≤—É—î—Ç—å—Å—è –¥–æ –∫–æ–∂–Ω–æ–≥–æ —Å—Ç–æ–≤–ø—Ü—è –Ω–µ–∑–∞–ª–µ–∂–Ω–æ.

### 3. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è scaler

```python
import joblib

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
joblib.dump(scaler, 'scaler.pkl')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
scaler = joblib.load('scaler.pkl')
X_new_scaled = scaler.transform(X_new)
```

---

## –ü—Ä–∏–∫–ª–∞–¥: –ø–æ–≤–Ω–∏–π workflow

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# 1. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è scaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# 3. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
X_test_scaled = scaler.transform(X_test)

# 4. –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# 5. –û—Ü—ñ–Ω–∫–∞
score = model.score(X_test_scaled, y_test)
print(f"Accuracy: {score:.2f}")
```

---

## –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –µ—Ñ–µ–∫—Ç—É

```python
import matplotlib.pyplot as plt
import numpy as np

# –ü–æ—á–∞—Ç–∫–æ–≤—ñ –¥–∞–Ω—ñ
data = np.random.randn(1000, 2) * [100, 5] + [500, 50]

# –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

ax1.scatter(data[:, 0], data[:, 1], alpha=0.5)
ax1.set_title('–î–æ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è')
ax1.set_xlabel('Feature 1')
ax1.set_ylabel('Feature 2')

ax2.scatter(data_scaled[:, 0], data_scaled[:, 1], alpha=0.5)
ax2.set_title('–ü—ñ—Å–ª—è StandardScaler')
ax2.set_xlabel('Feature 1 (scaled)')
ax2.set_ylabel('Feature 2 (scaled)')

plt.tight_layout()
plt.show()
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[02_Categorical_Encoding]] ‚Äî –∫–æ–¥—É–≤–∞–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö
- [[03_Missing_Values]] ‚Äî –æ–±—Ä–æ–±–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
- [[04_Outliers_Handling]] ‚Äî —Ä–æ–±–æ—Ç–∞ –∑ –≤–∏–∫–∏–¥–∞–º–∏

## –†–µ—Å—É—Ä—Å–∏

- [Scikit-learn: Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Feature Scaling Best Practices](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)

---

#ml #preprocessing #scaling #datascience
