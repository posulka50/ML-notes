
**Метод максимальної правдоподібності (ММП)** — це статистичний метод для оцінювання параметрів моделі, який шукає такі значення параметрів, при яких спостережувані дані мають найбільшу ймовірність.

**Головна ідея:** знайти параметри моделі, які роблять наші реальні дані найбільш правдоподібними (найімовірнішими).

## Формула

Функція правдоподібності для незалежних спостережень:

$$L(\theta) = \prod_{i=1}^{n} p(x_i | \theta)$$

Логарифмічна функція правдоподібності (зручніша для обчислень):

$$\log L(\theta) = \sum_{i=1}^{n} \log p(x_i | \theta)$$

де $\theta$ — параметри моделі, $x_i$ — спостереження.

## Простий приклад
### Підкидання монети

Підкинули монету 10 разів: 7 орлів, 3 решки.

**Завдання:** оцінити ймовірність випадання орла $p$.

**Інтуїція:** яка ймовірність $p$ робить такий результат найімовірнішим?

Функція правдоподібності:
$$L(p) = p^7 \cdot (1-p)^3$$

Максимум досягається при $p = 0.7$ (7 орлів з 10 спроб).

## Складний приклад: оцінювання параметрів нормального розподілу

### Дані

Виміряли зріст 5 студентів (см): 170, 175, 168, 172, 180

**Завдання:** оцінити середнє $\mu$ та стандартне відхилення $\sigma$ для нормального розподілу.

### Розрахунок

Для нормального розподілу:
$$p(x | \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$

Логарифмічна правдоподібність:
$$\log L(\mu, \sigma) = -n\log(\sigma) - \frac{n}{2}\log(2\pi) - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i - \mu)^2$$

### Результат

Оцінки ММП для нормального розподілу:

$$\hat{\mu} = \frac{1}{n}\sum_{i=1}^{n} x_i = \frac{170 + 175 + 168 + 172 + 180}{5} = 173 \text{ см}$$

$$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i - \hat{\mu})^2 = \frac{(170-173)^2 + ... + (180-173)^2}{5} = 18.8$$

$$\hat{\sigma} \approx 4.34 \text{ см}$$

### Інтерпретація

- Середній зріст: **173 см**
- Типове відхилення: **4.34 см**
- Ці параметри роблять наші спостереження найбільш правдоподібними

## Чому логарифм?

| Підхід | Особливості |
|--------|-------------|
| $L(\theta) = p_1 \cdot p_2 \cdot ... \cdot p_n$ | Добуток малих чисел → числова нестабільність |
| $\log L(\theta) = \log p_1 + \log p_2 + ... + \log p_n$ | ✓ Сума замість добутку; монотонне перетворення |

**Важливо:** максимум $L(\theta)$ та $\log L(\theta)$ досягається в тій самій точці!

## Геометрична інтуїція

> ММП шукає вершину "гори правдоподібності" — точку в просторі параметрів, де дані найімовірніші.

## Як знаходять максимум?

1. **Аналітично** — прирівняти похідну до нуля (якщо можливо)
2. **Числово** — градієнтний спуск або інші методи оптимізації

## Властивості оцінок ММП

- **Асимптотична незміщеність** — при $n \to \infty$ оцінка прямує до справжнього значення
- **Ефективність** — найменша можлива дисперсія серед незміщених оцінок
- **Інваріантність** — якщо $\hat{\theta}$ — ММП для $\theta$, то $g(\hat{\theta})$ — ММП для $g(\theta)$

## Порівняння з МНК

| Метод | Суть |
|-------|------|
| МНК | Мінімізує суму квадратів помилок |
| ММП | Максимізує ймовірність спостережених даних |

**Зв'язок:** для нормально розподілених помилок МНК = ММП!

## Обмеження

- **Потребує знання розподілу** — треба припустити, яким розподілом описуються дані
- **Локальні максимуми** — складні моделі можуть мати багато локальних оптимумів
- **Обчислювальна складність** — для деяких моделей немає аналітичного рішення

## Ключові висновки

> ММП знаходить параметри моделі, які роблять спостережувані дані максимально правдоподібними.

- **Універсальний підхід** — працює для різних типів розподілів
- **Теоретично обґрунтований** — має хороші статистичні властивості
- **Широке застосування** — основа багатьох методів машинного навчання