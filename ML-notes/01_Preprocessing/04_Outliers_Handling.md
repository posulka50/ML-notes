# Outliers Handling (–†–æ–±–æ—Ç–∞ –∑ –≤–∏–∫–∏–¥–∞–º–∏)

## –©–æ —Ç–∞–∫–µ –≤–∏–∫–∏–¥–∏?

**–í–∏–∫–∏–¥–∏ (Outliers)** ‚Äî —Ü–µ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è, —è–∫—ñ –∑–Ω–∞—á–Ω–æ –≤—ñ–¥—Ä—ñ–∑–Ω—è—é—Ç—å—Å—è –≤—ñ–¥ —ñ–Ω—à–∏—Ö –¥–∞–Ω–∏—Ö —É –Ω–∞–±–æ—Ä—ñ. –í–æ–Ω–∏ –º–æ–∂—É—Ç—å –±—É—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø–æ–º–∏–ª–æ–∫ –∞–±–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç–∏ —Ä—ñ–¥–∫—ñ—Å–Ω—ñ, –∞–ª–µ —Ä–µ–∞–ª—å–Ω—ñ –ø–æ–¥—ñ—ó.

## –¢–∏–ø–∏ –≤–∏–∫–∏–¥—ñ–≤

### 1. Univariate Outliers (–û–¥–Ω–æ–≤–∏–º—ñ—Ä–Ω—ñ)

**–ï–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –æ–¥–Ω—ñ–π –∑–º—ñ–Ω–Ω—ñ–π**
- –ü—Ä–∏–∫–ª–∞–¥: –≤—ñ–∫ = 200 —Ä–æ–∫—ñ–≤
- –í–∏–∑–Ω–∞—á–∞—é—Ç—å—Å—è –¥–ª—è –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏ –æ–∫—Ä–µ–º–æ

### 2. Multivariate Outliers (–ë–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω—ñ)

**–ù–µ–∑–≤–∏—á–∞–π–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è –∑–Ω–∞—á–µ–Ω—å**
- –ü—Ä–∏–∫–ª–∞–¥: –≤—ñ–∫ = 15, –∑–∞—Ä–ø–ª–∞—Ç–∞ = $200,000
- –û–∫—Ä–µ–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–æ—Ä–º–∞–ª—å–Ω—ñ, –∞–ª–µ —Ä–∞–∑–æ–º ‚Äî –Ω—ñ
- –í–∞–∂—á–µ –≤–∏—è–≤–∏—Ç–∏

---

## –ß–æ–º—É –≤–∏–Ω–∏–∫–∞—é—Ç—å? ü§î

### –ü–æ–º–∏–ª–∫–∏ (–≤–∏–¥–∞–ª–∏—Ç–∏!)

- üìù –ü–æ–º–∏–ª–∫–∏ –≤–≤–æ–¥—É –¥–∞–Ω–∏—Ö (1000 –∑–∞–º—ñ—Å—Ç—å 100)
- üîß –ó–±–æ—ó –≤ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—ñ
- üêõ –ë–∞–≥–∏ –≤ –∫–æ–¥—ñ –æ–±—Ä–æ–±–∫–∏
- üîÑ –ü–æ–º–∏–ª–∫–∏ –ø—Ä–∏ –æ–±'—î–¥–Ω–∞–Ω–Ω—ñ –¥–∞–Ω–∏—Ö

### –†–µ–∞–ª—å–Ω—ñ –ø–æ–¥—ñ—ó (–∑–±–µ—Ä–µ–≥—Ç–∏!)

- üíé –†—ñ–¥–∫—ñ—Å–Ω—ñ, –∞–ª–µ –ª–µ–≥—ñ—Ç–∏–º–Ω—ñ –≤–∏–ø–∞–¥–∫–∏
- üåü VIP –∫–ª—ñ—î–Ω—Ç–∏ –∑ –Ω–∞–¥–≤–∏—Å–æ–∫–∏–º–∏ –ø–æ–∫—É–ø–∫–∞–º–∏
- üèÜ –í–∏–Ω—è—Ç–∫–æ–≤—ñ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è
- üìä –ü—Ä–∏—Ä–æ–¥–Ω–∞ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö

---

## –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤

## 1. –í—ñ–∑—É–∞–ª—å–Ω—ñ –º–µ—Ç–æ–¥–∏

### A) Box Plot (–Ø—â–∏–∫ –∑ –≤—É—Å–∞–º–∏)

```python
import matplotlib.pyplot as plt
import seaborn as sns

# –ü—Ä–æ—Å—Ç–∏–π box plot
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='–∑–∞—Ä–ø–ª–∞—Ç–∞')
plt.title('Box Plot –∑–∞—Ä–ø–ª–∞—Ç–∏')
plt.show()

# –î–ª—è –±–∞–≥–∞—Ç—å–æ—Ö –∑–º—ñ–Ω–Ω–∏—Ö
df[['–≤—ñ–∫', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–¥–æ—Å–≤—ñ–¥']].boxplot(figsize=(12, 6))
plt.show()
```

**–Ø–∫ —á–∏—Ç–∞—Ç–∏:**
- –ö–æ—Ä–æ–±–∫–∞: 25%-75% –∫–≤–∞—Ä—Ç–∏–ª—ñ (IQR)
- –õ—ñ–Ω—ñ—è –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ: –º–µ–¥—ñ–∞–Ω–∞
- –í—É—Å–∞: 1.5 √ó IQR
- –¢–æ—á–∫–∏ –∑–∞ –≤—É—Å–∞–º–∏: **–≤–∏–∫–∏–¥–∏**

### B) Scatter Plot (–î—ñ–∞–≥—Ä–∞–º–∞ —Ä–æ–∑—Å—ñ—é–≤–∞–Ω–Ω—è)

```python
# –î–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –≤–∏–∫–∏–¥—ñ–≤
plt.figure(figsize=(10, 6))
plt.scatter(df['–≤—ñ–∫'], df['–∑–∞—Ä–ø–ª–∞—Ç–∞'], alpha=0.5)
plt.xlabel('–í—ñ–∫')
plt.ylabel('–ó–∞—Ä–ø–ª–∞—Ç–∞')
plt.title('–°–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è –≤—ñ–∫—É —Ç–∞ –∑–∞—Ä–ø–ª–∞—Ç–∏')
plt.show()
```

### C) Histogram (–ì—ñ—Å—Ç–æ–≥—Ä–∞–º–∞)

```python
plt.figure(figsize=(10, 6))
df['—Ü—ñ–Ω–∞'].hist(bins=50)
plt.xlabel('–¶—ñ–Ω–∞')
plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
plt.title('–†–æ–∑–ø–æ–¥—ñ–ª —Ü—ñ–Ω')
plt.show()
```

### D) Violin Plot

```python
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, y='–∑–∞—Ä–ø–ª–∞—Ç–∞')
plt.title('Violin Plot –∑–∞—Ä–ø–ª–∞—Ç–∏')
plt.show()
```

---

## 2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –º–µ—Ç–æ–¥–∏

### A) IQR Method (–ú–µ—Ç–æ–¥ –º—ñ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω–æ–≥–æ —Ä–æ–∑–º–∞—Ö—É)

**–ù–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏–π –º–µ—Ç–æ–¥**

```python
import numpy as np

def detect_outliers_iqr(data, column):
    """
    –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ –º–µ—Ç–æ–¥–æ–º IQR
    """
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    # –Ü–Ω–¥–µ–∫—Å–∏ –≤–∏–∫–∏–¥—ñ–≤
    outliers = data[(data[column] < lower_bound) | 
                    (data[column] > upper_bound)]
    
    return outliers, lower_bound, upper_bound

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers, lower, upper = detect_outliers_iqr(df, '–∑–∞—Ä–ø–ª–∞—Ç–∞')
print(f"–ù–∏–∂–Ω—è –º–µ–∂–∞: {lower}")
print(f"–í–µ—Ä—Ö–Ω—è –º–µ–∂–∞: {upper}")
print(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏–∫–∏–¥—ñ–≤: {len(outliers)}")
```

**–§–æ—Ä–º—É–ª–∞:**

```
Lower Bound = Q1 - 1.5 √ó IQR
Upper Bound = Q3 + 1.5 √ó IQR

–¥–µ IQR = Q3 - Q1
```

### B) Z-Score Method

**–î–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–ø–æ–¥—ñ–ª—É**

```python
from scipy import stats

def detect_outliers_zscore(data, column, threshold=3):
    """
    –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ –º–µ—Ç–æ–¥–æ–º Z-score
    """
    z_scores = np.abs(stats.zscore(data[column].dropna()))
    outliers = data[z_scores > threshold]
    
    return outliers

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers = detect_outliers_zscore(df, '–∑–∞—Ä–ø–ª–∞—Ç–∞', threshold=3)
print(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏–∫–∏–¥—ñ–≤ (Z-score > 3): {len(outliers)}")
```

**–§–æ—Ä–º—É–ª–∞:**

```
Z = (x - Œº) / œÉ

–¥–µ:
- x: –∑–Ω–∞—á–µ–Ω–Ω—è
- Œº: —Å–µ—Ä–µ–¥–Ω—î
- œÉ: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
- |Z| > 2: –º–æ–∂–ª–∏–≤–∏–π –≤–∏–∫–∏–¥ (95% –¥–∞–Ω–∏—Ö)
- |Z| > 3: —Å–∏–ª—å–Ω–∏–π –≤–∏–∫–∏–¥ (99.7% –¥–∞–Ω–∏—Ö)

### C) Modified Z-Score (Robust)

**–†–æ–±–∞—Å—Ç–Ω–∞ –≤–µ—Ä—Å—ñ—è –¥–ª—è –Ω–µ–Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤**

```python
def detect_outliers_modified_zscore(data, column, threshold=3.5):
    """
    Modified Z-score –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –º–µ–¥—ñ–∞–Ω—É –∑–∞–º—ñ—Å—Ç—å —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ
    """
    median = data[column].median()
    mad = np.median(np.abs(data[column] - median))
    
    modified_z_scores = 0.6745 * (data[column] - median) / mad
    outliers = data[np.abs(modified_z_scores) > threshold]
    
    return outliers

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers = detect_outliers_modified_zscore(df, '—Ü—ñ–Ω–∞')
```

---

### D) Isolation Forest

**Machine Learning –ø—ñ–¥—Ö—ñ–¥**

```python
from sklearn.ensemble import IsolationForest

def detect_outliers_isolation_forest(data, columns, contamination=0.1):
    """
    –í–∏—è–≤–ª–µ–Ω–Ω—è –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –≤–∏–∫–∏–¥—ñ–≤
    """
    iso_forest = IsolationForest(
        contamination=contamination,  # –û—á—ñ–∫—É–≤–∞–Ω–∏–π % –≤–∏–∫–∏–¥—ñ–≤
        random_state=42
    )
    
    # –ü—Ä–µ–¥–∏–∫—Ü—ñ—è: 1 = –Ω–æ—Ä–º–∞–ª—å–Ω—ñ, -1 = –≤–∏–∫–∏–¥–∏
    predictions = iso_forest.fit_predict(data[columns])
    
    # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
    data['outlier'] = predictions
    outliers = data[data['outlier'] == -1]
    
    return outliers

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers = detect_outliers_isolation_forest(
    df, 
    columns=['–≤—ñ–∫', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–¥–æ—Å–≤—ñ–¥'],
    contamination=0.05
)
```

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –ü—Ä–∞—Ü—é—î –∑ –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
- ‚úÖ –ù–µ –ø—Ä–∏–ø—É—Å–∫–∞—î –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
- ‚úÖ –®–≤–∏–¥–∫–∏–π

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –ë–∞–≥–∞—Ç–æ –æ–∑–Ω–∞–∫
- –°–∫–ª–∞–¥–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
- –ù–µ–≤—ñ–¥–æ–º–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª

---

### E) Local Outlier Factor (LOF)

**–ù–∞ –æ—Å–Ω–æ–≤—ñ –ª–æ–∫–∞–ª—å–Ω–æ—ó —â—ñ–ª—å–Ω–æ—Å—Ç—ñ**

```python
from sklearn.neighbors import LocalOutlierFactor

def detect_outliers_lof(data, columns, n_neighbors=20):
    """
    LOF –≤–∏—è–≤–ª—è—î –≤–∏–∫–∏–¥–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ª–æ–∫–∞–ª—å–Ω–æ—ó —â—ñ–ª—å–Ω–æ—Å—Ç—ñ
    """
    lof = LocalOutlierFactor(
        n_neighbors=n_neighbors,
        contamination='auto'
    )
    
    predictions = lof.fit_predict(data[columns])
    
    data['outlier_lof'] = predictions
    outliers = data[data['outlier_lof'] == -1]
    
    return outliers

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers = detect_outliers_lof(
    df, 
    columns=['–≤—ñ–∫', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–¥–æ—Å–≤—ñ–¥']
)
```

---

### F) DBSCAN Clustering

**–í–∏—è–≤–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—é**

```python
from sklearn.cluster import DBSCAN

def detect_outliers_dbscan(data, columns, eps=0.5, min_samples=5):
    """
    –¢–æ—á–∫–∏, —â–æ –Ω–µ –≤—Ö–æ–¥—è—Ç—å –≤ –∂–æ–¥–µ–Ω –∫–ª–∞—Å—Ç–µ—Ä = –≤–∏–∫–∏–¥–∏
    """
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    clusters = dbscan.fit_predict(data[columns])
    
    # -1 –æ–∑–Ω–∞—á–∞—î –≤–∏–∫–∏–¥ (noise)
    data['cluster'] = clusters
    outliers = data[data['cluster'] == -1]
    
    return outliers

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
outliers = detect_outliers_dbscan(
    df,
    columns=['feature1', 'feature2']
)
```

---

## –û–±—Ä–æ–±–∫–∞ –≤–∏–∫–∏–¥—ñ–≤

## 1. –í–∏–¥–∞–ª–µ–Ω–Ω—è (Removal)

```python
# –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ –≤–∏–∫–∏–¥–∞–º–∏
df_clean = df[~df.index.isin(outliers.index)]

# –ê–±–æ –∑–∞ —É–º–æ–≤–æ—é
Q1 = df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].quantile(0.25)
Q3 = df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].quantile(0.75)
IQR = Q3 - Q1

df_clean = df[
    (df['–∑–∞—Ä–ø–ª–∞—Ç–∞'] >= Q1 - 1.5 * IQR) & 
    (df['–∑–∞—Ä–ø–ª–∞—Ç–∞'] <= Q3 + 1.5 * IQR)
]
```

### ‚ö†Ô∏è –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ –í–∏–∫–∏–¥–∏ ‚Äî —Ü–µ –ø–æ–º–∏–ª–∫–∏
‚úÖ –ù–µ–≤–µ–ª–∏–∫–∏–π % –≤–∏–∫–∏–¥—ñ–≤ (< 1-5%)
‚úÖ –ë–∞–≥–∞—Ç–æ –¥–∞–Ω–∏—Ö

‚ùå –í–∏–∫–∏–¥–∏ —Ä–µ–∞–ª—å–Ω—ñ —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ñ
‚ùå –ú–∞–ª–∏–π –¥–∞—Ç–∞—Å–µ—Ç

---

## 2. Capping/Clipping (–û–±—Ä—ñ–∑–∞–Ω–Ω—è)

### Winsorization
**–ó–∞–º—ñ–Ω–∞ –≤–∏–∫–∏–¥—ñ–≤ –Ω–∞ –≥—Ä–∞–Ω–∏—á–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è**

```python
from scipy.stats.mstats import winsorize

# –û–±—Ä—ñ–∑–∞–Ω–Ω—è 5% –∑ –∫–æ–∂–Ω–æ–≥–æ –±–æ–∫—É
df['–∑–∞—Ä–ø–ª–∞—Ç–∞_winsorized'] = winsorize(
    df['–∑–∞—Ä–ø–ª–∞—Ç–∞'], 
    limits=[0.05, 0.05]
)
```

### –í—Ä—É—á–Ω—É
```python
def cap_outliers(data, column, lower_percentile=5, upper_percentile=95):
    """
    –û–±—Ä—ñ–∑–∞—î –≤–∏–∫–∏–¥–∏ –¥–æ –≤–∫–∞–∑–∞–Ω–∏—Ö –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—ñ–≤
    """
    lower = data[column].quantile(lower_percentile / 100)
    upper = data[column].quantile(upper_percentile / 100)
    
    data[f'{column}_capped'] = data[column].clip(lower, upper)
    
    return data

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
df = cap_outliers(df, '—Ü—ñ–Ω–∞', lower_percentile=1, upper_percentile=99)
```

### –ó–∞ –¥–æ–ø–æ–º–æ–≥–æ—é IQR
```python
def cap_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    data[f'{column}_capped'] = data[column].clip(
        lower_bound, 
        upper_bound
    )
    
    return data

df = cap_outliers_iqr(df, '–∑–∞—Ä–ø–ª–∞—Ç–∞')
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?
‚úÖ –•–æ—á–µ–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ –≤—Å—ñ –¥–∞–Ω—ñ
‚úÖ –í–∏–∫–∏–¥–∏ –≤–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ –º–æ–¥–µ–ª—å
‚úÖ –†–æ–∑–ø–æ–¥—ñ–ª –≤–∞–∂–ª–∏–≤–∏–π, –∞–ª–µ –µ–∫—Å—Ç—Ä–µ–º—É–º–∏ ‚Äî –Ω—ñ

---

## 3. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è (Transformation)

### A) Log Transformation
**–î–ª—è –ø—Ä–∞–≤–æ—Å–∫–æ—à–µ–Ω–∏—Ö —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤**

```python
import numpy as np

# Log —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
df['—Ü—ñ–Ω–∞_log'] = np.log1p(df['—Ü—ñ–Ω–∞'])  # log1p = log(1 + x)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

df['—Ü—ñ–Ω–∞'].hist(bins=50, ax=axes[0])
axes[0].set_title('–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ')

df['—Ü—ñ–Ω–∞_log'].hist(bins=50, ax=axes[1])
axes[1].set_title('–ü—ñ—Å–ª—è log —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó')

plt.show()
```

### B) Square Root Transformation
```python
df['–∑–Ω–∞—á–µ–Ω–Ω—è_sqrt'] = np.sqrt(df['–∑–Ω–∞—á–µ–Ω–Ω—è'])
```

### C) Box-Cox Transformation
**–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø—ñ–¥–±–∏—Ä–∞—î –Ω–∞–π–∫—Ä–∞—â—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—é**

```python
from scipy import stats

# Box-Cox (—Ç—ñ–ª—å–∫–∏ –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å)
transformed_data, lambda_param = stats.boxcox(df['—Ü—ñ–Ω–∞'])
df['—Ü—ñ–Ω–∞_boxcox'] = transformed_data

print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ lambda: {lambda_param}")
```

### D) Yeo-Johnson Transformation
**Box-Cox, –∞–ª–µ –ø—Ä–∞—Ü—é—î –∑ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏**

```python
from sklearn.preprocessing import PowerTransformer

transformer = PowerTransformer(method='yeo-johnson')
df['—Ü—ñ–Ω–∞_yeojohnson'] = transformer.fit_transform(df[['—Ü—ñ–Ω–∞']])
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?
‚úÖ –°–∫–æ—à–µ–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
‚úÖ –ù–æ—Ä–º–∞–ª—å–Ω—ñ—Å—Ç—å –≤–∞–∂–ª–∏–≤–∞ –¥–ª—è –º–æ–¥–µ–ª—ñ
‚úÖ –•–æ—á–µ–º–æ –∑–º–µ–Ω—à–∏—Ç–∏ –≤–ø–ª–∏–≤ –≤–∏–∫–∏–¥—ñ–≤, –∞–ª–µ –∑–±–µ—Ä–µ–≥—Ç–∏ —ó—Ö

---

## 4. –û–∫—Ä–µ–º–µ –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è (Separate Treatment)

### –ë—ñ–Ω–∞—Ä–∏–∑–∞—Ü—ñ—è
```python
# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ "—á–∏ —î –≤–∏–∫–∏–¥–æ–º"
threshold = df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].quantile(0.95)
df['–≤–∏—Å–æ–∫–∞_–∑–∞—Ä–ø–ª–∞—Ç–∞'] = (df['–∑–∞—Ä–ø–ª–∞—Ç–∞'] > threshold).astype(int)
```

### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
```python
def categorize_by_outliers(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    
    def categorize(value):
        if value < lower:
            return '–Ω–∏–∂—á–µ_–Ω–æ—Ä–º–∏'
        elif value > upper:
            return '–≤–∏—â–µ_–Ω–æ—Ä–º–∏'
        else:
            return '–Ω–æ—Ä–º–∞'
    
    data[f'{column}_category'] = data[column].apply(categorize)
    
    return data

df = categorize_by_outliers(df, '–∑–∞—Ä–ø–ª–∞—Ç–∞')
```

---

## 5. –†–æ–±–∞—Å—Ç–Ω—ñ –º–æ–¥–µ–ª—ñ

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤, —Å—Ç—ñ–π–∫–∏—Ö –¥–æ –≤–∏–∫–∏–¥—ñ–≤**

```python
# –î–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å (—Å—Ç—ñ–π–∫—ñ –¥–æ –≤–∏–∫–∏–¥—ñ–≤)
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
model.fit(X_train, y_train)

# –†–æ–±–∞—Å—Ç–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è
from sklearn.linear_model import HuberRegressor

model = HuberRegressor(epsilon=1.35)
model.fit(X_train, y_train)
```

### –†–æ–±–∞—Å—Ç–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏:
- ‚úÖ Random Forest
- ‚úÖ Gradient Boosting (XGBoost, LightGBM)
- ‚úÖ Huber Regression
- ‚úÖ RANSAC

### –ß—É—Ç–ª–∏–≤—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏:
- ‚ùå Linear Regression
- ‚ùå Logistic Regression
- ‚ùå SVM
- ‚ùå K-Nearest Neighbors

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤

| –ú–µ—Ç–æ–¥ | –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ | –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ |
|-------|----------|----------|----------------------|
| –í–∏–¥–∞–ª–µ–Ω–Ω—è | –ü—Ä–æ—Å—Ç–æ | –í—Ç—Ä–∞—Ç–∞ –¥–∞–Ω–∏—Ö | –í–∏–∫–∏–¥–∏ = –ø–æ–º–∏–ª–∫–∏ |
| Capping | –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–∞–Ω—ñ | –®—Ç—É—á–Ω—ñ –º–µ–∂—ñ | –ï–∫—Å—Ç—Ä–µ–º—É–º–∏ –Ω–µ–≤–∞–∂–ª–∏–≤—ñ |
| –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è | –ó–±–µ—Ä—ñ–≥–∞—î –ø–æ—Ä—è–¥–æ–∫ | –°–∫–ª–∞–¥–Ω–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è | –°–∫–æ—à–µ–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª |
| –†–æ–±–∞—Å—Ç–Ω—ñ –º–æ–¥–µ–ª—ñ | –ù–µ –ø–æ—Ç—Ä–µ–±—É—î –æ–±—Ä–æ–±–∫–∏ | –û–±–º–µ–∂–µ–Ω–∏–π –≤–∏–±—ñ—Ä | –ë–∞–≥–∞—Ç–æ –≤–∏–∫–∏–¥—ñ–≤ |

---

## –ü–æ–≤–Ω–∏–π Workflow

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
df = pd.read_csv('data.csv')

# 2. –í—ñ–∑—É–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Box plot
sns.boxplot(data=df, y='–∑–∞—Ä–ø–ª–∞—Ç–∞', ax=axes[0, 0])
axes[0, 0].set_title('Box Plot')

# Histogram
df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].hist(bins=50, ax=axes[0, 1])
axes[0, 1].set_title('Histogram')

# Scatter
axes[1, 0].scatter(df['–≤—ñ–∫'], df['–∑–∞—Ä–ø–ª–∞—Ç–∞'], alpha=0.5)
axes[1, 0].set_title('–í—ñ–∫ vs –ó–∞—Ä–ø–ª–∞—Ç–∞')

# Q-Q plot
stats.probplot(df['–∑–∞—Ä–ø–ª–∞—Ç–∞'], dist="norm", plot=axes[1, 1])
axes[1, 1].set_title('Q-Q Plot')

plt.tight_layout()
plt.show()

# 3. –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ (IQR)
Q1 = df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].quantile(0.25)
Q3 = df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers_mask = (df['–∑–∞—Ä–ø–ª–∞—Ç–∞'] < lower_bound) | (df['–∑–∞—Ä–ø–ª–∞—Ç–∞'] > upper_bound)
print(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏–∫–∏–¥—ñ–≤: {outliers_mask.sum()}")
print(f"–í—ñ–¥—Å–æ—Ç–æ–∫ –≤–∏–∫–∏–¥—ñ–≤: {outliers_mask.sum() / len(df) * 100:.2f}%")

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏–∫–∏–¥—ñ–≤
plt.figure(figsize=(10, 6))
plt.scatter(df.index, df['–∑–∞—Ä–ø–ª–∞—Ç–∞'], c=outliers_mask, cmap='coolwarm', alpha=0.6)
plt.axhline(y=lower_bound, color='r', linestyle='--', label='Lower Bound')
plt.axhline(y=upper_bound, color='r', linestyle='--', label='Upper Bound')
plt.xlabel('–Ü–Ω–¥–µ–∫—Å')
plt.ylabel('–ó–∞—Ä–ø–ª–∞—Ç–∞')
plt.title('–í–∏—è–≤–ª–µ–Ω—ñ –≤–∏–∫–∏–¥–∏')
plt.legend()
plt.show()

# 5. –û–±—Ä–æ–±–∫–∞ (–≤–∏–±–∏—Ä–∞—î–º–æ –º–µ—Ç–æ–¥)
# –í–∞—Ä—ñ–∞–Ω—Ç –ê: –í–∏–¥–∞–ª–µ–Ω–Ω—è
df_no_outliers = df[~outliers_mask]

# –í–∞—Ä—ñ–∞–Ω—Ç –ë: Capping
df_capped = df.copy()
df_capped['–∑–∞—Ä–ø–ª–∞—Ç–∞'] = df_capped['–∑–∞—Ä–ø–ª–∞—Ç–∞'].clip(lower_bound, upper_bound)

# –í–∞—Ä—ñ–∞–Ω—Ç –í: Log —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
df_transformed = df.copy()
df_transformed['–∑–∞—Ä–ø–ª–∞—Ç–∞_log'] = np.log1p(df_transformed['–∑–∞—Ä–ø–ª–∞—Ç–∞'])

# 6. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

df_no_outliers['–∑–∞—Ä–ø–ª–∞—Ç–∞'].hist(bins=30, ax=axes[0])
axes[0].set_title('–ü—ñ—Å–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤')

df_capped['–∑–∞—Ä–ø–ª–∞—Ç–∞'].hist(bins=30, ax=axes[1])
axes[1].set_title('–ü—ñ—Å–ª—è capping')

df_transformed['–∑–∞—Ä–ø–ª–∞—Ç–∞_log'].hist(bins=30, ax=axes[2])
axes[2].set_title('–ü—ñ—Å–ª—è log —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó')

plt.tight_layout()
plt.show()

# 7. –í–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É
print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ===")
print(f"–û—Ä–∏–≥—ñ–Ω–∞–ª - Mean: {df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].mean():.2f}, Std: {df['–∑–∞—Ä–ø–ª–∞—Ç–∞'].std():.2f}")
print(f"–ë–µ–∑ –≤–∏–∫–∏–¥—ñ–≤ - Mean: {df_no_outliers['–∑–∞—Ä–ø–ª–∞—Ç–∞'].mean():.2f}, Std: {df_no_outliers['–∑–∞—Ä–ø–ª–∞—Ç–∞'].std():.2f}")
print(f"Capped - Mean: {df_capped['–∑–∞—Ä–ø–ª–∞—Ç–∞'].mean():.2f}, Std: {df_capped['–∑–∞—Ä–ø–ª–∞—Ç–∞'].std():.2f}")
```

---

## Best Practices üí°

### 1. –ó–∞–≤–∂–¥–∏ –≤—ñ–∑—É–∞–ª—ñ–∑—É–π—Ç–µ

```python
# –ü–µ—Ä–µ–¥ —ñ –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

sns.boxplot(data=df, y='—Ü—ñ–Ω–∞', ax=axes[0])
axes[0].set_title('–î–æ –æ–±—Ä–æ–±–∫–∏')

sns.boxplot(data=df_processed, y='—Ü—ñ–Ω–∞', ax=axes[1])
axes[1].set_title('–ü—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏')
```

### 2. –†–æ–∑—É–º—ñ–π—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç

**–ù–µ –≤—Å—ñ –≤–∏–∫–∏–¥–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–¥–∞–ª—è—Ç–∏!**
- –í–∏—Å–æ–∫–∞ —Ü—ñ–Ω–∞ –±—É–¥–∏–Ω–∫—É –≤ –µ–ª—ñ—Ç–Ω–æ–º—É —Ä–∞–π–æ–Ω—ñ ‚Äî —Ü–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
- –ê–Ω–æ–º–∞–ª—å–Ω–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—è –º–æ–∂–µ –±—É—Ç–∏ —à–∞—Ö—Ä–∞–π—Å—Ç–≤–æ–º (–≤–∞–∂–ª–∏–≤–∞!)

### 3. –î–æ–∫—É–º–µ–Ω—Ç—É–π—Ç–µ —Ä—ñ—à–µ–Ω–Ω—è

```python
# –°—Ç–≤–æ—Ä—é—î–º–æ –∑–≤—ñ—Ç
outlier_report = {
    '–º–µ—Ç–æ–¥_–≤–∏—è–≤–ª–µ–Ω–Ω—è': 'IQR',
    '–º–µ—Ç–æ–¥_–æ–±—Ä–æ–±–∫–∏': 'capping',
    '–∫—ñ–ª—å–∫—ñ—Å—Ç—å_–≤–∏–∫–∏–¥—ñ–≤': outliers_mask.sum(),
    '–≤—ñ–¥—Å–æ—Ç–æ–∫': f"{outliers_mask.sum() / len(df) * 100:.2f}%",
    '–Ω–∏–∂–Ω—è_–º–µ–∂–∞': lower_bound,
    '–≤–µ—Ä—Ö–Ω—è_–º–µ–∂–∞': upper_bound
}

import json
with open('outlier_report.json', 'w') as f:
    json.dump(outlier_report, f, indent=2)
```

### 4. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ domain knowledge
–ö–æ–Ω—Å—É–ª—å—Ç—É–π—Ç–µ—Å—è –∑ –µ–∫—Å–ø–µ—Ä—Ç–∞–º–∏ –≤ –ø—Ä–µ–¥–º–µ—Ç–Ω—ñ–π –æ–±–ª–∞—Å—Ç—ñ!

### 5. A/B —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è

```python
# –ü–æ—Ä—ñ–≤–Ω—è–π—Ç–µ –º–æ–¥–µ–ª—ñ –∑ —Ä—ñ–∑–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é –≤–∏–∫–∏–¥—ñ–≤
from sklearn.model_selection import cross_val_score

# –ó –≤–∏–∫–∏–¥–∞–º–∏
score_with = cross_val_score(model, X_with_outliers, y, cv=5).mean()

# –ë–µ–∑ –≤–∏–∫–∏–¥—ñ–≤
score_without = cross_val_score(model, X_without_outliers, y_clean, cv=5).mean()

print(f"–ó –≤–∏–∫–∏–¥–∞–º–∏: {score_with:.4f}")
print(f"–ë–µ–∑ –≤–∏–∫–∏–¥—ñ–≤: {score_without:.4f}")
```

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –≤—Å—ñ—Ö –≤–∏–∫–∏–¥—ñ–≤

```python
# ‚ùå –ù–ï —Ä–æ–±—ñ—Ç—å —Ç–∞–∫ –±–µ–∑ –∞–Ω–∞–ª—ñ–∑—É!
df = df[df['—Ü—ñ–Ω–∞'] < df['—Ü—ñ–Ω–∞'].quantile(0.99)]
```

### 2. –û–±—Ä–æ–±–∫–∞ –ø—ñ—Å–ª—è train-test split

```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
X_train, X_test = train_test_split(X, y)
X_train = remove_outliers(X_train)  # –í–∏—Ç—ñ–∫ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó!

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
X_clean = remove_outliers(X)
X_train, X_test = train_test_split(X_clean, y)
```

### 3. –Ü–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –≤–∏–∫–∏–¥—ñ–≤

```python
# –û–∫—Ä–µ–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è OK, –∞–ª–µ —Ä–∞–∑–æ–º ‚Äî –≤–∏–∫–∏–¥
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ Isolation Forest –∞–±–æ LOF
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_Feature_Scaling]] ‚Äî –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ –≤–∏–∫–∏–¥—ñ–≤
- [[03_Missing_Values]] ‚Äî –ø—Ä–æ–ø—É—Å–∫–∏ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ –≤–∏–∫–∏–¥–∞–º–∏
- [[Feature_Engineering]] ‚Äî —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–∑–Ω–∞–∫ –∑ –≤–∏–∫–∏–¥—ñ–≤

## –†–µ—Å—É—Ä—Å–∏
- [Scikit-learn Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)
- [PyOD Library](https://pyod.readthedocs.io/)

---

#ml #preprocessing #outliers #anomaly-detection #datascience
