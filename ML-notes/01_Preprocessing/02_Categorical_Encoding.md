# Categorical Encoding (–ö–æ–¥—É–≤–∞–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö)

## –©–æ —Ü–µ?

–ö–æ–¥—É–≤–∞–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö ‚Äî —Ü–µ –ø—Ä–æ—Ü–µ—Å –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –∞–±–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É —á–∏—Å–ª–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç, –∑—Ä–æ–∑—É–º—ñ–ª–∏–π –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ?

üî¢ **–ë—ñ–ª—å—à—ñ—Å—Ç—å ML-–∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –ø—Ä–∞—Ü—é—î —Ç—ñ–ª—å–∫–∏ –∑ —á–∏—Å–ª–∞–º–∏**
- –ù–µ –º–æ–∂—É—Ç—å –æ–±—Ä–æ–±–ª—è—Ç–∏ —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É
- –ü–æ—Ç—Ä–µ–±—É—é—Ç—å —á–∏—Å–ª–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–π

---

## –¢–∏–ø–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö

### 1. Nominal (–ù–æ–º—ñ–Ω–∞–ª—å–Ω—ñ)

**–ë–µ–∑ –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫—É**
- –ö–æ–ª—ñ—Ä: [—á–µ—Ä–≤–æ–Ω–∏–π, –∑–µ–ª–µ–Ω–∏–π, —Å–∏–Ω—ñ–π]
- –ö—Ä–∞—ó–Ω–∞: [–£–∫—Ä–∞—ó–Ω–∞, –ü–æ–ª—å—â–∞, –ù—ñ–º–µ—á—á–∏–Ω–∞]
- –¢–∏–ø –ø—Ä–æ–¥—É–∫—Ç—É: [–µ–ª–µ–∫—Ç—Ä–æ–Ω—ñ–∫–∞, –æ–¥—è–≥, —ó–∂–∞]

### 2. Ordinal (–ü–æ—Ä—è–¥–∫–æ–≤—ñ)

**–ó –ø—Ä–∏—Ä–æ–¥–Ω–∏–º –ø–æ—Ä—è–¥–∫–æ–º**
- –û—Å–≤—ñ—Ç–∞: [—à–∫–æ–ª–∞, –±–∞–∫–∞–ª–∞–≤—Ä, –º–∞–≥—ñ—Å—Ç—Ä, PhD]
- –†–æ–∑–º—ñ—Ä: [S, M, L, XL]
- –†–µ–π—Ç–∏–Ω–≥: [–Ω–∏–∑—å–∫–∏–π, —Å–µ—Ä–µ–¥–Ω—ñ–π, –≤–∏—Å–æ–∫–∏–π]

---

## –ú–µ—Ç–æ–¥–∏ –∫–æ–¥—É–≤–∞–Ω–Ω—è

## 1. Label Encoding (–ú—ñ—á–µ–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è)

### –©–æ —Ä–æ–±–∏—Ç—å?

–ü—Ä–∏—Å–≤–æ—é—î –∫–æ–∂–Ω—ñ–π —É–Ω—ñ–∫–∞–ª—å–Ω—ñ–π –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó —á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–¥ 0 –¥–æ n-1.

### –ü—Ä–∏–∫–ª–∞–¥

```
–í—Ö—ñ–¥:  [—Å–æ–±–∞–∫–∞, –∫—ñ—Ç, —Å–æ–±–∞–∫–∞, –ø—Ç–∞—Ö, –∫—ñ—Ç]
–í–∏—Ö—ñ–¥: [0, 1, 0, 2, 1]
```

### –ö–æ–¥ (scikit-learn)

```python
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

# –î–ª—è –æ–¥–Ω–æ–≥–æ —Å—Ç–æ–≤–ø—Ü—è
sizes = ['S', 'M', 'L', 'XL', 'M', 'S']
sizes_encoded = encoder.fit_transform(sizes)
print(sizes_encoded)  # [0 1 2 3 1 0]

# –ó–≤–æ—Ä–æ—Ç–Ω—î –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è
sizes_original = encoder.inverse_transform(sizes_encoded)
print(sizes_original)  # ['S' 'M' 'L' 'XL' 'M' 'S']
```

### Pandas –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

```python
import pandas as pd

df['size_encoded'] = pd.Categorical(df['size']).codes
```

### ‚ö†Ô∏è –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ **–¢—ñ–ª—å–∫–∏ –¥–ª—è –ø–æ—Ä—è–¥–∫–æ–≤–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö** (–¥–µ –ø–æ—Ä—è–¥–æ–∫ –º–∞—î –∑–Ω–∞—á–µ–Ω–Ω—è)
‚úÖ Target variable (—Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞) –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
‚úÖ –î–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å –º–æ–∂—É—Ç—å –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –∑ Label Encoding

‚ùå **–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –¥–ª—è –Ω–æ–º—ñ–Ω–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö** –∑ –±—ñ–ª—å—à—ñ—Å—Ç—é –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤

- –°—Ç–≤–æ—Ä—é—î —à—Ç—É—á–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ (0 < 1 < 2)
- –ú–æ–¥–µ–ª—å –º–æ–∂–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ —Ü–µ —è–∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ –≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è

---

## 2. Ordinal Encoding (–ü–æ—Ä—è–¥–∫–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è)

### –©–æ —Ä–æ–±–∏—Ç—å?

–°—Ö–æ–∂–µ –Ω–∞ Label Encoding, –∞–ª–µ **–∑ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—é –∑–∞–¥–∞—Ç–∏ —Å–≤—ñ–π –ø–æ—Ä—è–¥–æ–∫**.

### –ö–æ–¥

```python
from sklearn.preprocessing import OrdinalEncoder

# –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
encoder = OrdinalEncoder(
    categories=[['–Ω–∏–∑—å–∫–∏–π', '—Å–µ—Ä–µ–¥–Ω—ñ–π', '–≤–∏—Å–æ–∫–∏–π', '–¥—É–∂–µ –≤–∏—Å–æ–∫–∏–π']]
)

education = [['–Ω–∏–∑—å–∫–∏–π'], ['–≤–∏—Å–æ–∫–∏–π'], ['—Å–µ—Ä–µ–¥–Ω—ñ–π'], ['–Ω–∏–∑—å–∫–∏–π']]
encoded = encoder.fit_transform(education)
print(encoded)  # [[0.], [2.], [1.], [0.]]
```

### –ü—Ä–∏–∫–ª–∞–¥ –∑ DataFrame

```python
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder

df = pd.DataFrame({
    '–æ—Å–≤—ñ—Ç–∞': ['—à–∫–æ–ª–∞', '–±–∞–∫–∞–ª–∞–≤—Ä', '–º–∞–≥—ñ—Å—Ç—Ä', '–±–∞–∫–∞–ª–∞–≤—Ä', 'PhD'],
    '–¥–æ—Å–≤—ñ–¥': ['junior', 'middle', 'senior', 'middle', 'senior']
})

encoder = OrdinalEncoder(
    categories=[
        ['—à–∫–æ–ª–∞', '–±–∞–∫–∞–ª–∞–≤—Ä', '–º–∞–≥—ñ—Å—Ç—Ä', 'PhD'],
        ['junior', 'middle', 'senior']
    ]
)

df[['–æ—Å–≤—ñ—Ç–∞_encoded', '–¥–æ—Å–≤—ñ–¥_encoded']] = encoder.fit_transform(
    df[['–æ—Å–≤—ñ—Ç–∞', '–¥–æ—Å–≤—ñ–¥']]
)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ –ü–æ—Ä—è–¥–∫–æ–≤—ñ –∑–º—ñ–Ω–Ω—ñ –∑ —á—ñ—Ç–∫–æ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º –ø–æ—Ä—è–¥–∫–æ–º
‚úÖ –ö–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –ø–æ—Ä—è–¥–∫–æ–º –∫–æ–¥—É–≤–∞–Ω–Ω—è
‚úÖ –†–µ–π—Ç–∏–Ω–≥–∏, —Ä—ñ–≤–Ω—ñ, —Ä–æ–∑–º—ñ—Ä–∏ —Ç–æ—â–æ

---

## 3. One-Hot Encoding (–ë—ñ–Ω–∞—Ä–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è)

### –©–æ —Ä–æ–±–∏—Ç—å?
–°—Ç–≤–æ—Ä—é—î **–æ–∫—Ä–µ–º–∏–π –±—ñ–Ω–∞—Ä–Ω–∏–π —Å—Ç–æ–≤–ø–µ—Ü—å –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó**.

### –ü—Ä–∏–∫–ª–∞–¥
```
–í—Ö—ñ–¥:  [—á–µ—Ä–≤–æ–Ω–∏–π, –∑–µ–ª–µ–Ω–∏–π, —Å–∏–Ω—ñ–π, —á–µ—Ä–≤–æ–Ω–∏–π]

–í–∏—Ö—ñ–¥:
    —á–µ—Ä–≤–æ–Ω–∏–π  –∑–µ–ª–µ–Ω–∏–π  —Å–∏–Ω—ñ–π
    1         0        0
    0         1        0
    0         0        1
    1         0        0
```

### –ö–æ–¥ (pandas)

```python
import pandas as pd

df = pd.DataFrame({'–∫–æ–ª—ñ—Ä': ['—á–µ—Ä–≤–æ–Ω–∏–π', '–∑–µ–ª–µ–Ω–∏–π', '—Å–∏–Ω—ñ–π', '—á–µ—Ä–≤–æ–Ω–∏–π']})

# One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['–∫–æ–ª—ñ—Ä'], prefix='–∫–æ–ª—ñ—Ä')
print(df_encoded)
```

### –ö–æ–¥ (scikit-learn)

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False)  # sparse=False –¥–ª—è –≥—É—Å—Ç–æ–≥–æ –º–∞—Å–∏–≤—É

colors = [['—á–µ—Ä–≤–æ–Ω–∏–π'], ['–∑–µ–ª–µ–Ω–∏–π'], ['—Å–∏–Ω—ñ–π'], ['—á–µ—Ä–≤–æ–Ω–∏–π']]
encoded = encoder.fit_transform(colors)

# –û—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–∞–∑–≤ —Å—Ç–æ–≤–ø—Ü—ñ–≤
feature_names = encoder.get_feature_names_out(['–∫–æ–ª—ñ—Ä'])
df_encoded = pd.DataFrame(encoded, columns=feature_names)
```

### –û–±—Ä–æ–±–∫–∞ –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π

```python
encoder = OneHotEncoder(
    handle_unknown='ignore',  # –Ü–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ –Ω–µ–≤—ñ–¥–æ–º—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
    sparse_output=False
)
```

### Drop first (—É–Ω–∏–∫–Ω–µ–Ω–Ω—è –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω–æ—Å—Ç—ñ)

```python
# Pandas
df_encoded = pd.get_dummies(df, columns=['–∫–æ–ª—ñ—Ä'], drop_first=True)

# Scikit-learn
encoder = OneHotEncoder(drop='first', sparse_output=False)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

‚úÖ **–ù–æ–º—ñ–Ω–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ** (–±–µ–∑ –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫—É)
‚úÖ –ù–µ–≤–µ–ª–∏–∫–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (< 10-15)
‚úÖ –õ—ñ–Ω—ñ–π–Ω—ñ –º–æ–¥–µ–ª—ñ, SVM, –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ

‚ùå –£–Ω–∏–∫–∞—Ç–∏ –ø—Ä–∏ –≤–µ–ª–∏–∫—ñ–π –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (curse of dimensionality)

---

## 4. Binary Encoding (–ë—ñ–Ω–∞—Ä–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –±—ñ—Ç–∏)

### –©–æ —Ä–æ–±–∏—Ç—å?
–ö–æ–º–±—ñ–Ω—É—î Label Encoding —ñ One-Hot Encoding —á–µ—Ä–µ–∑ –±—ñ–Ω–∞—Ä–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è.

### –ü—Ä–∏–∫–ª–∞–¥
```
–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó: A, B, C, D, E (5 –∫–∞—Ç–µ–≥–æ—Ä—ñ–π)

Label:    0,  1,  2,  3,  4
Binary:   00, 01, 10, 11, 100

–†–µ–∑—É–ª—å—Ç–∞—Ç: 3 —Å—Ç–æ–≤–ø—Ü—ñ –∑–∞–º—ñ—Å—Ç—å 5
    bit_0  bit_1  bit_2
A   0      0      0
B   0      0      1
C   0      1      0
D   0      1      1
E   1      0      0
```

### –ö–æ–¥ (category_encoders)
```python
import category_encoders as ce

encoder = ce.BinaryEncoder(cols=['category'])
df_encoded = encoder.fit_transform(df)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?
‚úÖ –ë–∞–≥–∞—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (–¥–µ—Å—è—Ç–∫–∏ –∞–±–æ —Å–æ—Ç–Ω—ñ)
‚úÖ –ü–æ—Ç—Ä—ñ–±–Ω–æ –∑–º–µ–Ω—à–∏—Ç–∏ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ One-Hot
‚úÖ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ One-Hot –¥–ª—è –≤–∏—Å–æ–∫–æ—ó –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ

---

## 5. Target Encoding (–ö–æ–¥—É–≤–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó)

### –©–æ —Ä–æ–±–∏—Ç—å?
–ó–∞–º—ñ–Ω—é—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é **—Å–µ—Ä–µ–¥–Ω—ñ–º –∑–Ω–∞—á–µ–Ω–Ω—è–º target** –¥–ª—è —Ü—ñ—î—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó.

### –ü—Ä–∏–∫–ª–∞–¥ (–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è)
```python
–ú—ñ—Å—Ç–æ        | –ö—É–ø–∏–≤ (0/1)
-------------|------------
–ö–∏—ó–≤         | 1
–õ—å–≤—ñ–≤        | 0
–ö–∏—ó–≤         | 1
–•–∞—Ä–∫—ñ–≤       | 1
–õ—å–≤—ñ–≤        | 0
–ö–∏—ó–≤         | 0

Target Encoding:
–ö–∏—ó–≤  ‚Üí (1+1+0)/3 = 0.67
–õ—å–≤—ñ–≤ ‚Üí (0+0)/2 = 0.0
–•–∞—Ä–∫—ñ–≤ ‚Üí 1/1 = 1.0
```

### –ö–æ–¥ (category_encoders)
```python
import category_encoders as ce

encoder = ce.TargetEncoder(cols=['–º—ñ—Å—Ç–æ'])

# –í–∞–∂–ª–∏–≤–æ: fit –Ω–∞ train, transform –Ω–∞ train —ñ test –æ–∫—Ä–µ–º–æ
X_train_encoded = encoder.fit_transform(X_train, y_train)
X_test_encoded = encoder.transform(X_test)
```

### ‚ö†Ô∏è –†–∏–∑–∏–∫ overfitting!
**–†–æ–∑–≤'—è–∑–∞–Ω–Ω—è: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –∞–±–æ CV**
```python
encoder = ce.TargetEncoder(
    cols=['–∫–∞—Ç–µ–≥–æ—Ä—ñ—è'],
    smoothing=1.0  # –ó–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è
)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?
‚úÖ –í–∏—Å–æ–∫–æ-–∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó (—Å–æ—Ç–Ω—ñ/—Ç–∏—Å—è—á—ñ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å)
‚úÖ Gradient Boosting –º–æ–¥–µ–ª—ñ (XGBoost, LightGBM, CatBoost)
‚úÖ –ö–æ–ª–∏ —î —Å–∏–ª—å–Ω–∞ –∑–∞–ª–µ–∂–Ω—ñ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –≤—ñ–¥ target

‚ùå –û–±–µ—Ä–µ–∂–Ω–æ –∑ overfitting!

---

## 6. Frequency Encoding (–ö–æ–¥—É–≤–∞–Ω–Ω—è —á–∞—Å—Ç–æ—Ç–æ—é)

### –©–æ —Ä–æ–±–∏—Ç—å?
–ó–∞–º—ñ–Ω—é—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é —ó—ó **—á–∞—Å—Ç–æ—Ç–æ—é –ø–æ—è–≤–∏** –≤ –¥–∞–Ω–∏—Ö.

### –ü—Ä–∏–∫–ª–∞–¥
```python
–ö–æ–ª—ñ—Ä     | –ö—ñ–ª—å–∫—ñ—Å—Ç—å
----------|----------
—á–µ—Ä–≤–æ–Ω–∏–π  | 50
–∑–µ–ª–µ–Ω–∏–π   | 30
—Å–∏–Ω—ñ–π     | 20

Frequency Encoding:
—á–µ—Ä–≤–æ–Ω–∏–π ‚Üí 50/100 = 0.50
–∑–µ–ª–µ–Ω–∏–π  ‚Üí 30/100 = 0.30
—Å–∏–Ω—ñ–π    ‚Üí 20/100 = 0.20
```

### –ö–æ–¥ (–≤—Ä—É—á–Ω—É)
```python
freq = df['–∫–æ–ª—ñ—Ä'].value_counts(normalize=True)
df['–∫–æ–ª—ñ—Ä_freq'] = df['–∫–æ–ª—ñ—Ä'].map(freq)
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?
‚úÖ –í–∏—Å–æ–∫–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å
‚úÖ –ß–∞—Å—Ç–æ—Ç–∞ –º–∞—î –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó
‚úÖ –®–≤–∏–¥–∫–∏–π —Ç–∞ –ø—Ä–æ—Å—Ç–∏–π –º–µ—Ç–æ–¥

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤

| –ú–µ—Ç–æ–¥ | –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å | Nominal | Ordinal | –í–∏—Å–æ–∫–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å | –†–∏–∑–∏–∫ overfitting |
|-------|-------------|---------|---------|----------------------|-------------------|
| Label Encoding | –ù–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è | ‚ùå | ‚úÖ | ‚úÖ | –ù–∏–∑—å–∫–∏–π |
| Ordinal Encoding | –ù–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è | ‚ùå | ‚úÖ | ‚úÖ | –ù–∏–∑—å–∫–∏–π |
| One-Hot Encoding | ++(n-1) | ‚úÖ | ‚ùå | ‚ùå | –ù–∏–∑—å–∫–∏–π |
| Binary Encoding | +log‚ÇÇ(n) | ‚úÖ | ‚ùå | ‚úÖ | –ù–∏–∑—å–∫–∏–π |
| Target Encoding | –ù–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è | ‚úÖ | ‚úÖ | ‚úÖ | **–í–∏—Å–æ–∫–∏–π** ‚ö†Ô∏è |
| Frequency Encoding | –ù–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è | ‚úÖ | ‚ùå | ‚úÖ | –°–µ—Ä–µ–¥–Ω—ñ–π |

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ó–∞–≤–∂–¥–∏ fit –Ω–∞ train, transform –Ω–∞ test
```python
# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
encoder.fit(X_train)
X_train_enc = encoder.transform(X_train)
X_test_enc = encoder.transform(X_test)

# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
encoder.fit(X_test)  # –í–∏—Ç—ñ–∫ –¥–∞–Ω–∏—Ö!
```

### 2. –û–±—Ä–æ–±–∫–∞ –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
```python
# One-Hot
encoder = OneHotEncoder(handle_unknown='ignore')

# Target Encoding
encoder = ce.TargetEncoder(handle_unknown='value')
```

### 3. –ü–æ—î–¥–Ω–∞–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤
```python
# –ù–∏–∑—å–∫–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å ‚Üí One-Hot
# –í–∏—Å–æ–∫–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å ‚Üí Target/Frequency

if df['–∫–∞—Ç–µ–≥–æ—Ä—ñ—è'].nunique() < 10:
    encoder = OneHotEncoder()
else:
    encoder = ce.TargetEncoder()
```

---

## –ü–æ–≤–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
import category_encoders as ce

# –î–∞–Ω—ñ
df = pd.DataFrame({
    '–∫–æ–ª—ñ—Ä': ['—á–µ—Ä–≤–æ–Ω–∏–π', '–∑–µ–ª–µ–Ω–∏–π', '—Å–∏–Ω—ñ–π', '—á–µ—Ä–≤–æ–Ω–∏–π', '–∑–µ–ª–µ–Ω–∏–π'],
    '—Ä–æ–∑–º—ñ—Ä': ['S', 'M', 'L', 'M', 'S'],
    '–º—ñ—Å—Ç–æ': ['–ö–∏—ó–≤', '–õ—å–≤—ñ–≤', '–ö–∏—ó–≤', '–û–¥–µ—Å–∞', '–õ—å–≤—ñ–≤'],
    '—Ü—ñ–Ω–∞': [100, 150, 200, 120, 90]
})

X = df.drop('—Ü—ñ–Ω–∞', axis=1)
y = df['—Ü—ñ–Ω–∞']

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 1. One-Hot –¥–ª—è –∫–æ–ª—å–æ—Ä—É (–Ω–æ–º—ñ–Ω–∞–ª—å–Ω–∞, –Ω–∏–∑—å–∫–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å)
onehot = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
color_train = onehot.fit_transform(X_train[['–∫–æ–ª—ñ—Ä']])
color_test = onehot.transform(X_test[['–∫–æ–ª—ñ—Ä']])

# 2. Ordinal –¥–ª—è —Ä–æ–∑–º—ñ—Ä—É (–ø–æ—Ä—è–¥–∫–æ–≤–∞)
ordinal = OrdinalEncoder(categories=[['S', 'M', 'L', 'XL']])
size_train = ordinal.fit_transform(X_train[['—Ä–æ–∑–º—ñ—Ä']])
size_test = ordinal.transform(X_test[['—Ä–æ–∑–º—ñ—Ä']])

# 3. Target –¥–ª—è –º—ñ—Å—Ç–∞ (–≤–∏—Å–æ–∫–∞ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∞ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ñ—Å—Ç—å)
target_enc = ce.TargetEncoder(cols=['–º—ñ—Å—Ç–æ'])
city_train = target_enc.fit_transform(X_train[['–º—ñ—Å—Ç–æ']], y_train)
city_test = target_enc.transform(X_test[['–º—ñ—Å—Ç–æ']])

# –û–±'—î–¥–Ω–∞–Ω–Ω—è
import numpy as np
X_train_final = np.hstack([color_train, size_train, city_train])
X_test_final = np.hstack([color_test, size_test, city_test])

print(f"Train shape: {X_train_final.shape}")
print(f"Test shape: {X_test_final.shape}")
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏
- [[01_Feature_Scaling]] ‚Äî –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫
- [[03_Missing_Values]] ‚Äî –æ–±—Ä–æ–±–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
- [[Feature_Engineering]] ‚Äî —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –æ–∑–Ω–∞–∫

## –†–µ—Å—É—Ä—Å–∏
- [Scikit-learn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)
- [Category Encoders Library](https://contrib.scikit-learn.org/category_encoders/)

---

#ml #preprocessing #encoding #categorical #datascience
