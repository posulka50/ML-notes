# Train-Test Split (–†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π —Ç–∞ —Ç–µ—Å—Ç–æ–≤–∏–π –Ω–∞–±–æ—Ä–∏)

## –©–æ —Ü–µ?

**Train-Test Split** ‚Äî —Ü–µ –ø—Ä–æ—Ü–µ—Å **—Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É –Ω–∞ –¥–≤—ñ —á–∞—Å—Ç–∏–Ω–∏**: –æ–¥–Ω–∞ –¥–ª—è **–Ω–∞–≤—á–∞–Ω–Ω—è** –º–æ–¥–µ–ª—ñ (train set), –¥—Ä—É–≥–∞ –¥–ª—è **–æ—Ü—ñ–Ω–∫–∏** —ó—ó –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (test set).

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** –º–æ–¥–µ–ª—å –Ω–∞–≤—á–∞—î—Ç—å—Å—è –Ω–∞ train set, –∞ –æ—Ü—ñ–Ω—é—î—Ç—å—Å—è –Ω–∞ test set, —è–∫–∏–π –≤–æ–Ω–∞ **–Ω—ñ–∫–æ–ª–∏ –Ω–µ –±–∞—á–∏–ª–∞** –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è. –¶–µ –¥–æ–∑–≤–æ–ª—è—î –æ–±'—î–∫—Ç–∏–≤–Ω–æ –æ—Ü—ñ–Ω–∏—Ç–∏ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ **—É–∑–∞–≥–∞–ª—å–Ω—é–≤–∞—Ç–∏** –Ω–∞ –Ω–æ–≤—ñ –¥–∞–Ω—ñ.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ?

- üéØ **–û–±'—î–∫—Ç–∏–≤–Ω–∞ –æ—Ü—ñ–Ω–∫–∞** ‚Äî —è–∫ –º–æ–¥–µ–ª—å –ø—Ä–∞—Ü—é—î –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
- üîç **–í–∏—è–≤–ª–µ–Ω–Ω—è overfitting** ‚Äî —á–∏ –Ω–µ –∑–∞–ø–∞–º'—è—Ç–∞–ª–∞ –º–æ–¥–µ–ª—å train set
- üìä **–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π** ‚Äî —á–µ—Å–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—è
- ‚ö†Ô∏è **–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º** ‚Äî before production
- üí° **–í–∏–±—ñ—Ä –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤** ‚Äî —Ä–∞–∑–æ–º –∑ validation set
- üöÄ **Production-ready** ‚Äî –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å —É —è–∫–æ—Å—Ç—ñ

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ó–∞–≤–∂–¥–∏! üî•**
- –ë—É–¥—å-—è–∫–∞ –∑–∞–¥–∞—á–∞ ML (—Ä–µ–≥—Ä–µ—Å—ñ—è, –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏)
- –ü–µ—Ä–µ–¥ –Ω–∞–≤—á–∞–Ω–Ω—è–º –º–æ–¥–µ–ª—ñ
- –ü—Ä–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
- –ö–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∞ —á–µ—Å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞

**–í–∏–Ω—è—Ç–æ–∫:**
- Time series (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è time-based split)
- Cross-validation (–∞–ª–µ –Ω–∞–≤—ñ—Ç—å —Ç–æ–¥—ñ –ø–æ—Ç—Ä—ñ–±–µ–Ω final test set)

---

## –û—Å–Ω–æ–≤–Ω–∏–π –ø—Ä–∏–Ω—Ü–∏–ø

### –ß–æ–º—É –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ä–æ–∑–¥—ñ–ª—è—Ç–∏?

```python
# ‚ùå –ü–û–ì–ê–ù–û: –æ—Ü—ñ–Ω–∫–∞ –Ω–∞ —Ç–∏—Ö —Å–∞–º–∏—Ö –¥–∞–Ω–∏—Ö, –Ω–∞ —è–∫–∏—Ö –Ω–∞–≤—á–∞–ª–∞—Å—è
model.fit(X, y)
score = model.score(X, y)  # –ú–æ–∂–µ –±—É—Ç–∏ 100%, –∞–ª–µ —Ü–µ –Ω—ñ—á–æ–≥–æ –Ω–µ –æ–∑–Ω–∞—á–∞—î!

# ‚úÖ –î–û–ë–†–ï: –æ—Ü—ñ–Ω–∫–∞ –Ω–∞ –ù–û–í–ò–• –¥–∞–Ω–∏—Ö
X_train, X_test, y_train, y_test = train_test_split(X, y)
model.fit(X_train, y_train)
score = model.score(X_test, y_test)  # –†–µ–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞!
```

### –í—ñ–∑—É–∞–ª—å–Ω–∞ —ñ–Ω—Ç—É—ó—Ü—ñ—è

```
–í–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç (100%):
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ïë
‚ïë ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Train-Test Split (70/30):
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë TRAIN SET (70%)          ‚ïë TEST      ‚ïë
‚ïë –ú–æ–¥–µ–ª—å –ë–ê–ß–ò–¢–¨ —Ü—ñ –¥–∞–Ω—ñ ‚úì  ‚ïë –ú–æ–¥–µ–ª—å    ‚ïë
‚ïë –ù–∞–≤—á–∞—î—Ç—å—Å—è —Ç—É—Ç            ‚ïë –ù–ï –ë–ê–ß–ò–¢–¨ ‚ïë
‚ïë ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢    ‚ïë —Ü—ñ –¥–∞–Ω—ñ ‚úó ‚ïë
‚ïë ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢    ‚ïë ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
                           ‚îÇ
                           ‚îî‚îÄ> –û—Ü—ñ–Ω–∫–∞ —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è
```

---

## –ë–∞–∑–æ–≤–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è (Scikit-learn)

### –ù–∞–π–ø—Ä–æ—Å—Ç—ñ—à–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
from sklearn.model_selection import train_test_split
import numpy as np

# –î–∞–Ω—ñ
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([1, 2, 3, 4, 5])

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è: 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% –¥–ª—è test
    random_state=42     # –í—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
)

print(f"X shape: {X.shape}")
print(f"X_train shape: {X_train.shape}")  # (4, 2) - 80%
print(f"X_test shape: {X_test.shape}")    # (1, 2) - 20%
```

### –ó —Ä–µ–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏

```python
from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö (–ø—Ä–∏–∫–ª–∞–¥)
# boston = load_boston()
# X = boston.data
# y = boston.target

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (boston deprecated):
from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
X = housing.data
y = housing.target

print(f"Dataset size: {X.shape[0]} samples")
print(f"Features: {X.shape[1]}")

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,     # 30% –¥–ª—è —Ç–µ—Å—Ç—É
    random_state=42
)

print(f"\nTrain set: {X_train.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
model = LinearRegression()
model.fit(X_train, y_train)

# –û—Ü—ñ–Ω–∫–∞ –Ω–∞ train
y_train_pred = model.predict(X_train)
train_r2 = r2_score(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

# –û—Ü—ñ–Ω–∫–∞ –Ω–∞ test
y_test_pred = model.predict(X_test)
test_r2 = r2_score(y_test, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

print(f"\n{'='*50}")
print(f"RESULTS")
print(f"{'='*50}")
print(f"Train R¬≤: {train_r2:.4f} | RMSE: {train_rmse:.4f}")
print(f"Test R¬≤:  {test_r2:.4f} | RMSE: {test_rmse:.4f}")
print(f"Gap:      {train_r2 - test_r2:.4f}")

if train_r2 - test_r2 > 0.1:
    print("‚ö†Ô∏è  Large gap ‚Üí possible overfitting")
elif test_r2 < 0.6:
    print("‚ö†Ô∏è  Low test score ‚Üí possible underfitting")
else:
    print("‚úÖ Good balance!")
```

---

## –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ train_test_split

### test_size

**–†–æ–∑–º—ñ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä—É** (—á–∞—Å—Ç–∫–∞ –∞–±–æ –∞–±—Å–æ–ª—é—Ç–Ω–µ —á–∏—Å–ª–æ).

```python
# –ß–∞—Å—Ç–∫–∞ (–Ω–∞–π—á–∞—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2  # 20% –¥–ª—è test
)

# –ê–±—Å–æ–ª—é—Ç–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=100  # –†—ñ–≤–Ω–æ 100 –∑—Ä–∞–∑–∫—ñ–≤ –¥–ª—è test
)

# –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º test_size=0.25 (25%)
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
- **–ú–∞–ª–∏–π –¥–∞—Ç–∞—Å–µ—Ç** (< 1000): `test_size=0.2-0.3` (20-30%)
- **–°–µ—Ä–µ–¥–Ω—ñ–π –¥–∞—Ç–∞—Å–µ—Ç** (1000-10000): `test_size=0.2` (20%)
- **–í–µ–ª–∏–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç** (> 10000): `test_size=0.1-0.2` (10-20%)

### train_size

**–†–æ–∑–º—ñ—Ä —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É** (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ test_size).

```python
# –ú–æ–∂–Ω–∞ –≤–∫–∞–∑–∞—Ç–∏ train_size –∑–∞–º—ñ—Å—Ç—å test_size
X_train, X_test, y_train, y_test = train_test_split(
    X, y, train_size=0.8  # 80% –¥–ª—è train ‚Üí 20% –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –¥–ª—è test
)

# –ê–±–æ –æ–±–∏–¥–≤–∞ (–º–∞—é—Ç—å —Å—É–º—É–≤–∞—Ç–∏—Å—è –¥–æ 1.0)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, train_size=0.7, test_size=0.3
)
```

### random_state

**Seed –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö —á–∏—Å–µ–ª** ‚Äî –∑–∞–±–µ–∑–ø–µ—á—É—î **–≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å**.

```python
# –ó random_state ‚Äî –∑–∞–≤–∂–¥–∏ –æ–¥–Ω–∞–∫–æ–≤–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
X_train1, X_test1, y_train1, y_test1 = train_test_split(
    X, y, test_size=0.3, random_state=42
)

X_train2, X_test2, y_train2, y_test2 = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# X_train1 == X_train2 ‚úì (—ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ)

# –ë–µ–∑ random_state ‚Äî –∫–æ–∂–µ–Ω —Ä–∞–∑ —Ä—ñ–∑–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
X_train3, X_test3, y_train3, y_test3 = train_test_split(
    X, y, test_size=0.3  # random_state=None (default)
)
# X_train3 != X_train1 (—Ä—ñ–∑–Ω—ñ)
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –∑–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π `random_state` –¥–ª—è **reproducibility**!

```python
# ‚úÖ –î–û–ë–†–ï
random_state = 42  # –ë—É–¥—å-—è–∫–µ —á–∏—Å–ª–æ, –∞–ª–µ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–µ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=random_state
)
```

### shuffle

**–ß–∏ –ø–µ—Ä–µ–º—ñ—à—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ** –ø–µ—Ä–µ–¥ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è–º.

```python
# –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º shuffle=True (–ø–µ—Ä–µ–º—ñ—à—É—î)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=True
)

# –ë–µ–∑ –ø–µ—Ä–µ–º—ñ—à—É–≤–∞–Ω–Ω—è (–¥–ª—è time series)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=False
)
```

**–ö–æ–ª–∏ shuffle=False?**
- **Time series** ‚Äî –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–ª–∏–≤–∏–π!
- –î–∞–Ω—ñ –≤–∂–µ –≤–ø–æ—Ä—è–¥–∫–æ–≤–∞–Ω—ñ —ñ —Ü–µ –≤–∞–∂–ª–∏–≤–æ

**–£–≤–∞–≥–∞:** —è–∫—â–æ –¥–∞–Ω—ñ –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω—ñ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –≤—Å—ñ 0 –≤ –ø–æ—á–∞—Ç–∫—É, –≤—Å—ñ 1 –≤ –∫—ñ–Ω—Ü—ñ), `shuffle=False` –ø—Ä–∏–∑–≤–µ–¥–µ –¥–æ **–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–æ–∑–ø–æ–¥—ñ–ª—É**!

```python
# ‚ùå –ü–û–ì–ê–ù–û: –¥–∞–Ω—ñ –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω—ñ
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

# –ó shuffle=False
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, shuffle=False
)
# y_train = [0, 0, 0, 0, 0] ‚Äî —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å 0!
# y_test = [1, 1, 1, 1, 1] ‚Äî —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å 1!

# ‚úÖ –î–û–ë–†–ï: –∑ shuffle=True
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, shuffle=True, random_state=42
)
# y_train —Ç–∞ y_test –º—ñ—Å—Ç—è—Ç—å –æ–±–∏–¥–≤–∞ –∫–ª–∞—Å–∏
```

### stratify

**–ó–±–µ—Ä—ñ–≥–∞—î –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó –∫–ª–∞—Å—ñ–≤** —É train —Ç–∞ test sets (–¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó).

```python
# –ë–µ–∑ stratify ‚Äî –º–æ–∂–µ –±—É—Ç–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å
y = np.array([0]*90 + [1]*10)  # 90% –∫–ª–∞—Å 0, 10% –∫–ª–∞—Å 1

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print(f"Train: {np.bincount(y_train)}")  # –ú–æ–∂–µ –±—É—Ç–∏ [64, 6] (91% vs 9%)
print(f"Test: {np.bincount(y_test)}")    # –ú–æ–∂–µ –±—É—Ç–∏ [26, 4] (87% vs 13%)

# –ó stratify ‚Äî –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

print(f"Train: {np.bincount(y_train)}")  # [63, 7] (90% vs 10%) ‚úì
print(f"Test: {np.bincount(y_test)}")    # [27, 3] (90% vs 10%) ‚úì
```

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ stratify?**
- **–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è** –∑ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–º–∏ –∫–ª–∞—Å–∞–º–∏
- –ú–∞–ª—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏
- –ö–æ–ª–∏ –≤–∞–∂–ª–∏–≤–æ –∑–±–µ—Ä–µ–≥—Ç–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª

```python
# ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    stratify=y,      # –ó–±–µ—Ä–µ–≥—Ç–∏ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó –∫–ª–∞—Å—ñ–≤
    random_state=42
)
```

---

## –¢–∏–ø–æ–≤—ñ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è

### 70/30 Split

```python
# 70% train, 30% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: —Å–µ—Ä–µ–¥–Ω—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏
```

### 80/20 Split (–Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏–π)

```python
# 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –∑–∞–¥–∞—á
```

### 90/10 Split

```python
# 90% train, 10% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.1, random_state=42
)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: –≤–µ–ª–∏–∫—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏ (>100k –∑—Ä–∞–∑–∫—ñ–≤)
```

### –ü—Ä–∞–≤–∏–ª–æ –≤–∏–±–æ—Ä—É

| –†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è | –ü—Ä–∏–∫–ª–∞–¥ |
|-----------------|--------------|---------|
| **–ú–∞–ª–∏–π** (< 1000) | 70/30 –∞–±–æ 60/40 | `test_size=0.3` |
| **–°–µ—Ä–µ–¥–Ω—ñ–π** (1k-10k) | 80/20 | `test_size=0.2` |
| **–í–µ–ª–∏–∫–∏–π** (10k-100k) | 80/20 –∞–±–æ 85/15 | `test_size=0.15` |
| **–î—É–∂–µ –≤–µ–ª–∏–∫–∏–π** (>100k) | 90/10 –∞–±–æ 95/5 | `test_size=0.1` |

**–ö–ª—é—á–æ–≤–∏–π –ø—Ä–∏–Ω—Ü–∏–ø:**
- Test set –º–∞—î –±—É—Ç–∏ **–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –≤–µ–ª–∏–∫–∏–º** –¥–ª—è –Ω–∞–¥—ñ–π–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏
- Train set –º–∞—î –±—É—Ç–∏ **–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –≤–µ–ª–∏–∫–∏–º** –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è

```python
# –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ —Ä–æ–∑–º—ñ—Ä–∏
# Test: —Ö–æ—á–∞ –± 100-200 –∑—Ä–∞–∑–∫—ñ–≤ (–¥–ª—è –Ω–∞–¥—ñ–π–Ω–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
# Train: –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –∞–ª–≥–æ—Ä–∏—Ç–º—É —Ç–∞ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫

# –ü—Ä–∏–∫–ª–∞–¥: 500 –∑—Ä–∞–∑–∫—ñ–≤
# 70/30 ‚Üí train=350, test=150 ‚úì
# 80/20 ‚Üí train=400, test=100 ‚úì (–∞–ª–µ test –Ω–∞ –º–µ–∂—ñ)
# 90/10 ‚Üí train=450, test=50 ‚ùå (test –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∏–π)
```

---

## Train/Validation/Test Split

### –ù–∞–≤—ñ—â–æ 3 –Ω–∞–±–æ—Ä–∏?

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë TRAIN (60%)         ‚ïë VAL (20%)    ‚ïë TEST (20%)‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ     ‚ïë Tuning       ‚ïë –§—ñ–Ω–∞–ª—å–Ω–∞  ‚ïë
‚ïë                     ‚ïë –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤   ‚ïë –æ—Ü—ñ–Ω–∫–∞    ‚ïë
‚ïë model.fit()         ‚ïë GridSearch   ‚ïë score()   ‚ïë
‚ïë                     ‚ïë Early Stop   ‚ïë 1 —Ä–∞–∑!    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è

**–ú–µ—Ç–æ–¥ 1: –î–≤–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ split**

```python
from sklearn.model_selection import train_test_split

# –ö—Ä–æ–∫ 1: –í—ñ–¥–¥—ñ–ª–∏—Ç–∏ test set (20%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –ö—Ä–æ–∫ 2: –†–æ–∑–¥—ñ–ª–∏—Ç–∏ temp –Ω–∞ train —ñ validation
# 0.25 * 0.8 = 0.2 (20% –≤—ñ–¥ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42
)

print(f"Original: {len(X)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X)*100:.0f}%)")
print(f"Validation: {len(X_val)} ({len(X_val)/len(X)*100:.0f}%)")
print(f"Test: {len(X_test)} ({len(X_test)/len(X)*100:.0f}%)")
```

**–ú–µ—Ç–æ–¥ 2: –§—É–Ω–∫—Ü—ñ—è –¥–ª—è 3-way split**

```python
def train_val_test_split(X, y, train_size=0.6, val_size=0.2, test_size=0.2, 
                         random_state=None, stratify=None):
    """
    –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train, validation, test
    """
    assert train_size + val_size + test_size == 1.0, \
        "Sizes must sum to 1.0"
    
    # Train + Val vs Test
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state,
        stratify=stratify
    )
    
    # Train vs Val
    # val_size / (train_size + val_size) = val —á–∞—Å—Ç–∫–∞ –≤—ñ–¥ temp
    val_ratio = val_size / (train_size + val_size)
    
    stratify_temp = None
    if stratify is not None:
        stratify_temp = y_temp
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp,
        test_size=val_ratio,
        random_state=random_state,
        stratify=stratify_temp
    )
    
    return X_train, X_val, X_test, y_train, y_val, y_test


# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(
    X, y, 
    train_size=0.6, 
    val_size=0.2, 
    test_size=0.2,
    random_state=42,
    stratify=y  # –î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
)
```

### Workflow –∑ validation

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# 1. –í—ñ–¥–æ–∫—Ä–µ–º–∏—Ç–∏ test set (—Ç–æ—Ä–∫–∞—î–º–æ—Å—å –¢–Ü–õ–¨–ö–ò –≤ –∫—ñ–Ω—Ü—ñ!)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. –†–æ–∑–¥—ñ–ª–∏—Ç–∏ –Ω–∞ train —ñ validation
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42
)

# 3. Tuning –Ω–∞ train/validation
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20, None]
}

# –í–∞—Ä—ñ–∞–Ω—Ç A: Manual validation
best_score = -np.inf
best_params = None

for n_est in param_grid['n_estimators']:
    for max_d in param_grid['max_depth']:
        rf = RandomForestRegressor(n_estimators=n_est, max_depth=max_d, 
                                   random_state=42)
        rf.fit(X_train, y_train)
        val_score = rf.score(X_val, y_val)
        
        if val_score > best_score:
            best_score = val_score
            best_params = {'n_estimators': n_est, 'max_depth': max_d}

print(f"Best params: {best_params}")
print(f"Best validation score: {best_score:.4f}")

# –í–∞—Ä—ñ–∞–Ω—Ç B: GridSearchCV (–∑ CV –Ω–∞ train+val)
# –ü—Ä–∏–º—ñ—Ç–∫–∞: GridSearchCV —Å–∞–º —Ä–æ–±–∏—Ç—å CV, –∞–ª–µ –º–∏ –º–æ–∂–µ–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏
# validation set –¥–ª—è early stopping –∞–±–æ —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–±–æ—Ä—É

# 4. –§—ñ–Ω–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
final_model = RandomForestRegressor(**best_params, random_state=42)
final_model.fit(X_train, y_train)  # –ê–±–æ X_temp (train+val)

# 5. –§–Ü–ù–ê–õ–¨–ù–ê –æ—Ü—ñ–Ω–∫–∞ –Ω–∞ test (—Ç—ñ–ª—å–∫–∏ –û–î–ò–ù —Ä–∞–∑!)
test_score = final_model.score(X_test, y_test)
print(f"\nFinal test score: {test_score:.4f}")
```

---

## –î–ª—è Time Series

### –ß–æ–º—É –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∑–≤–∏—á–∞–π–Ω–∏–π train_test_split?

**Time series –º–∞—î —á–∞—Å–æ–≤—É –∑–∞–ª–µ–∂–Ω—ñ—Å—Ç—å!**

```python
# ‚ùå –ü–û–ì–ê–ù–û: shuffle=True –¥–ª—è time series
dates = ['2020-01', '2020-02', '2020-03', '2020-04', '2020-05', 
         '2020-06', '2020-07', '2020-08']

# –ó shuffle=True ‚Üí –ø–æ—Ä—É—à—É—î —á–∞—Å–æ–≤—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
# Train: ['2020-02', '2020-05', '2020-07', '2020-08']
# Test: ['2020-01', '2020-03', '2020-04', '2020-06']
# –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–∞—î—Ç—å—Å—è –Ω–∞ –º–∞–π–±—É—Ç–Ω—ñ—Ö –¥–∞–Ω–∏—Ö! ‚ùå
```

### Time-based split

```python
# ‚úÖ –î–û–ë–†–ï: –¥–ª—è time series
# Train: –º–∏–Ω—É–ª–µ
# Test: –º–∞–π–±—É—Ç–Ω—î

# –í–∞—Ä—ñ–∞–Ω—Ç 1: Manual split
train_size = int(len(X) * 0.8)

X_train = X[:train_size]   # –ü–µ—Ä—à—ñ 80%
y_train = y[:train_size]

X_test = X[train_size:]    # –û—Å—Ç–∞–Ω–Ω—ñ 20%
y_test = y[train_size:]

# –í–∞—Ä—ñ–∞–Ω—Ç 2: –∑ train_test_split (shuffle=False!)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    shuffle=False  # –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è time series!
)
```

### Time Series Split –∑ Cross-Validation

```python
from sklearn.model_selection import TimeSeriesSplit

# Time series CV
tscv = TimeSeriesSplit(n_splits=5)

for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
    print(f"\nFold {fold + 1}:")
    print(f"  Train: index {train_idx[0]} to {train_idx[-1]}")
    print(f"  Test: index {test_idx[0]} to {test_idx[-1]}")
    
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # Train and evaluate
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    print(f"  Score: {score:.4f}")
```

**–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è TimeSeriesSplit:**

```
Fold 1: [Train----] [Test]
Fold 2: [Train--------] [Test]
Fold 3: [Train------------] [Test]
Fold 4: [Train----------------] [Test]
Fold 5: [Train--------------------] [Test]

–ö–æ–∂–µ–Ω fold:
- Train —Ä–æ—Å—Ç–µ (–≤–∫–ª—é—á–∞—î –≤—Å—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ)
- Test –∑–∞–≤–∂–¥–∏ –ü–Ü–°–õ–Ø train (–º–∞–π–±—É—Ç–Ω—î)
```

---

## –ü–æ—à–∏—Ä–µ–Ω—ñ –ø–æ–º–∏–ª–∫–∏ ‚ùå

### 1. –û—Ü—ñ–Ω–∫–∞ –Ω–∞ train set

```python
# ‚ùå –î–£–ñ–ï –ü–û–ì–ê–ù–û
model.fit(X, y)
score = model.score(X, y)
print(f"Accuracy: {score}")  # –ú–æ–∂–µ –±—É—Ç–∏ 100%, –∞–ª–µ –Ω–µ–ø—Ä–∞–≤–¥–∞!

# ‚úÖ –î–û–ë–†–ï
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model.fit(X_train, y_train)
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)
print(f"Train: {train_score:.3f}, Test: {test_score:.3f}")
```

### 2. Tuning –Ω–∞ test set

```python
# ‚ùå –ü–û–ì–ê–ù–û: –≤–∏—Ç—ñ–∫ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ test set
for alpha in [0.1, 1.0, 10.0]:
    model = Ridge(alpha=alpha)
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)  # ‚ùå –í–∏–∫–æ—Ä–∏—Å—Ç–∞–ª–∏ test –¥–ª—è –≤–∏–±–æ—Ä—É!

# ‚úÖ –î–û–ë–†–ï: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π validation –∞–±–æ CV
from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(Ridge(), {'alpha': [0.1, 1.0, 10.0]}, cv=5)
grid.fit(X_train, y_train)
best_model = grid.best_estimator_

# –¢–µ–ø–µ—Ä –û–î–ò–ù —Ä–∞–∑ –æ—Ü—ñ–Ω—é—î–º–æ –Ω–∞ test
final_score = best_model.score(X_test, y_test)
```

### 3. Preprocessing –ø–µ—Ä–µ–¥ split

```python
# ‚ùå –ü–û–ì–ê–ù–û: –≤–∏—Ç—ñ–∫ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–≤ –í–ï–°–¨ –¥–∞—Ç–∞—Å–µ—Ç!

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)
# Test set –≤–ø–ª–∏–Ω—É–≤ –Ω–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—é train set!

# ‚úÖ –î–û–ë–†–ï: —Å–ø–æ—á–∞—Ç–∫—É split, –ø–æ—Ç—ñ–º preprocessing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)    # –¢—ñ–ª—å–∫–∏ train!
X_test_scaled = scaler.transform(X_test)          # –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ –¥–æ test
```

### 4. –ù–µ —Ñ—ñ–∫—Å—É–≤–∞—Ç–∏ random_state

```python
# ‚ùå –ü–û–ì–ê–ù–û: —Ä—ñ–∑–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–æ–∂–µ–Ω —Ä–∞–∑
X_train, X_test, y_train, y_test = train_test_split(X, y)
# –ù–µ–º–æ–∂–ª–∏–≤–æ –≤—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç!

# ‚úÖ –î–û–ë–†–ï
X_train, X_test, y_train, y_test = train_test_split(
    X, y, random_state=42
)
# –ó–∞–≤–∂–¥–∏ –æ–¥–Ω–∞–∫–æ–≤–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
```

### 5. Shuffle –¥–ª—è time series

```python
# ‚ùå –ü–û–ì–ê–ù–û: –¥–ª—è —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
X_train, X_test, y_train, y_test = train_test_split(
    X, y, shuffle=True  # –ü–æ—Ä—É—à—É—î —á–∞—Å–æ–≤—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å!
)

# ‚úÖ –î–û–ë–†–ï
X_train, X_test, y_train, y_test = train_test_split(
    X, y, shuffle=False  # –ó–±–µ—Ä–µ–≥—Ç–∏ –ø–æ—Ä—è–¥–æ–∫
)
```

### 6. –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ stratify –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤

```python
# –î–∞–Ω—ñ: 95% –∫–ª–∞—Å 0, 5% –∫–ª–∞—Å 1
y = np.array([0]*950 + [1]*50)

# ‚ùå –ü–û–ì–ê–ù–û: –±–µ–∑ stratify
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# –ú–æ–∂–µ –±—É—Ç–∏: y_test –º—ñ—Å—Ç–∏—Ç—å 0 –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤ –∫–ª–∞—Å—É 1!

# ‚úÖ –î–û–ë–†–ï: –∑—ñ stratify
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y
)
# y_test –º—ñ—Å—Ç–∏—Ç—å ~5% –∫–ª–∞—Å—É 1 (–ø—Ä–æ–ø–æ—Ä—Ü—ñ–π–Ω–æ)
```

### 7. –ó–∞–±—É–≤–∞—Ç–∏ –ø—Ä–æ random seed —É –≤—Å—ñ—Ö –º—ñ—Å—Ü—è—Ö

```python
# ‚ùå –ü–û–ì–ê–ù–û: —Ç—ñ–ª—å–∫–∏ –≤ train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, random_state=42
)

model = RandomForestRegressor()  # random_state=None ‚Üí —Ä—ñ–∑–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
model.fit(X_train, y_train)

# ‚úÖ –î–û–ë–†–ï: —Å–∫—Ä—ñ–∑—å
X_train, X_test, y_train, y_test = train_test_split(
    X, y, random_state=42
)

model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)
```

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –ó–∞–≤–∂–¥–∏ —Ñ—ñ–∫—Å—É–π random_state

```python
# –°—Ç–≤–æ—Ä–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É
RANDOM_STATE = 42

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Å–∫—Ä—ñ–∑—å
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE
)

model = RandomForestRegressor(random_state=RANDOM_STATE)
```

### 2. –ü–µ—Ä–µ–≤—ñ—Ä—è–π —Ä–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ (–¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó)

```python
import pandas as pd

# –ü—ñ—Å–ª—è split
print("Train set class distribution:")
print(pd.Series(y_train).value_counts(normalize=True))

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts(normalize=True))

# –ü–æ–≤–∏–Ω–Ω—ñ –±—É—Ç–∏ —Å—Ö–æ–∂—ñ!
```

### 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π validation set –¥–ª—è tuning

```python
# –°—Ö–µ–º–∞: Train ‚Üí Validation ‚Üí Test
# Train: –Ω–∞–≤—á–∞–Ω–Ω—è
# Validation: –ø—ñ–¥–±—ñ—Ä –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
# Test: –§–Ü–ù–ê–õ–¨–ù–ê –æ—Ü—ñ–Ω–∫–∞ (1 —Ä–∞–∑!)

# –ù–ï —Ç–æ—Ä–∫–∞–π—Å—è test set –¥–æ —Å–∞–º–æ–≥–æ –∫—ñ–Ω—Ü—è!
```

### 4. –î–æ–∫—É–º–µ–Ω—Ç—É–π —Ä–æ–∑–ø–æ–¥—ñ–ª

```python
# –í –∫–æ–¥—ñ –∞–±–æ –≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—è—Ö
"""
Data split:
- Train: 60% (12,000 samples)
- Validation: 20% (4,000 samples)
- Test: 20% (4,000 samples)
- Random state: 42
- Stratified: Yes (imbalanced classes)
"""
```

### 5. –ó–±–µ—Ä—ñ–≥–∞–π —ñ–Ω–¥–µ–∫—Å–∏

```python
# –ö–æ—Ä–∏—Å–Ω–æ –¥–ª—è debugging
X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(
    X, y, range(len(X)),  # –ü–µ—Ä–µ–¥–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å–∏
    test_size=0.2,
    random_state=42
)

# –¢–µ–ø–µ—Ä –º–æ–∂–Ω–∞ –∑–Ω–∞–π—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –∑—Ä–∞–∑–∫–∏
print(f"Test set indices: {test_idx[:10]}")
```

### 6. –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ä–æ–∑–ø–æ–¥—ñ–ª

```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Train
axes[0].hist(y_train, bins=30, alpha=0.7)
axes[0].set_title('Train Set Target Distribution')
axes[0].set_xlabel('Target')
axes[0].set_ylabel('Frequency')

# Test
axes[1].hist(y_test, bins=30, alpha=0.7, color='orange')
axes[1].set_title('Test Set Target Distribution')
axes[1].set_xlabel('Target')
axes[1].set_ylabel('Frequency')

plt.tight_layout()
plt.show()

# –†–æ–∑–ø–æ–¥—ñ–ª–∏ –ø–æ–≤–∏–Ω–Ω—ñ –±—É—Ç–∏ —Å—Ö–æ–∂—ñ!
```

### 7. Wrapper function –¥–ª—è consistency

```python
def prepare_data(X, y, test_size=0.2, val_size=0.2, random_state=42, 
                 stratify=False, scale=False):
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –∑ best practices
    
    Returns:
        dict –∑ keys: X_train, X_val, X_test, y_train, y_val, y_test, scaler
    """
    from sklearn.preprocessing import StandardScaler
    
    # Stratify
    strat = y if stratify else None
    
    # Split –Ω–∞ train+val —Ç–∞ test
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=strat
    )
    
    # Split –Ω–∞ train —Ç–∞ val
    if val_size > 0:
        val_ratio = val_size / (1 - test_size)
        strat_temp = y_temp if stratify else None
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_ratio, 
            random_state=random_state, stratify=strat_temp
        )
    else:
        X_train, y_train = X_temp, y_temp
        X_val, y_val = None, None
    
    # Scaling
    scaler = None
    if scale:
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        if X_val is not None:
            X_val = scaler.transform(X_val)
    
    # Print info
    print(f"Data split complete:")
    print(f"  Train: {X_train.shape[0]} samples")
    if X_val is not None:
        print(f"  Validation: {X_val.shape[0]} samples")
    print(f"  Test: {X_test.shape[0]} samples")
    
    return {
        'X_train': X_train,
        'X_val': X_val,
        'X_test': X_test,
        'y_train': y_train,
        'y_val': y_val,
        'y_test': y_test,
        'scaler': scaler
    }

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
data = prepare_data(X, y, test_size=0.2, val_size=0.2, 
                    random_state=42, stratify=True, scale=True)

X_train = data['X_train']
y_train = data['y_train']
# etc.
```

---

## –†–µ–∞–ª—å–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: –ü–æ–≤–Ω–∏–π workflow

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è reproducibility
RANDOM_STATE = 42

print("="*70)
print("COMPLETE ML WORKFLOW WITH TRAIN-TEST SPLIT")
print("="*70)

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

print(f"\nüìä Dataset Info:")
print(f"Samples: {X.shape[0]}")
print(f"Features: {X.shape[1]}")
print(f"Classes: {np.unique(y)} (0=malignant, 1=benign)")
print(f"Class distribution: {pd.Series(y).value_counts().to_dict()}")

# 2. Train/Val/Test Split (60/20/20)
print(f"\nüìÇ Splitting data (60/20/20)...")

# –ö—Ä–æ–∫ 1: –í—ñ–¥–æ–∫—Ä–µ–º–∏—Ç–∏ test (20%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    stratify=y,  # –ó–±–µ—Ä–µ–≥—Ç–∏ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó –∫–ª–∞—Å—ñ–≤
    random_state=RANDOM_STATE
)

# –ö—Ä–æ–∫ 2: –†–æ–∑–¥—ñ–ª–∏—Ç–∏ temp –Ω–∞ train/val (60/20 –≤—ñ–¥ –æ—Ä–∏–≥—ñ–Ω–∞–ª—É)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp,
    test_size=0.25,  # 0.25 * 0.8 = 0.2
    stratify=y_temp,
    random_state=RANDOM_STATE
)

print(f"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.0f}%)")
print(f"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.0f}%)")
print(f"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.0f}%)")

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ stratification
print(f"\nClass distribution:")
print(f"  Train: {pd.Series(y_train).value_counts(normalize=True).to_dict()}")
print(f"  Val:   {pd.Series(y_val).value_counts(normalize=True).to_dict()}")
print(f"  Test:  {pd.Series(y_test).value_counts(normalize=True).to_dict()}")

# 3. Preprocessing (–ü–Ü–°–õ–Ø split!)
print(f"\nüîß Scaling features...")
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)  # Fit —Ç—ñ–ª—å–∫–∏ –Ω–∞ train!
X_val_scaled = scaler.transform(X_val)          # Transform val
X_test_scaled = scaler.transform(X_test)        # Transform test

# 4. Model Selection & Tuning (–Ω–∞ train + validation)
print(f"\nüîç Hyperparameter tuning...")

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=RANDOM_STATE),
    param_grid,
    cv=5,  # 5-fold CV –Ω–∞ train set
    scoring='roc_auc',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_scaled, y_train)

print(f"\nBest parameters: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.4f}")

# 5. Evaluation –Ω–∞ validation
best_model = grid_search.best_estimator_
val_score = best_model.score(X_val_scaled, y_val)
y_val_pred = best_model.predict(X_val_scaled)
val_auc = roc_auc_score(y_val, best_model.predict_proba(X_val_scaled)[:, 1])

print(f"\nüìä Validation Results:")
print(f"Accuracy: {val_score:.4f}")
print(f"ROC-AUC: {val_auc:.4f}")

# 6. FINAL Evaluation –Ω–∞ test (–¢–Ü–õ–¨–ö–ò –û–î–ò–ù –†–ê–ó!)
print(f"\nüéØ FINAL Test Results:")
test_score = best_model.score(X_test_scaled, y_test)
y_test_pred = best_model.predict(X_test_scaled)
test_auc = roc_auc_score(y_test, best_model.predict_proba(X_test_scaled)[:, 1])

print(f"Accuracy: {test_score:.4f}")
print(f"ROC-AUC: {test_auc:.4f}")

print(f"\nClassification Report:")
print(classification_report(y_test, y_test_pred, 
                          target_names=['Malignant', 'Benign']))

# 7. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Confusion Matrix
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_estimator(
    best_model, X_test_scaled, y_test,
    cmap='Blues', ax=axes[0, 0]
)
axes[0, 0].set_title('Confusion Matrix (Test Set)', fontweight='bold')

# ROC Curve
from sklearn.metrics import RocCurveDisplay
RocCurveDisplay.from_estimator(
    best_model, X_test_scaled, y_test,
    ax=axes[0, 1]
)
axes[0, 1].set_title(f'ROC Curve (AUC={test_auc:.3f})', fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# Feature Importances
feature_imp = pd.DataFrame({
    'feature': cancer.feature_names,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False).head(10)

axes[1, 0].barh(feature_imp['feature'], feature_imp['importance'])
axes[1, 0].set_xlabel('Importance')
axes[1, 0].set_title('Top 10 Feature Importances', fontweight='bold')
axes[1, 0].invert_yaxis()

# Train/Val/Test Comparison
scores = {
    'Train': best_model.score(X_train_scaled, y_train),
    'Validation': val_score,
    'Test': test_score
}

axes[1, 1].bar(scores.keys(), scores.values(), 
              color=['blue', 'orange', 'green'], alpha=0.7)
axes[1, 1].set_ylabel('Accuracy')
axes[1, 1].set_title('Model Performance Comparison', fontweight='bold')
axes[1, 1].set_ylim([0.9, 1.0])
axes[1, 1].grid(True, alpha=0.3, axis='y')

# Add values on bars
for i, (name, val) in enumerate(scores.items()):
    axes[1, 1].text(i, val + 0.005, f'{val:.3f}', 
                   ha='center', fontweight='bold')

plt.tight_layout()
plt.show()

# 8. –ü—ñ–¥—Å—É–º–æ–∫
print(f"\n{'='*70}")
print("SUMMARY")
print(f"{'='*70}")
print(f"Model: Random Forest")
print(f"Best params: {grid_search.best_params_}")
print(f"\nPerformance:")
print(f"  Train Accuracy:      {scores['Train']:.4f}")
print(f"  Validation Accuracy: {scores['Validation']:.4f}")
print(f"  Test Accuracy:       {scores['Test']:.4f}")
print(f"  Test ROC-AUC:        {test_auc:.4f}")

# –î—ñ–∞–≥–Ω–æ–∑
gap = scores['Train'] - scores['Test']
if gap > 0.1:
    print(f"\n‚ö†Ô∏è  Large gap ({gap:.3f}) ‚Üí possible overfitting")
elif scores['Test'] < 0.9:
    print(f"\n‚ö†Ô∏è  Low test score ‚Üí room for improvement")
else:
    print(f"\n‚úÖ Excellent performance with good generalization!")

print(f"{'='*70}")
```

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_Bias_Variance_Tradeoff]] ‚Äî —á–æ–º—É –≤–∞–∂–ª–∏–≤–æ —Ç–µ—Å—Ç—É–≤–∞—Ç–∏ –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
- [[02_Overfitting_Underfitting]] ‚Äî –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é train/test
- [[04_Cross_Validation]] ‚Äî –±—ñ–ª—å—à –Ω–∞–¥—ñ–π–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- [[Preprocessing]] ‚Äî –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –ø–æ—Ä—è–¥–∫—É –æ–ø–µ—Ä–∞—Ü—ñ–π
- [[Model_Selection]] ‚Äî –≤–∏–±—ñ—Ä —ñ tuning –º–æ–¥–µ–ª–µ–π

## –†–µ—Å—É—Ä—Å–∏

- [Scikit-learn: train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [Machine Learning Mastery: Train-Test Split](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/)
- [Towards Data Science: The Right Way to Split Data](https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> Train-Test Split ‚Äî —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π –∫—Ä–æ–∫ –≤ ML pipeline. –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–∞—î—Ç—å—Å—è –Ω–∞ train set, –∞ –æ—Ü—ñ–Ω—é—î—Ç—å—Å—è –Ω–∞ test set, —è–∫–∏–π –≤–æ–Ω–∞ –ù–Ü–ö–û–õ–ò –Ω–µ –±–∞—á–∏–ª–∞. –¶–µ —î–¥–∏–Ω–∏–π —Å–ø–æ—Å—ñ–± —á–µ—Å–Ω–æ –æ—Ü—ñ–Ω–∏—Ç–∏ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –¥–æ —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è.

**Best Practices:**
```python
# 1. –ó–∞–≤–∂–¥–∏ —Ä–æ–∑–¥—ñ–ª—è–π –¥–∞–Ω—ñ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 2. Preprocessing –ü–Ü–°–õ–Ø split
scaler.fit_transform(X_train)  # ‚úì
scaler.transform(X_test)       # ‚úì

# 3. –¢—Ä–∏ –Ω–∞–±–æ—Ä–∏ –¥–ª—è tuning
# Train ‚Üí –Ω–∞–≤—á–∞–Ω–Ω—è
# Validation ‚Üí –ø—ñ–¥–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤  
# Test ‚Üí —Ñ—ñ–Ω–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ (1 —Ä–∞–∑!)

# 4. –§—ñ–∫—Å—É–π random_state –¥–ª—è reproducibility
```

**–¢–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏:**
- ‚ùå –û—Ü—ñ–Ω–∫–∞ –Ω–∞ train set
- ‚ùå Tuning –Ω–∞ test set
- ‚ùå Preprocessing –ø–µ—Ä–µ–¥ split
- ‚ùå Shuffle –¥–ª—è time series
- ‚ùå –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ stratify –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤

**–ü—Ä–∞–≤–∏–ª–æ —Ä–æ–∑–º—ñ—Ä—É:**
- –ú–∞–ª—ñ –¥–∞–Ω—ñ (< 1000): 70/30 –∞–±–æ 60/20/20
- –°–µ—Ä–µ–¥–Ω—ñ (1k-10k): 80/20 –∞–±–æ 60/20/20
- –í–µ–ª–∏–∫—ñ (> 10k): 90/10 –∞–±–æ 70/15/15

---

#ml #core-concepts #train-test-split #validation #model-evaluation #best-practices
