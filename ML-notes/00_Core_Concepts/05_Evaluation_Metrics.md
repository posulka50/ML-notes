# Evaluation Metrics (–ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏)

## –©–æ —Ü–µ?

**Evaluation Metrics** ‚Äî —Ü–µ **–∫—ñ–ª—å–∫—ñ—Å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏**, —è–∫—ñ –≤–∏–º—ñ—Ä—é—é—Ç—å **—è–∫—ñ—Å—Ç—å —Ä–æ–±–æ—Ç–∏** ML –º–æ–¥–µ–ª—ñ. –í–æ–Ω–∏ –¥–æ–∑–≤–æ–ª—è—é—Ç—å –æ–±'—î–∫—Ç–∏–≤–Ω–æ –æ—Ü—ñ–Ω–∏—Ç–∏, –Ω–∞—Å–∫—ñ–ª—å–∫–∏ –¥–æ–±—Ä–µ –º–æ–¥–µ–ª—å –≤–∏–∫–æ–Ω—É—î —Å–≤–æ—é –∑–∞–¥–∞—á—É.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** —Ä—ñ–∑–Ω—ñ –∑–∞–¥–∞—á—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å —Ä—ñ–∑–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫. –¢–µ, —â–æ –¥–æ–±—Ä–µ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó, –Ω–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó. –í–∏–±—ñ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –º–µ—Ç—Ä–∏–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è —É—Å–ø—ñ—Ö—É –ø—Ä–æ–µ–∫—Ç—É.

## –ù–∞–≤—ñ—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ?

- üéØ **–û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ** ‚Äî —á–∏ –¥–æ–±—Ä–µ –ø—Ä–∞—Ü—é—î –º–æ–¥–µ–ª—å
- üìä **–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π** ‚Äî —è–∫–∞ –∫—Ä–∞—â–∞
- üîç **–í–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º** ‚Äî –¥–µ –º–æ–¥–µ–ª—å –ø–æ–º–∏–ª—è—î—Ç—å—Å—è
- ‚öôÔ∏è **–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è** ‚Äî —â–æ –ø–æ–∫—Ä–∞—â—É–≤–∞—Ç–∏
- üíº **–ë—ñ–∑–Ω–µ—Å-—Ä—ñ—à–µ–Ω–Ω—è** ‚Äî —á–∏ –≥–æ—Ç–æ–≤–∞ –º–æ–¥–µ–ª—å –¥–æ production
- üìà **–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥** ‚Äî –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è –¥–µ–≥—Ä–∞–¥–∞—Ü—ñ—ó –≤ production

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

**–ó–∞–≤–∂–¥–∏!** –ü—ñ—Å–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –±—É–¥—å-—è–∫–æ—ó –º–æ–¥–µ–ª—ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ –æ—Ü—ñ–Ω–∏—Ç–∏ —ó—ó —è–∫—ñ—Å—Ç—å.

**–í–∞–∂–ª–∏–≤–æ:**
- –†—ñ–∑–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
- –í—Ä–∞—Ö–æ–≤—É–≤–∞—Ç–∏ business context (–Ω–µ —Ç—ñ–ª—å–∫–∏ accuracy!)
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∫—ñ–ª—å–∫–∞ –º–µ—Ç—Ä–∏–∫ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
- –†–æ–∑—É–º—ñ—Ç–∏ trade-offs –º—ñ–∂ –º–µ—Ç—Ä–∏–∫–∞–º–∏

---

## –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –º–µ—Ç—Ä–∏–∫

```
Evaluation Metrics
‚îÇ
‚îú‚îÄ‚îÄ Regression Metrics
‚îÇ   ‚îú‚îÄ‚îÄ MAE (Mean Absolute Error)
‚îÇ   ‚îú‚îÄ‚îÄ MSE (Mean Squared Error)
‚îÇ   ‚îú‚îÄ‚îÄ RMSE (Root Mean Squared Error)
‚îÇ   ‚îú‚îÄ‚îÄ R¬≤ (R-squared / Coefficient of Determination)
‚îÇ   ‚îú‚îÄ‚îÄ MAPE (Mean Absolute Percentage Error)
‚îÇ   ‚îî‚îÄ‚îÄ Adjusted R¬≤
‚îÇ
‚îî‚îÄ‚îÄ Classification Metrics
    ‚îú‚îÄ‚îÄ Accuracy
    ‚îú‚îÄ‚îÄ Precision
    ‚îú‚îÄ‚îÄ Recall (Sensitivity)
    ‚îú‚îÄ‚îÄ F1-Score
    ‚îú‚îÄ‚îÄ Specificity
    ‚îú‚îÄ‚îÄ ROC-AUC
    ‚îú‚îÄ‚îÄ Confusion Matrix
    ‚îú‚îÄ‚îÄ Cohen's Kappa
    ‚îî‚îÄ‚îÄ Log Loss
```

---

# REGRESSION METRICS

## 1. MAE (Mean Absolute Error)

### –§–æ—Ä–º—É–ª–∞

$$\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

–¥–µ:
- $y_i$ ‚Äî —Å–ø—Ä–∞–≤–∂–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è
- $\hat{y}_i$ ‚Äî –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
- $n$ ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**MAE** ‚Äî —Ü–µ **—Å–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ —Ä—ñ–∑–Ω–∏—Ü—è** –º—ñ–∂ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è–º —Ç–∞ —Ä–µ–∞–ª—å–Ω—ñ—Å—Ç—é.

```
–†–µ–∞–ª—å–Ω—ñ —Ü—ñ–Ω–∏:        [100, 200, 150, 180]
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:        [110, 190, 160, 170]
–ê–±—Å–æ–ª—é—Ç–Ω—ñ –ø–æ–º–∏–ª–∫–∏:   [ 10,  10,  10,  10]

MAE = (10 + 10 + 10 + 10) / 4 = 10

–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è: –≤ —Å–µ—Ä–µ–¥–Ω—å–æ–º—É –º–æ–¥–µ–ª—å –ø–æ–º–∏–ª—è—î—Ç—å—Å—è –Ω–∞ 10 –≥—Ä–Ω
```

### –ö–æ–¥

```python
from sklearn.metrics import mean_absolute_error
import numpy as np

# –î–∞–Ω—ñ
y_true = np.array([100, 200, 150, 180])
y_pred = np.array([110, 190, 160, 170])

# MAE
mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")

# –ê–±–æ –≤—Ä—É—á–Ω—É
mae_manual = np.mean(np.abs(y_true - y_pred))
print(f"MAE (manual): {mae_manual:.2f}")
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –ü—Ä–æ—Å—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è | ‚ùå –ù–µ –∫–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ —Å–∏–ª—å–Ω—ñ—à–µ |
| ‚úÖ –°—Ç—ñ–π–∫–∞ –¥–æ –≤–∏–∫–∏–¥—ñ–≤ | ‚ùå –ù–µ –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–Ω–∞ –≤ 0 |
| ‚úÖ –í —Ç–∏—Ö —Å–∞–º–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö, —â–æ y | ‚ùå –í—Å—ñ –ø–æ–º–∏–ª–∫–∏ —Ä—ñ–≤–Ω–æ—Ü—ñ–Ω–Ω—ñ |

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

- ‚úÖ –ö–æ–ª–∏ –≤—Å—ñ –ø–æ–º–∏–ª–∫–∏ –æ–¥–Ω–∞–∫–æ–≤–æ –≤–∞–∂–ª–∏–≤—ñ
- ‚úÖ –ö–æ–ª–∏ —î –≤–∏–∫–∏–¥–∏ –≤ –¥–∞–Ω–∏—Ö
- ‚úÖ –ö–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –ø—Ä–æ—Å—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è
- ‚ùå –ö–æ–ª–∏ –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ—à—ñ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π MSE)

---

## 2. MSE (Mean Squared Error)

### –§–æ—Ä–º—É–ª–∞

$$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**MSE** ‚Äî —Ü–µ **—Å–µ—Ä–µ–¥–Ω—ñ–π –∫–≤–∞–¥—Ä–∞—Ç –ø–æ–º–∏–ª–∫–∏**. –ü—ñ–¥–Ω–µ—Å–µ–Ω–Ω—è –¥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞ **–∫–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ —Å–∏–ª—å–Ω—ñ—à–µ**.

```
–†–µ–∞–ª—å–Ω—ñ —Ü—ñ–Ω–∏:        [100, 200, 150, 180]
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:        [110, 190, 160, 170]
–ü–æ–º–∏–ª–∫–∏:             [ 10,  10,  10,  10]
–ö–≤–∞–¥—Ä–∞—Ç–∏ –ø–æ–º–∏–ª–æ–∫:    [100, 100, 100, 100]

MSE = (100 + 100 + 100 + 100) / 4 = 100

–ê–ª–µ —è–∫—â–æ –æ–¥–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤–µ–ª–∏–∫–∞:
–ü–æ–º–∏–ª–∫–∏:             [ 5,  5,  5,  35]
–ö–≤–∞–¥—Ä–∞—Ç–∏:            [25, 25, 25, 1225]

MSE = (25 + 25 + 25 + 1225) / 4 = 325  ‚Üê –ù–∞–±–∞–≥–∞—Ç–æ –±—ñ–ª—å—à–µ!
```

### –ö–æ–¥

```python
from sklearn.metrics import mean_squared_error

y_true = np.array([100, 200, 150, 180])
y_pred = np.array([110, 190, 160, 170])

# MSE
mse = mean_squared_error(y_true, y_pred)
print(f"MSE: {mse:.2f}")

# –í—Ä—É—á–Ω—É
mse_manual = np.mean((y_true - y_pred) ** 2)
print(f"MSE (manual): {mse_manual:.2f}")
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è: MSE vs MAE

```python
import matplotlib.pyplot as plt

errors = np.linspace(-10, 10, 100)

mae_values = np.abs(errors)
mse_values = errors ** 2

plt.figure(figsize=(10, 6))
plt.plot(errors, mae_values, label='MAE = |error|', linewidth=2)
plt.plot(errors, mse_values, label='MSE = error¬≤', linewidth=2)
plt.xlabel('Error', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.title('MAE vs MSE: How they penalize errors', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)
plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)
plt.tight_layout()
plt.show()

# MSE —Å–∏–ª—å–Ω–æ –∫–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏!
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –ö–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ —Å–∏–ª—å–Ω—ñ—à–µ | ‚ùå –ß—É—Ç–ª–∏–≤–∞ –¥–æ –≤–∏–∫–∏–¥—ñ–≤ |
| ‚úÖ –î–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–Ω–∞ (–¥–ª—è –≥—Ä–∞–¥—ñ—î–Ω—Ç—ñ–≤) | ‚ùå –û–¥–∏–Ω–∏—Ü—ñ ‚Äî –∫–≤–∞–¥—Ä–∞—Ç y (—Å–∫–ª–∞–¥–Ω—ñ—à–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏) |
| ‚úÖ –ü–æ–ø—É–ª—è—Ä–Ω–∞ loss function | ‚ùå –ú–æ–∂–µ –±—É—Ç–∏ –∑–∞–Ω–∞–¥—Ç–æ –ø–µ—Å–∏–º—ñ—Å—Ç–∏—á–Ω–æ—é |

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

- ‚úÖ –ö–æ–ª–∏ –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ **–Ω–µ–ø—Ä–∏–π–Ω—è—Ç–Ω—ñ**
- ‚úÖ –î–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó (loss function)
- ‚úÖ –ö–æ–ª–∏ –Ω–µ–º–∞—î –∑–Ω–∞—á–Ω–∏—Ö –≤–∏–∫–∏–¥—ñ–≤
- ‚ùå –ö–æ–ª–∏ —î –≤–∏–∫–∏–¥–∏ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π MAE)

---

## 3. RMSE (Root Mean Squared Error)

### –§–æ—Ä–º—É–ª–∞

$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} = \sqrt{\text{MSE}}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**RMSE** ‚Äî —Ü–µ **–∫–æ—Ä—ñ–Ω—å –∑ MSE**, –ø–æ–≤–µ—Ä—Ç–∞—î –º–µ—Ç—Ä–∏–∫—É –≤ **–æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –æ–¥–∏–Ω–∏—Ü—ñ** y.

```
MSE = 100 (—É –∫–≤–∞–¥—Ä–∞—Ç—ñ –≥—Ä–Ω)
RMSE = ‚àö100 = 10 –≥—Ä–Ω  ‚Üê –í —Ç–∏—Ö —Å–∞–º–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö!

–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è: –º–æ–¥–µ–ª—å –≤ —Å–µ—Ä–µ–¥–Ω—å–æ–º—É –ø–æ–º–∏–ª—è—î—Ç—å—Å—è –Ω–∞ ~10 –≥—Ä–Ω
```

### –ö–æ–¥

```python
from sklearn.metrics import mean_squared_error
import numpy as np

y_true = np.array([100, 200, 150, 180])
y_pred = np.array([110, 190, 160, 170])

# RMSE
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
print(f"RMSE: {rmse:.2f}")

# –ê–±–æ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä
rmse = mean_squared_error(y_true, y_pred, squared=False)
print(f"RMSE: {rmse:.2f}")
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –í –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö –æ–¥–∏–Ω–∏—Ü—è—Ö | ‚ùå –ß—É—Ç–ª–∏–≤–∞ –¥–æ –≤–∏–∫–∏–¥—ñ–≤ |
| ‚úÖ –ö–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ | ‚ùå –°–∫–ª–∞–¥–Ω—ñ—à–µ –æ–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ (—á–µ—Ä–µ–∑ –∫–æ—Ä—ñ–Ω—å) |
| ‚úÖ –Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ –∑—Ä–æ–∑—É–º—ñ–ª–∞ | |

### MAE vs RMSE: –ö–æ–ª–∏ —â–æ?

```python
# –ü—Ä–∏–∫–ª–∞–¥ –∑ –≤–∏–∫–∏–¥–æ–º
y_true = np.array([100, 100, 100, 100, 100])

# –ú–æ–¥–µ–ª—å A: –≤—Å—ñ –ø–æ–º–∏–ª–∫–∏ –º–∞–ª–µ–Ω—å–∫—ñ
y_pred_A = np.array([105, 95, 102, 98, 103])

# –ú–æ–¥–µ–ª—å B: –æ–¥–∏–Ω –≤–µ–ª–∏–∫–∏–π –≤–∏–∫–∏–¥
y_pred_B = np.array([100, 100, 100, 100, 150])

mae_A = mean_absolute_error(y_true, y_pred_A)
mae_B = mean_absolute_error(y_true, y_pred_B)
rmse_A = mean_squared_error(y_true, y_pred_A, squared=False)
rmse_B = mean_squared_error(y_true, y_pred_B, squared=False)

print("Model A (consistent small errors):")
print(f"  MAE:  {mae_A:.2f}")
print(f"  RMSE: {rmse_A:.2f}")

print("\nModel B (one large outlier):")
print(f"  MAE:  {mae_B:.2f}")
print(f"  RMSE: {rmse_B:.2f}")

# –í–∏–≤—ñ–¥:
# Model A: MAE ‚âà 3.4, RMSE ‚âà 3.7
# Model B: MAE = 10,  RMSE ‚âà 22.4  ‚Üê RMSE –∫–∞—Ä–∞—î —Å–∏–ª—å–Ω—ñ—à–µ!
```

---

## 4. R¬≤ (R-squared / Coefficient of Determination)

### –§–æ—Ä–º—É–ª–∞

$$R^2 = 1 - \frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}$$

–¥–µ:
- $\text{SS}_{\text{res}}$ ‚Äî —Å—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ –∑–∞–ª–∏—à–∫—ñ–≤ (residual sum of squares)
- $\text{SS}_{\text{tot}}$ ‚Äî –∑–∞–≥–∞–ª—å–Ω–∞ —Å—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ (total sum of squares)
- $\bar{y}$ ‚Äî —Å–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è y

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**R¬≤** –ø–æ–∫–∞–∑—É—î, **—è–∫–∞ —á–∞—Å—Ç–∫–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—ó y –ø–æ—è—Å–Ω—é—î—Ç—å—Å—è –º–æ–¥–µ–ª–ª—é**.

```
R¬≤ = 1.0  ‚Üí –ú–æ–¥–µ–ª—å —ñ–¥–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î (100% –≤–∞—Ä—ñ–∞—Ü—ñ—ó –ø–æ—è—Å–Ω–µ–Ω–æ)
R¬≤ = 0.8  ‚Üí –ú–æ–¥–µ–ª—å –ø–æ—è—Å–Ω—é—î 80% –≤–∞—Ä—ñ–∞—Ü—ñ—ó (–¥–æ–±—Ä–µ!)
R¬≤ = 0.5  ‚Üí –ú–æ–¥–µ–ª—å –ø–æ—è—Å–Ω—é—î 50% –≤–∞—Ä—ñ–∞—Ü—ñ—ó (—Å–µ—Ä–µ–¥–Ω—å–æ)
R¬≤ = 0.0  ‚Üí –ú–æ–¥–µ–ª—å –Ω–µ –∫—Ä–∞—â–∞ –∑–∞ –ø—Ä–æ—Å—Ç–µ —Å–µ—Ä–µ–¥–Ω—î
R¬≤ < 0    ‚Üí –ú–æ–¥–µ–ª—å –ì–Ü–†–®–ï –∑–∞ —Å–µ—Ä–µ–¥–Ω—î! ‚ùå
```

### –í—ñ–∑—É–∞–ª—å–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è

```
–î–∞–Ω—ñ: y = [10, 20, 30, 40, 50]
–°–µ—Ä–µ–¥–Ω—î: »≥ = 30

Baseline (–ø—Ä–æ—Å—Ç–æ —Å–µ—Ä–µ–¥–Ω—î):
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: [30, 30, 30, 30, 30]
SS‚Çú‚Çí‚Çú = (10-30)¬≤ + (20-30)¬≤ + (30-30)¬≤ + (40-30)¬≤ + (50-30)¬≤
      = 400 + 100 + 0 + 100 + 400 = 1000

–ù–∞—à–∞ –º–æ–¥–µ–ª—å:
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: [12, 21, 29, 39, 48]
SS·µ£‚Çë‚Çõ = (10-12)¬≤ + (20-21)¬≤ + (30-29)¬≤ + (40-39)¬≤ + (50-48)¬≤
      = 4 + 1 + 1 + 1 + 4 = 11

R¬≤ = 1 - (11 / 1000) = 1 - 0.011 = 0.989  ‚Üê –ß—É–¥–æ–≤–æ! 98.9%
```

### –ö–æ–¥

```python
from sklearn.metrics import r2_score

y_true = np.array([10, 20, 30, 40, 50])
y_pred = np.array([12, 21, 29, 39, 48])

# R¬≤
r2 = r2_score(y_true, y_pred)
print(f"R¬≤: {r2:.4f}")

# –í—Ä—É—á–Ω—É
ss_res = np.sum((y_true - y_pred) ** 2)
ss_tot = np.sum((y_true - y_true.mean()) ** 2)
r2_manual = 1 - (ss_res / ss_tot)
print(f"R¬≤ (manual): {r2_manual:.4f}")
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è R¬≤

```python
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
np.random.seed(42)
X = np.linspace(0, 10, 50).reshape(-1, 1)
y = 2 * X.ravel() + 1 + np.random.normal(0, 2, 50)

# –ú–æ–¥–µ–ª—å
model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)

# R¬≤
r2 = r2_score(y, y_pred)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(12, 5))

# Subplot 1: –ú–æ–¥–µ–ª—å
plt.subplot(1, 2, 1)
plt.scatter(X, y, alpha=0.6, s=50, label='Data')
plt.plot(X, y_pred, 'r-', linewidth=2, label='Model')
plt.axhline(y=y.mean(), color='green', linestyle='--', 
            linewidth=2, label=f'Baseline (mean={y.mean():.2f})')
plt.xlabel('X', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title(f'Linear Regression (R¬≤ = {r2:.3f})', fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)

# Subplot 2: Residuals
plt.subplot(1, 2, 2)
residuals = y - y_pred
plt.scatter(y_pred, residuals, alpha=0.6, s=50)
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Predicted values', fontsize=12)
plt.ylabel('Residuals', fontsize=12)
plt.title('Residual Plot', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–∞ (–≤—ñ–¥ 0 –¥–æ 1) | ‚ùå –ú–æ–∂–µ –±—É—Ç–∏ < 0 (–ø–æ–≥–∞–Ω–∞ –º–æ–¥–µ–ª—å) |
| ‚úÖ –ù–µ–∑–∞–ª–µ–∂–Ω–∞ –≤—ñ–¥ –æ–¥–∏–Ω–∏—Ü—å | ‚ùå –ó–∞–≤–∂–¥–∏ –∑—Ä–æ—Å—Ç–∞—î –∑ –¥–æ–¥–∞–≤–∞–Ω–Ω—è–º –æ–∑–Ω–∞–∫ |
| ‚úÖ –ü–æ–ø—É–ª—è—Ä–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ | ‚ùå –ù–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π |

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

- ‚úÖ –û—Å–Ω–æ–≤–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó
- ‚úÖ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
- ‚úÖ –ü–æ—è—Å–Ω–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ —Å—Ç–µ–π–∫—Ö–æ–ª–¥–µ—Ä–∞–º
- ‚ùå –î–ª—è –º–æ–¥–µ–ª–µ–π –∑ –≤–µ–ª–∏–∫–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –æ–∑–Ω–∞–∫ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Adjusted R¬≤)

---

## 5. Adjusted R¬≤

### –§–æ—Ä–º—É–ª–∞

$$R^2_{\text{adj}} = 1 - \frac{(1 - R^2)(n - 1)}{n - p - 1}$$

–¥–µ:
- $n$ ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤
- $p$ ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (–ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ñ–≤)

### –ù–∞–≤—ñ—â–æ?

**–ü—Ä–æ–±–ª–µ–º–∞ R¬≤:** –∑–∞–≤–∂–¥–∏ –∑—Ä–æ—Å—Ç–∞—î –ø—Ä–∏ –¥–æ–¥–∞–≤–∞–Ω–Ω—ñ –Ω–æ–≤–∏—Ö –æ–∑–Ω–∞–∫, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤–æ–Ω–∏ –±–µ–∑–∫–æ—Ä–∏—Å–Ω—ñ.

**Adjusted R¬≤** **–∫–∞—Ä–∞—î** –∑–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –æ–∑–Ω–∞–∫.

```python
from sklearn.linear_model import LinearRegression

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
np.random.seed(42)
n_samples = 100
X = np.random.randn(n_samples, 1)  # 1 –∫–æ—Ä–∏—Å–Ω–∞ –æ–∑–Ω–∞–∫–∞
y = 2 * X.ravel() + 1 + np.random.normal(0, 0.5, n_samples)

# –î–æ–¥–∞–º–æ 10 –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö (–±–µ–∑–∫–æ—Ä–∏—Å–Ω–∏—Ö) –æ–∑–Ω–∞–∫
X_noise = np.random.randn(n_samples, 10)
X_with_noise = np.hstack([X, X_noise])

# –ú–æ–¥–µ–ª—å –∑ 1 –æ–∑–Ω–∞–∫–æ—é
model_simple = LinearRegression()
model_simple.fit(X, y)
r2_simple = model_simple.score(X, y)

# –ú–æ–¥–µ–ª—å –∑ 11 –æ–∑–Ω–∞–∫–∞–º–∏
model_complex = LinearRegression()
model_complex.fit(X_with_noise, y)
r2_complex = model_complex.score(X_with_noise, y)

# Adjusted R¬≤
def adjusted_r2(r2, n, p):
    return 1 - (1 - r2) * (n - 1) / (n - p - 1)

adj_r2_simple = adjusted_r2(r2_simple, n_samples, 1)
adj_r2_complex = adjusted_r2(r2_complex, n_samples, 11)

print(f"Simple model (1 feature):")
print(f"  R¬≤:          {r2_simple:.4f}")
print(f"  Adjusted R¬≤: {adj_r2_simple:.4f}")

print(f"\nComplex model (11 features):")
print(f"  R¬≤:          {r2_complex:.4f}")  # –¢—Ä–æ—Ö–∏ –≤–∏—â–µ!
print(f"  Adjusted R¬≤: {adj_r2_complex:.4f}")  # –ê–ª–µ Adj R¬≤ –Ω–∏–∂—á–µ!

# R¬≤ –∑—Ä–æ—Å–ª–æ —á–µ—Ä–µ–∑ –¥–æ–¥–∞–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫
# –ê–ª–µ Adjusted R¬≤ –≤–ø–∞–ª–æ ‚Üí –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–∫—Ä–∞—â–∏–ª–∞—Å—å –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ!
```

---

## 6. MAPE (Mean Absolute Percentage Error)

### –§–æ—Ä–º—É–ª–∞

$$\text{MAPE} = \frac{100\%}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**MAPE** ‚Äî —Ü–µ **—Å–µ—Ä–µ–¥–Ω—è –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∞ –ø–æ–º–∏–ª–∫–∞**.

```
–†–µ–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞: 100 –≥—Ä–Ω
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: 110 –≥—Ä–Ω
–ü–æ–º–∏–ª–∫–∞: |100 - 110| / 100 = 10 / 100 = 10%

MAPE = 10% ‚Üí –º–æ–¥–µ–ª—å –≤ —Å–µ—Ä–µ–¥–Ω—å–æ–º—É –ø–æ–º–∏–ª—è—î—Ç—å—Å—è –Ω–∞ 10%
```

### –ö–æ–¥

```python
from sklearn.metrics import mean_absolute_percentage_error

y_true = np.array([100, 200, 150, 180])
y_pred = np.array([110, 190, 160, 170])

# MAPE
mape = mean_absolute_percentage_error(y_true, y_pred)
print(f"MAPE: {mape:.4f} ({mape*100:.2f}%)")

# –í—Ä—É—á–Ω—É
mape_manual = np.mean(np.abs((y_true - y_pred) / y_true))
print(f"MAPE (manual): {mape_manual*100:.2f}%")
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–∞ (–≤—ñ–¥—Å–æ—Ç–∫–∏) | ‚ùå –ù–µ –≤–∏–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è y=0 |
| ‚úÖ –ù–µ–∑–∞–ª–µ–∂–Ω–∞ –≤—ñ–¥ –º–∞—Å—à—Ç–∞–±—É | ‚ùå –ê—Å–∏–º–µ—Ç—Ä–∏—á–Ω–∞ (–∫–∞—Ä–∞—î –Ω–µ–¥–æ–æ—Ü—ñ–Ω–∫—É —Å–∏–ª—å–Ω—ñ—à–µ) |
| ‚úÖ –õ–µ–≥–∫–æ –ø–æ—è—Å–Ω–∏—Ç–∏ –±—ñ–∑–Ω–µ—Å—É | ‚ùå –ß—É—Ç–ª–∏–≤–∞ –¥–æ –º–∞–ª–∏—Ö –∑–Ω–∞—á–µ–Ω—å y |

### –ü—Ä–æ–±–ª–µ–º–∞ MAPE –∑ –Ω—É–ª—è–º–∏

```python
y_true = np.array([100, 200, 0, 180])  # –û–¥–∏–Ω –Ω—É–ª—å!
y_pred = np.array([110, 190, 10, 170])

# MAPE
try:
    mape = mean_absolute_percentage_error(y_true, y_pred)
except:
    print("Error: Division by zero!")

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: sMAPE (symmetric MAPE)
def smape(y_true, y_pred):
    return 100 * np.mean(
        2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))
    )

smape_value = smape(y_true, y_pred)
print(f"sMAPE: {smape_value:.2f}%")
```

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è Regression Metrics

```python
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import (mean_absolute_error, mean_squared_error, 
                             r2_score, mean_absolute_percentage_error)
import pandas as pd

# –î–∞–Ω—ñ
housing = fetch_california_housing()
X_train, X_test, y_train, y_test = train_test_split(
    housing.data, housing.target, test_size=0.2, random_state=42
)

# –ú–æ–¥–µ–ª—å
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# –í—Å—ñ –º–µ—Ç—Ä–∏–∫–∏
metrics = {
    'MAE': mean_absolute_error(y_test, y_pred),
    'MSE': mean_squared_error(y_test, y_pred),
    'RMSE': mean_squared_error(y_test, y_pred, squared=False),
    'R¬≤': r2_score(y_test, y_pred),
    'MAPE': mean_absolute_percentage_error(y_test, y_pred) * 100
}

print("="*50)
print("REGRESSION METRICS COMPARISON")
print("="*50)
for metric, value in metrics.items():
    if metric == 'MAPE':
        print(f"{metric:10s}: {value:.2f}%")
    elif metric == 'R¬≤':
        print(f"{metric:10s}: {value:.4f}")
    else:
        print(f"{metric:10s}: {value:.4f}")

# –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è
print("\n" + "="*50)
print("INTERPRETATION")
print("="*50)
print(f"MAE:  Model is off by ¬±{metrics['MAE']:.2f} on average")
print(f"RMSE: Root mean squared error is {metrics['RMSE']:.2f}")
print(f"R¬≤:   Model explains {metrics['R¬≤']*100:.1f}% of variance")
print(f"MAPE: Average error is {metrics['MAPE']:.1f}%")
```

### –ö–æ–ª–∏ —è–∫—É –º–µ—Ç—Ä–∏–∫—É –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

| –°–∏—Ç—É–∞—Ü—ñ—è | –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ |
|----------|----------------------|
| **–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞** | R¬≤ |
| **–Ñ –≤–∏–∫–∏–¥–∏** | MAE |
| **–í–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ** | RMSE, MSE |
| **–ü–æ—Ç—Ä—ñ–±–Ω—ñ –≤—ñ–¥—Å–æ—Ç–∫–∏** | MAPE |
| **–ë–∞–≥–∞—Ç–æ –æ–∑–Ω–∞–∫** | Adjusted R¬≤ |
| **–ë—ñ–∑–Ω–µ—Å-–∫–æ–º—É–Ω—ñ–∫–∞—Ü—ñ—è** | MAPE, R¬≤ |
| **Loss function** | MSE |

---

# CLASSIFICATION METRICS

## Confusion Matrix (–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏)

### –©–æ —Ü–µ?

**Confusion Matrix** ‚Äî —Ü–µ **—Ç–∞–±–ª–∏—Ü—è**, —è–∫–∞ –ø–æ–∫–∞–∑—É—î, —è–∫ –º–æ–¥–µ–ª—å –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—î –∑—Ä–∞–∑–∫–∏.

```
                 Predicted
                 Positive  Negative
Actual  Positive    TP        FN
        Negative    FP        TN

TP (True Positive)  ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ Positive
TN (True Negative)  ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ Negative
FP (False Positive) ‚Äî –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ Positive (Type I error)
FN (False Negative) ‚Äî –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ Negative (Type II error)
```

### –ü—Ä–∏–∫–ª–∞–¥

```
–ó–∞–¥–∞—á–∞: –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ö–≤–æ—Ä–æ–±–∏

100 –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤:
- 60 —Ö–≤–æ—Ä–∏—Ö
- 40 –∑–¥–æ—Ä–æ–≤–∏—Ö

–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∞:
- 55 —Ö–≤–æ—Ä–∏—Ö (–∑ –Ω–∏—Ö 50 —Å–ø—Ä–∞–≤–¥—ñ —Ö–≤–æ—Ä—ñ, 5 –ø–æ–º–∏–ª–∫–æ–≤–æ)
- 45 –∑–¥–æ—Ä–æ–≤–∏—Ö (–∑ –Ω–∏—Ö 35 —Å–ø—Ä–∞–≤–¥—ñ –∑–¥–æ—Ä–æ–≤—ñ, 10 –ø–æ–º–∏–ª–∫–æ–≤–æ)

Confusion Matrix:
                Predicted
                Sick  Healthy
Actual  Sick     50      10     ‚Üê 50 TP, 10 FN
        Healthy   5      35     ‚Üê 5 FP, 35 TN

TP = 50  (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–Ω–∞–π—à–ª–∏ —Ö–≤–æ—Ä–∏—Ö)
TN = 35  (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–Ω–∞–π—à–ª–∏ –∑–¥–æ—Ä–æ–≤–∏—Ö)
FP = 5   (–ø–æ–º–∏–ª–∫–æ–≤–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç—É–≤–∞–ª–∏ —Ö–≤–æ—Ä–æ–±—É)
FN = 10  (–ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ —Ö–≤–æ—Ä–∏—Ö!) ‚Üê –ö–†–ò–¢–ò–ß–ù–û!
```

### –ö–æ–¥

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# –î–∞–Ω—ñ
y_true = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0])
y_pred = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 1])

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:")
print(cm)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=['Negative', 'Positive']
)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# –ï–ª–µ–º–µ–Ω—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ñ
tn, fp, fn, tp = cm.ravel()
print(f"\nTP (True Positive):  {tp}")
print(f"TN (True Negative):  {tn}")
print(f"FP (False Positive): {fp}")
print(f"FN (False Negative): {fn}")
```

---

## 7. Accuracy (–¢–æ—á–Ω—ñ—Å—Ç—å)

### –§–æ—Ä–º—É–ª–∞

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{\text{–ü—Ä–∞–≤–∏–ª—å–Ω—ñ}}{\text{–í—Å—å–æ–≥–æ}}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Accuracy** ‚Äî —Ü–µ **—á–∞—Å—Ç–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å**.

```
TP = 50, TN = 35, FP = 5, FN = 10

Accuracy = (50 + 35) / (50 + 35 + 5 + 10)
         = 85 / 100
         = 0.85 = 85%

–ú–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –≤ 85% –≤–∏–ø–∞–¥–∫—ñ–≤
```

### –ö–æ–¥

```python
from sklearn.metrics import accuracy_score

y_true = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]
y_pred = [1, 1, 1, 1, 0, 0, 0, 0, 0, 1]

accuracy = accuracy_score(y_true, y_pred)
print(f"Accuracy: {accuracy:.2f} ({accuracy*100:.0f}%)")

# –í—Ä—É—á–Ω—É
correct = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred))
total = len(y_true)
accuracy_manual = correct / total
print(f"Accuracy (manual): {accuracy_manual:.2f}")
```

### –ü—Ä–æ–±–ª–µ–º–∞ Accuracy: –ù–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –∫–ª–∞—Å–∏

```python
# 95% –∑–¥–æ—Ä–æ–≤–∏—Ö, 5% —Ö–≤–æ—Ä–∏—Ö
y_true = [0]*95 + [1]*5

# "–ú–æ–¥–µ–ª—å", —è–∫–∞ –ó–ê–í–ñ–î–ò –∫–∞–∂–µ "–∑–¥–æ—Ä–æ–≤–∏–π"
y_pred = [0]*100

accuracy = accuracy_score(y_true, y_pred)
print(f"Accuracy: {accuracy:.2f}")  # 95%! ‚Üê –ê–ª–µ –º–æ–¥–µ–ª—å –±–µ–∑–≥–ª—É–∑–¥–∞!

# –ú–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π—à–ª–∞ –ñ–û–î–ù–û–ì–û —Ö–≤–æ—Ä–æ–≥–æ, –∞–ª–µ accuracy –≤–∏—Å–æ–∫–∞!
```

**–í–∏—Å–Ω–æ–≤–æ–∫:** Accuracy **–Ω–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å** –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤!

---

## 8. Precision (–¢–æ—á–Ω—ñ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å)

### –§–æ—Ä–º—É–ª–∞

$$\text{Precision} = \frac{TP}{TP + FP} = \frac{\text{–ü—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ}}{\text{–í—Å—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è}}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Precision** –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è: **"–ö–æ–ª–∏ –º–æ–¥–µ–ª—å –∫–∞–∂–µ Positive, –Ω–∞—Å–∫—ñ–ª—å–∫–∏ —á–∞—Å—Ç–æ –≤–æ–Ω–∞ –ø—Ä–∞–≤–∞?"**

```
–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∞ 55 "—Ö–≤–æ—Ä–∏—Ö"
–ó –Ω–∏—Ö 50 —Å–ø—Ä–∞–≤–¥—ñ —Ö–≤–æ—Ä—ñ, 5 ‚Äî –ø–æ–º–∏–ª–∫–æ–≤–æ

Precision = 50 / (50 + 5) = 50 / 55 ‚âà 0.91 = 91%

–ö–æ–ª–∏ –º–æ–¥–µ–ª—å –∫–∞–∂–µ "—Ö–≤–æ—Ä–∏–π", –≤–æ–Ω–∞ –ø—Ä–∞–≤–∞ –≤ 91% –≤–∏–ø–∞–¥–∫—ñ–≤
```

### –ü—Ä–∏–∫–ª–∞–¥: Email Spam Filter

```
100 emails:
- 20 spam
- 80 not spam

–ú–æ–¥–µ–ª—å –ø–æ–∑–Ω–∞—á–∏–ª–∞ 25 —è–∫ spam:
- 18 —Å–ø—Ä–∞–≤–¥—ñ spam (TP)
- 7 —Ö–æ—Ä–æ—à–∏—Ö –ª–∏—Å—Ç—ñ–≤ (FP) ‚Üê –ü–æ–º–∏–ª–∫–æ–≤–æ –≤ —Å–ø–∞–º!

Precision = 18 / (18 + 7) = 18 / 25 = 0.72 = 72%

72% –ª–∏—Å—Ç—ñ–≤ —É —Å–ø–∞–º—ñ ‚Äî —Å–ø—Ä–∞–≤–¥—ñ —Å–ø–∞–º
28% ‚Äî —Ö–æ—Ä–æ—à—ñ –ª–∏—Å—Ç–∏, —è–∫—ñ –º–∏ –≤—Ç—Ä–∞—Ç–∏–ª–∏! ‚ùå
```

### –ö–æ–¥

```python
from sklearn.metrics import precision_score

y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]
y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0]

precision = precision_score(y_true, y_pred)
print(f"Precision: {precision:.4f}")

# –í—Ä—É—á–Ω—É —á–µ—Ä–µ–∑ confusion matrix
cm = confusion_matrix(y_true, y_pred)
tn, fp, fn, tp = cm.ravel()
precision_manual = tp / (tp + fp)
print(f"Precision (manual): {precision_manual:.4f}")
```

### –ö–æ–ª–∏ –≤–∞–∂–ª–∏–≤–∞ –≤–∏—Å–æ–∫–∞ Precision?

- üö´ **Spam —Ñ—ñ–ª—å—Ç—Ä** ‚Äî –Ω–µ —Ö–æ—á–µ–º–æ –≤—Ç—Ä–∞—á–∞—Ç–∏ –≤–∞–∂–ª–∏–≤—ñ –ª–∏—Å—Ç–∏
- üíä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è –ª—ñ–∫—ñ–≤** ‚Äî –ø–æ–º–∏–ª–∫–æ–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è –Ω–µ–±–µ–∑–ø–µ—á–Ω–∞
- üì∫ **–†–µ–∫–ª–∞–º–Ω—ñ –∫–∞–º–ø–∞–Ω—ñ—ó** ‚Äî –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏ —Ä–µ–∫–ª–∞–º—É —Ç—ñ–ª—å–∫–∏ –∑–∞—Ü—ñ–∫–∞–≤–ª–µ–Ω–∏–º
- üè¶ **–í–∏—è–≤–ª–µ–Ω–Ω—è —à–∞—Ö—Ä–∞–π—Å—Ç–≤–∞** ‚Äî –Ω–µ –±–ª–æ–∫—É–≤–∞—Ç–∏ —á–µ—Å–Ω–∏—Ö –∫–ª—ñ—î–Ω—Ç—ñ–≤

---

## 9. Recall (–ü–æ–≤–Ω–æ—Ç–∞ / Sensitivity / True Positive Rate)

### –§–æ—Ä–º—É–ª–∞

$$\text{Recall} = \frac{TP}{TP + FN} = \frac{\text{–ü—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ}}{\text{–í—Å—ñ —Å–ø—Ä–∞–≤–∂–Ω—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ}}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Recall** –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è: **"–°–∫—ñ–ª—å–∫–∏ —Å–ø—Ä–∞–≤–∂–Ω—ñ—Ö Positive –º–∏ –∑–Ω–∞–π—à–ª–∏?"**

```
60 —Å–ø—Ä–∞–≤–¥—ñ —Ö–≤–æ—Ä–∏—Ö –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤
–ú–æ–¥–µ–ª—å –∑–Ω–∞–π—à–ª–∞ 50 –∑ –Ω–∏—Ö
10 –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∞ (FN)

Recall = 50 / (50 + 10) = 50 / 60 ‚âà 0.83 = 83%

–ó–Ω–∞–π—à–ª–∏ 83% —Ö–≤–æ—Ä–∏—Ö
–ü—Ä–æ–ø—É—Å—Ç–∏–ª–∏ 17% ‚Üê –¶–µ –º–æ–∂–µ –±—É—Ç–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ!
```

### –ü—Ä–∏–∫–ª–∞–¥: –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∫—É

```
100 –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤:
- 10 –∑ —Ä–∞–∫–æ–º
- 90 –±–µ–∑ —Ä–∞–∫—É

–ú–æ–¥–µ–ª—å –∑–Ω–∞–π—à–ª–∞ —Ä–∞–∫ —É 8 –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤:
- 7 —Å–ø—Ä–∞–≤–¥—ñ –∑ —Ä–∞–∫–æ–º (TP)
- 1 –ø–æ–º–∏–ª–∫–æ–≤–æ (FP)
- 3 –∑ —Ä–∞–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω—ñ! (FN) ‚Üê –ö–†–ò–¢–ò–ß–ù–û!

Recall = 7 / (7 + 3) = 7 / 10 = 0.7 = 70%

–ó–Ω–∞–π—à–ª–∏ —Ç—ñ–ª—å–∫–∏ 70% —Ö–≤–æ—Ä–∏—Ö –Ω–∞ —Ä–∞–∫!
30% –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ ‚Äî —Ü–µ –Ω–µ–ø—Ä–∏–π–Ω—è—Ç–Ω–æ! ‚ùå
```

### –ö–æ–¥

```python
from sklearn.metrics import recall_score

y_true = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]
y_pred = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0]

recall = recall_score(y_true, y_pred)
print(f"Recall: {recall:.4f}")

# –í—Ä—É—á–Ω—É
cm = confusion_matrix(y_true, y_pred)
tn, fp, fn, tp = cm.ravel()
recall_manual = tp / (tp + fn)
print(f"Recall (manual): {recall_manual:.4f}")
```

### –ö–æ–ª–∏ –≤–∞–∂–ª–∏–≤–∞ –≤–∏—Å–æ–∫–∞ Recall?

- üè• **–î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ö–≤–æ—Ä–æ–±** ‚Äî –Ω–µ –º–æ–∂–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∞—Ç–∏ —Ö–≤–æ—Ä–∏—Ö
- üîí **–í–∏—è–≤–ª–µ–Ω–Ω—è –≤—Ç–æ—Ä–≥–Ω–µ–Ω—å** ‚Äî –∫—Ä–∞—â–µ —Ö–∏–±–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞, –Ω—ñ–∂ –ø—Ä–æ–ø—É—â–µ–Ω–∞ –∞—Ç–∞–∫–∞
- üîç **–ü–æ—à—É–∫ –∑–Ω–∏–∫–ª–∏—Ö –ª—é–¥–µ–π** ‚Äî –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞–π—Ç–∏ –í–°–Ü–•
- ‚ö†Ô∏è **–í–∏—è–≤–ª–µ–Ω–Ω—è –¥–µ—Ñ–µ–∫—Ç—ñ–≤** ‚Äî –Ω–µ –º–æ–∂–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∞—Ç–∏ –±—Ä–∞–∫–æ–≤–∞–Ωi –≤–∏—Ä–æ–±–∏

---

## Precision vs Recall Trade-off

### –ö–æ–Ω—Ñ–ª—ñ–∫—Ç

```
Precision ‚Üë  ‚Üí  Recall ‚Üì
Recall ‚Üë     ‚Üí  Precision ‚Üì

–ù–µ –º–æ–∂–Ω–∞ –º–∞–∫—Å–∏–º—ñ–∑—É–≤–∞—Ç–∏ –æ–±–∏–¥–≤—ñ –æ–¥–Ω–æ—á–∞—Å–Ω–æ!
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
X, y = make_classification(n_samples=1000, n_classes=2, n_features=20,
                          n_informative=15, random_state=42)

# –ú–æ–¥–µ–ª—å
model = LogisticRegression()
model.fit(X, y)

# –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
y_proba = model.predict_proba(X)[:, 1]

# Precision-Recall curve
precision, recall, thresholds = precision_recall_curve(y, y_proba)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(12, 5))

# Subplot 1: Precision-Recall Curve
plt.subplot(1, 2, 1)
plt.plot(recall, precision, linewidth=2, label='PR Curve')
plt.xlabel('Recall', fontsize=12)
plt.ylabel('Precision', fontsize=12)
plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.legend()

# Subplot 2: Thresholds
plt.subplot(1, 2, 2)
plt.plot(thresholds, precision[:-1], label='Precision', linewidth=2)
plt.plot(thresholds, recall[:-1], label='Recall', linewidth=2)
plt.xlabel('Threshold', fontsize=12)
plt.ylabel('Score', fontsize=12)
plt.title('Precision & Recall vs Threshold', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### –ü—Ä–∏–∫–ª–∞–¥: –†—ñ–∑–Ω—ñ –ø–æ—Ä–æ–≥–∏

```python
from sklearn.metrics import precision_score, recall_score

# –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
y_true = np.array([1, 1, 1, 1, 0, 0, 0, 0])
y_proba = np.array([0.9, 0.8, 0.6, 0.4, 0.5, 0.3, 0.2, 0.1])

# –†—ñ–∑–Ω—ñ –ø–æ—Ä–æ–≥–∏
thresholds = [0.3, 0.5, 0.7]

for threshold in thresholds:
    y_pred = (y_proba >= threshold).astype(int)
    
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    
    print(f"\nThreshold = {threshold}:")
    print(f"  Precision: {precision:.2f}")
    print(f"  Recall:    {recall:.2f}")
    print(f"  Predictions: {y_pred}")

# –í–∏–≤—ñ–¥:
# Threshold = 0.3:  Precision: 0.67, Recall: 1.00  ‚Üê –í–∏—Å–æ–∫–∏–π Recall
# Threshold = 0.5:  Precision: 0.75, Recall: 0.75  ‚Üê –ë–∞–ª–∞–Ω—Å
# Threshold = 0.7:  Precision: 1.00, Recall: 0.50  ‚Üê –í–∏—Å–æ–∫–∞ Precision
```

---

## 10. F1-Score

### –§–æ—Ä–º—É–ª–∞

$$F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \cdot TP}{2 \cdot TP + FP + FN}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**F1-Score** ‚Äî —Ü–µ **–≥–∞—Ä–º–æ–Ω—ñ—á–Ω–µ —Å–µ—Ä–µ–¥–Ω—î** Precision —Ç–∞ Recall. –ë–∞–ª–∞–Ω—Å—É—î –º—ñ–∂ –Ω–∏–º–∏.

```
Precision = 0.8
Recall = 0.6

Arithmetic mean: (0.8 + 0.6) / 2 = 0.7
Harmonic mean (F1): 2 * (0.8 * 0.6) / (0.8 + 0.6) ‚âà 0.69

F1 –±–ª–∏–∂—á–µ –¥–æ –º–µ–Ω—à–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è!
```

### –ß–æ–º—É –≥–∞—Ä–º–æ–Ω—ñ—á–Ω–µ —Å–µ—Ä–µ–¥–Ω—î?

```python
# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö
precision = 0.9
recall = 0.1  # –î—É–∂–µ –Ω–∏–∑—å–∫–∏–π!

arithmetic_mean = (precision + recall) / 2
harmonic_mean = 2 * (precision * recall) / (precision + recall)

print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"Arithmetic mean: {arithmetic_mean:.2f}")  # 0.50
print(f"F1 (harmonic):   {harmonic_mean:.2f}")    # 0.18

# F1 –∫–∞—Ä–∞—î –¥–∏—Å–±–∞–ª–∞–Ω—Å –º—ñ–∂ Precision —ñ Recall!
# Arithmetic mean –±—É–ª–∞ –± –∑–∞–Ω–∞–¥—Ç–æ –æ–ø—Ç–∏–º—ñ—Å—Ç–∏—á–Ω–æ—é
```

### –ö–æ–¥

```python
from sklearn.metrics import f1_score

y_true = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]
y_pred = [1, 1, 1, 1, 0, 0, 0, 0, 0, 1]

f1 = f1_score(y_true, y_pred)
print(f"F1-Score: {f1:.4f}")

# –í—Ä—É—á–Ω—É
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1_manual = 2 * (precision * recall) / (precision + recall)
print(f"F1-Score (manual): {f1_manual:.4f}")
```

### F-beta Score (—É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–Ω—è)

```python
from sklearn.metrics import fbeta_score

# Œ≤ –∫–æ–Ω—Ç—Ä–æ–ª—é—î –±–∞–ª–∞–Ω—Å –º—ñ–∂ Precision —ñ Recall

# F0.5: Precision –≤–∞–∂–ª–∏–≤—ñ—à–∞
f05 = fbeta_score(y_true, y_pred, beta=0.5)

# F1: –†—ñ–≤–Ω–∏–π –±–∞–ª–∞–Ω—Å
f1 = fbeta_score(y_true, y_pred, beta=1.0)

# F2: Recall –≤–∞–∂–ª–∏–≤—ñ—à–∏–π
f2 = fbeta_score(y_true, y_pred, beta=2.0)

print(f"F0.5: {f05:.4f}  (favor Precision)")
print(f"F1:   {f1:.4f}   (balanced)")
print(f"F2:   {f2:.4f}   (favor Recall)")
```

---

## 11. Specificity (True Negative Rate)

### –§–æ—Ä–º—É–ª–∞

$$\text{Specificity} = \frac{TN}{TN + FP} = \frac{\text{–ü—Ä–∞–≤–∏–ª—å–Ω—ñ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ}}{\text{–í—Å—ñ —Å–ø—Ä–∞–≤–∂–Ω—ñ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ}}$$

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Specificity** ‚Äî —Ü–µ **"Recall –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –∫–ª–∞—Å—É"**. –°–∫—ñ–ª—å–∫–∏ —Å–ø—Ä–∞–≤–∂–Ω—ñ—Ö Negative –º–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∏–∑–Ω–∞—á–∏–ª–∏.

```
90 –∑–¥–æ—Ä–æ–≤–∏—Ö –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤
–ú–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∏–∑–Ω–∞—á–∏–ª–∞ 85 —è–∫ –∑–¥–æ—Ä–æ–≤–∏—Ö
5 –ø–æ–º–∏–ª–∫–æ–≤–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç—É–≤–∞–ª–∞ —è–∫ —Ö–≤–æ—Ä–∏—Ö (FP)

Specificity = 85 / (85 + 5) = 85 / 90 ‚âà 0.94 = 94%

94% –∑–¥–æ—Ä–æ–≤–∏—Ö –ª—é–¥–µ–π –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∏–∑–Ω–∞—á–µ–Ω—ñ —è–∫ –∑–¥–æ—Ä–æ–≤—ñ
```

### –ö–æ–¥

```python
# Specificity –Ω–µ–º–∞—î –≤ sklearn, —Ä–∞—Ö—É—î–º–æ –≤—Ä—É—á–Ω—É
from sklearn.metrics import confusion_matrix

y_true = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]
y_pred = [1, 1, 1, 0, 0, 0, 0, 0, 1, 0]

cm = confusion_matrix(y_true, y_pred)
tn, fp, fn, tp = cm.ravel()

specificity = tn / (tn + fp)
print(f"Specificity: {specificity:.4f}")

# –¢–∞–∫–æ–∂ –º–æ–∂–Ω–∞ —á–µ—Ä–µ–∑ recall_score –∑ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–º –∫–ª–∞—Å–æ–º = 0
from sklearn.metrics import recall_score
specificity_alt = recall_score(y_true, y_pred, pos_label=0)
print(f"Specificity (alternative): {specificity_alt:.4f}")
```

### –ö–æ–ª–∏ –≤–∞–∂–ª–∏–≤–∞ Specificity?

- ü©∫ **–°–∫—Ä–∏–Ω—ñ–Ω–≥** ‚Äî –Ω–µ —Ö–æ—á–µ–º–æ –ø–∞–Ω—ñ–∫—É–≤–∞—Ç–∏ –∑–¥–æ—Ä–æ–≤–∏—Ö –ª—é–¥–µ–π
- üí≥ **–ê–Ω—Ç–∏—Ñ—Ä–æ–¥** ‚Äî –Ω–µ –±–ª–æ–∫—É–≤–∞—Ç–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ñ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó
- üìß **Email —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è** ‚Äî –Ω–µ –≤–∏–¥–∞–ª—è—Ç–∏ –≤–∞–∂–ª–∏–≤—ñ –ª–∏—Å—Ç–∏

---

## 12. ROC Curve & AUC

### ROC Curve (Receiver Operating Characteristic)

**ROC Curve** –ø–æ–∫–∞–∑—É—î **trade-off –º—ñ–∂ True Positive Rate (Recall) —Ç–∞ False Positive Rate** –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö –ø–æ—Ä–æ–≥–∞—Ö.

```
True Positive Rate (TPR) = Recall = TP / (TP + FN)
False Positive Rate (FPR) = FP / (FP + TN) = 1 - Specificity
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# –î–∞–Ω—ñ
X, y = make_classification(n_samples=1000, n_classes=2, n_features=20,
                          n_informative=15, random_state=42)

# –ú–æ–¥–µ–ª—å
model = LogisticRegression()
model.fit(X, y)

# –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
y_proba = model.predict_proba(X)[:, 1]

# ROC Curve
fpr, tpr, thresholds = roc_curve(y, y_proba)
auc = roc_auc_score(y, y_proba)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(8, 7))
plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')

# –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —Ç–æ—á–∫–∞ (–Ω–∞–π–±–ª–∏–∂—á–∞ –¥–æ (0, 1))
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10,
         label=f'Optimal Threshold = {optimal_threshold:.2f}')

plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)
plt.ylabel('True Positive Rate (Recall)', fontsize=12)
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(f"AUC: {auc:.4f}")
print(f"Optimal threshold: {optimal_threshold:.4f}")
```

### –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è AUC

```
AUC = 1.0  ‚Üí –Ü–¥–µ–∞–ª—å–Ω–∏–π –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä ‚≠ê
AUC = 0.9  ‚Üí –í—ñ–¥–º—ñ–Ω–Ω–∏–π
AUC = 0.8  ‚Üí –î–æ–±—Ä–∏–π
AUC = 0.7  ‚Üí –°–µ—Ä–µ–¥–Ω—ñ–π
AUC = 0.5  ‚Üí –í–∏–ø–∞–¥–∫–æ–≤–∏–π (—è–∫ –ø—ñ–¥–∫–∏–¥–∞–Ω–Ω—è –º–æ–Ω–µ—Ç–∏)
AUC < 0.5  ‚Üí –ì—ñ—Ä—à–µ –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ (—â–æ—Å—å –Ω–µ —Ç–∞–∫!) ‚ùå
```

### –ö–æ–¥

```python
from sklearn.metrics import roc_auc_score

# Binary classification
y_true = np.array([0, 0, 1, 1, 1, 0, 1, 0])
y_proba = np.array([0.1, 0.3, 0.6, 0.8, 0.9, 0.2, 0.7, 0.4])

auc = roc_auc_score(y_true, y_proba)
print(f"AUC: {auc:.4f}")

# Multiclass (one-vs-rest)
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, random_state=42
)

model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

y_proba_multi = model.predict_proba(X_test)

auc_multi = roc_auc_score(y_test, y_proba_multi, multi_class='ovr')
print(f"AUC (multiclass): {auc_multi:.4f}")
```

### –ü–µ—Ä–µ–≤–∞–≥–∏ AUC

| –ü–µ—Ä–µ–≤–∞–≥–∏ | –ù–µ–¥–æ–ª—ñ–∫–∏ |
|----------|----------|
| ‚úÖ –ù–µ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –ø–æ—Ä–æ–≥—É | ‚ùå –°–∫–ª–∞–¥–Ω—ñ—à–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ |
| ‚úÖ –ü—Ä–∞—Ü—é—î –∑ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–º–∏ –∫–ª–∞—Å–∞–º–∏ | ‚ùå –ú–æ–∂–µ –±—É—Ç–∏ –æ–ø—Ç–∏–º—ñ—Å—Ç–∏—á–Ω–æ—é |
| ‚úÖ –û–¥–Ω–µ —á–∏—Å–ª–æ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è | ‚ùå –ù–µ –ø–æ–∫–∞–∑—É—î –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ Precision/Recall |

---

## 13. Log Loss (Cross-Entropy Loss)

### –§–æ—Ä–º—É–ª–∞

$$\text{Log Loss} = -\frac{1}{n}\sum_{i=1}^{n} [y_i \log(\hat{p}_i) + (1-y_i)\log(1-\hat{p}_i)]$$

–¥–µ:
- $y_i$ ‚Äî —Å–ø—Ä–∞–≤–∂–Ω—ñ–π –∫–ª–∞—Å (0 –∞–±–æ 1)
- $\hat{p}_i$ ‚Äî –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—É 1

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Log Loss** –∫–∞—Ä–∞—î **–≤–ø–µ–≤–Ω–µ–Ω—ñ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è** –¥—É–∂–µ —Å–∏–ª—å–Ω–æ.

```
–°–ø—Ä–∞–≤–∂–Ω—ñ–π –∫–ª–∞—Å: 1 (Positive)

–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: p = 0.9  ‚Üí Log Loss = -log(0.9) ‚âà 0.10   ‚úì –ú–∞–ª–∞ –ø–æ–º–∏–ª–∫–∞
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: p = 0.5  ‚Üí Log Loss = -log(0.5) ‚âà 0.69   ‚ö†Ô∏è –°–µ—Ä–µ–¥–Ω—è
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: p = 0.1  ‚Üí Log Loss = -log(0.1) ‚âà 2.30   ‚ùå –í–µ–ª–∏–∫–∞ –ø–æ–º–∏–ª–∫–∞!
–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: p = 0.01 ‚Üí Log Loss = -log(0.01) ‚âà 4.61  ‚ùå‚ùå –î—É–∂–µ –≤–µ–ª–∏–∫–∞!
```

### –ö–æ–¥

```python
from sklearn.metrics import log_loss

y_true = [1, 0, 1, 1, 0]

# –ì–∞—Ä–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_proba_good = [
    [0.1, 0.9],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.9 ‚úì
    [0.8, 0.2],   # –ö–ª–∞—Å 0, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.8 ‚úì
    [0.2, 0.8],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.8 ‚úì
    [0.1, 0.9],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.9 ‚úì
    [0.9, 0.1]    # –ö–ª–∞—Å 0, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.9 ‚úì
]

# –ü–æ–≥–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_proba_bad = [
    [0.9, 0.1],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.1 ‚ùå
    [0.2, 0.8],   # –ö–ª–∞—Å 0, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.2 ‚ùå
    [0.8, 0.2],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.2 ‚ùå
    [0.9, 0.1],   # –ö–ª–∞—Å 1, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.1 ‚ùå
    [0.1, 0.9]    # –ö–ª–∞—Å 0, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å 0.1 ‚ùå
]

loss_good = log_loss(y_true, y_proba_good)
loss_bad = log_loss(y_true, y_proba_bad)

print(f"Log Loss (good predictions): {loss_good:.4f}")
print(f"Log Loss (bad predictions):  {loss_bad:.4f}")
```

### –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?

- ‚úÖ –ö–æ–ª–∏ –≤–∞–∂–ª–∏–≤—ñ **–∫–∞–ª—ñ–±—Ä–æ–≤–∞–Ω—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ**
- ‚úÖ –î–ª—è **loss function** –≤ neural networks
- ‚úÖ Kaggle competitions
- ‚ùå –ö–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –ø—Ä–æ—Å—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Accuracy/F1)

---

## 14. Cohen's Kappa

### –§–æ—Ä–º—É–ª–∞

$$\kappa = \frac{p_o - p_e}{1 - p_e}$$

–¥–µ:
- $p_o$ ‚Äî observed agreement (accuracy)
- $p_e$ ‚Äî expected agreement by chance

### –Ü–Ω—Ç—É—ó—Ü—ñ—è

**Cohen's Kappa** –≤—Ä–∞—Ö–æ–≤—É—î **–≤–∏–ø–∞–¥–∫–æ–≤—ñ –∑–±—ñ–≥–∏**. –ö–æ—Ä–∏—Å–Ω–∞ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤.

```
100 –∑—Ä–∞–∑–∫—ñ–≤: 90 –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö, 10 –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö

–ú–æ–¥–µ–ª—å –∑–∞–≤–∂–¥–∏ –∫–∞–∂–µ "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π":
Accuracy = 90% ‚Üê –ó–¥–∞—î—Ç—å—Å—è –¥–æ–±—Ä–µ!

–ê–ª–µ –≤–∏–ø–∞–¥–∫–æ–≤–∞ –º–æ–¥–µ–ª—å —Ç–∞–∫–æ–∂ –¥–∞—Å—Ç—å ~90% (–ø—Ä–æ—Å—Ç–æ —á–µ—Ä–µ–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å)

Kappa = (0.9 - 0.9) / (1 - 0.9) = 0 / 0.1 = 0
‚Üê –ú–æ–¥–µ–ª—å –Ω–µ –∫—Ä–∞—â–∞ –∑–∞ –≤–∏–ø–∞–¥–∫–æ–≤—É!
```

### –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è

```
Œ∫ = 1.0   ‚Üí –Ü–¥–µ–∞–ª—å–Ω–∞ –∑–≥–æ–¥–∞
Œ∫ = 0.8   ‚Üí –ú–∞–π–∂–µ —ñ–¥–µ–∞–ª—å–Ω–∞
Œ∫ = 0.6   ‚Üí –°—É—Ç—Ç—î–≤–∞
Œ∫ = 0.4   ‚Üí –ü–æ–º—ñ—Ä–Ω–∞
Œ∫ = 0.2   ‚Üí –°–ª–∞–±–∫–∞
Œ∫ = 0.0   ‚Üí –í–∏–ø–∞–¥–∫–æ–≤–∞ (–Ω–µ –∫—Ä–∞—â–∞ –∑–∞ chance)
Œ∫ < 0     ‚Üí –ì—ñ—Ä—à–µ –≤–∏–ø–∞–¥–∫–æ–≤–æ—ó
```

### –ö–æ–¥

```python
from sklearn.metrics import cohen_kappa_score

y_true = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]
y_pred = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]

kappa = cohen_kappa_score(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Cohen's Kappa: {kappa:.2f}")

# –ú–æ–¥–µ–ª—å, —è–∫–∞ –∑–∞–≤–∂–¥–∏ –∫–∞–∂–µ "0"
y_pred_always_0 = [0] * 10

kappa_bad = cohen_kappa_score(y_true, y_pred_always_0)
accuracy_bad = accuracy_score(y_true, y_pred_always_0)

print(f"\nAlways-0 model:")
print(f"Accuracy: {accuracy_bad:.2f}")  # 0.60
print(f"Cohen's Kappa: {kappa_bad:.2f}")  # –ë–ª–∏–∑—å–∫–æ –¥–æ 0
```

---

## Multiclass Classification Metrics

### Macro vs Micro vs Weighted Average

```python
from sklearn.metrics import classification_report

# 3 –∫–ª–∞—Å–∏
y_true = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2]
y_pred = [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0]

report = classification_report(y_true, y_pred, 
                               target_names=['Class 0', 'Class 1', 'Class 2'])
print(report)
```

**–í–∏–≤—ñ–¥:**
```
              precision    recall  f1-score   support

     Class 0       0.75      0.75      0.75         4
     Class 1       0.75      0.75      0.75         4
     Class 2       1.00      0.80      0.89         5

    accuracy                           0.83        13
   macro avg       0.83      0.77      0.80        13
weighted avg       0.86      0.77      0.81        13
```

**–ü–æ—è—Å–Ω–µ–Ω–Ω—è:**
- **Macro average:** –ü—Ä–æ—Å—Ç–∞ —Å–µ—Ä–µ–¥–Ω—è –ø–æ –≤—Å—ñ—Ö –∫–ª–∞—Å–∞—Ö (–Ω–µ –≤—Ä–∞—Ö–æ–≤—É—î –¥–∏—Å–±–∞–ª–∞–Ω—Å)
- **Weighted average:** –ó–≤–∞–∂–µ–Ω–∞ —Å–µ—Ä–µ–¥–Ω—è (–≤—Ä–∞—Ö–æ–≤—É—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤ —É –∫–æ–∂–Ω–æ–º—É –∫–ª–∞—Å—ñ)
- **Micro average:** –ó–∞–≥–∞–ª—å–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ (—è–∫ accuracy –¥–ª—è multiclass)

### –ü—Ä–∏–∫–ª–∞–¥

```python
from sklearn.metrics import precision_score, recall_score, f1_score

y_true = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2]
y_pred = [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0]

# Macro: —Å–µ—Ä–µ–¥–Ω—î –ø–æ –∫–ª–∞—Å–∞—Ö
f1_macro = f1_score(y_true, y_pred, average='macro')

# Micro: –∑–∞–≥–∞–ª—å–Ω–µ
f1_micro = f1_score(y_true, y_pred, average='micro')

# Weighted: –∑–≤–∞–∂–µ–Ω–µ
f1_weighted = f1_score(y_true, y_pred, average='weighted')

print(f"F1 Macro:    {f1_macro:.4f}")
print(f"F1 Micro:    {f1_micro:.4f}")  # = Accuracy –¥–ª—è multiclass
print(f"F1 Weighted: {f1_weighted:.4f}")
```

---

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è Classification Metrics

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, cohen_kappa_score,
                             log_loss, confusion_matrix)
import pandas as pd

# –î–∞–Ω—ñ
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

# –ú–æ–¥–µ–ª—å
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

# –í—Å—ñ –º–µ—Ç—Ä–∏–∫–∏
metrics = {
    'Accuracy': accuracy_score(y_test, y_pred),
    'Precision': precision_score(y_test, y_pred),
    'Recall': recall_score(y_test, y_pred),
    'Specificity': tn / (tn + fp),
    'F1-Score': f1_score(y_test, y_pred),
    'ROC-AUC': roc_auc_score(y_test, y_proba),
    'Cohen\'s Kappa': cohen_kappa_score(y_test, y_pred),
    'Log Loss': log_loss(y_test, y_proba)
}

print("="*60)
print("CLASSIFICATION METRICS SUMMARY")
print("="*60)

for metric, value in metrics.items():
    print(f"{metric:20s}: {value:.4f}")

print("\n" + "="*60)
print("CONFUSION MATRIX")
print("="*60)
print(f"TP (True Positive):  {tp}")
print(f"TN (True Negative):  {tn}")
print(f"FP (False Positive): {fp}")
print(f"FN (False Negative): {fn}")
```

---

## –í–∏–±—ñ—Ä –º–µ—Ç—Ä–∏–∫–∏: Decision Tree

```
                    START
                      |
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                         ‚îÇ
    Regression?              Classification?
         ‚îÇ                         ‚îÇ
         ‚ñº                         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ        ‚îÇ            ‚îÇ             ‚îÇ
    ‚îÇ  Yes   ‚îÇ            ‚îÇ     Yes     ‚îÇ
    ‚îÇ        ‚îÇ            ‚îÇ             ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ General     ‚îÇ      ‚îÇ Balanced       ‚îÇ
   ‚îÇ evaluation? ‚îÇ      ‚îÇ classes?       ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ         ‚îÇ           ‚îÇ           ‚îÇ
    Yes       No          Yes         No
     ‚îÇ         ‚îÇ           ‚îÇ           ‚îÇ
     ‚ñº         ‚ñº           ‚ñº           ‚ñº
   R¬≤      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   Accuracy   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ Outliers?‚îÇ            ‚îÇ What's  ‚îÇ
          ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò            ‚îÇimportant‚îÇ
            ‚îÇ     ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îò
           Yes   No                  ‚îÇ   ‚îÇ
            ‚îÇ     ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îê
            ‚ñº     ‚ñº              ‚îÇ           ‚îÇ
          MAE   RMSE         Minimize    Minimize
                              FP?         FN?
                               ‚îÇ           ‚îÇ
                               ‚ñº           ‚ñº
                          Precision    Recall
                               ‚îÇ           ‚îÇ
                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
                                     ‚ñº
                                Both equally?
                                     ‚îÇ
                                     ‚ñº
                                 F1-Score
```

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏ üí°

### 1. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –∫—ñ–ª—å–∫–∞ –º–µ—Ç—Ä–∏–∫ –æ–¥–Ω–æ—á–∞—Å–Ω–æ

```python
from sklearn.metrics import classification_report

# –ù–µ –ø–æ–∫–ª–∞–¥–∞–π—Å—è –Ω–∞ –æ–¥–Ω—É –º–µ—Ç—Ä–∏–∫—É!
print(classification_report(y_test, y_pred))

# –î–∏–≤–∏—Å—å –Ω–∞:
# - Accuracy (–∑–∞–≥–∞–ª—å–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∞)
# - Precision/Recall –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É
# - F1-Score (–±–∞–ª–∞–Ω—Å)
# - Support (—Å–∫—ñ–ª—å–∫–∏ –∑—Ä–∞–∑–∫—ñ–≤)
```

### 2. –ó–∞–≤–∂–¥–∏ –¥–∏–≤–∏—Å—å –Ω–∞ Confusion Matrix

```python
from sklearn.metrics import ConfusionMatrixDisplay

# –í—ñ–∑—É–∞–ª—ñ–∑—É–π –¥–µ –º–æ–¥–µ–ª—å –ø–æ–º–∏–ª—è—î—Ç—å—Å—è
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.show()

# –ê–Ω–∞–ª—ñ–∑—É–π:
# - –Ø–∫—ñ –∫–ª–∞—Å–∏ –ø–ª—É—Ç–∞—é—Ç—å—Å—è –º—ñ–∂ —Å–æ–±–æ—é?
# - –ß–∏ —î –∞—Å–∏–º–µ—Ç—Ä–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏?
```

### 3. –í—Ä–∞—Ö–æ–≤—É–π business context

```python
# –ú–µ–¥–∏—á–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
# FN (–ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ —Ö–≤–æ—Ä—É –ª—é–¥–∏–Ω—É) >> FP (—Ö–∏–±–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞)
# ‚Üí –ú–∞–∫—Å–∏–º—ñ–∑—É–π Recall!

# Spam —Ñ—ñ–ª—å—Ç—Ä
# FP (–≤–∞–∂–ª–∏–≤–∏–π –ª–∏—Å—Ç —É —Å–ø–∞–º) >> FN (—Å–ø–∞–º —É inbox)
# ‚Üí –ú–∞–∫—Å–∏–º—ñ–∑—É–π Precision!

# Fraud detection
# –ë–∞–ª–∞–Ω—Å –º—ñ–∂ Precision —ñ Recall
# ‚Üí F1-Score –∞–±–æ custom threshold
```

### 4. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π ROC-AUC –¥–ª—è model selection

```python
from sklearn.model_selection import cross_val_score

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier()
}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')
    print(f"{name}: AUC = {scores.mean():.4f} (+/- {scores.std():.4f})")
```

### 5. –û–ø—Ç–∏–º—ñ–∑—É–π –ø–æ—Ä—ñ–≥ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏—Ö –ø–æ—Ç—Ä–µ–±

```python
from sklearn.metrics import precision_recall_curve

# –ó–Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)

# –ú–∞–∫—Å–∏–º—ñ–∑—É–≤–∞—Ç–∏ F1
f1_scores = 2 * (precision * recall) / (precision + recall)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]

print(f"Optimal threshold for F1: {optimal_threshold:.3f}")

# –ê–±–æ custom –≤–∏–º–æ–≥–∏
# –ó–Ω–∞–π—Ç–∏ –ø–æ—Ä—ñ–≥ –¥–µ Recall >= 0.9
high_recall_idx = np.where(recall >= 0.9)[0]
if len(high_recall_idx) > 0:
    threshold_90_recall = thresholds[high_recall_idx[0]]
    print(f"Threshold for Recall >= 0.9: {threshold_90_recall:.3f}")
```

---

## –†–µ–∞–ª—å–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: Comprehensive Evaluation

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, roc_curve,
                             confusion_matrix, ConfusionMatrixDisplay,
                             classification_report, precision_recall_curve)

print("="*70)
print("COMPREHENSIVE MODEL EVALUATION")
print("="*70)

# –î–∞–Ω—ñ
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, stratify=cancer.target, random_state=42
)

print(f"\nDataset: {cancer.data.shape[0]} samples")
print(f"Train: {X_train.shape[0]} samples")
print(f"Test: {X_test.shape[0]} samples")
print(f"Class distribution: {np.bincount(cancer.target)}")

# –ú–æ–¥–µ–ª—å
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# ============================================
# 1. –ë–ê–ó–û–í–Ü –ú–ï–¢–†–ò–ö–ò
# ============================================
print("\n" + "="*70)
print("1. BASIC METRICS")
print("="*70)

cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

print(f"\nConfusion Matrix:")
print(f"  TP: {tp:3d}  |  FN: {fn:3d}")
print(f"  FP: {fp:3d}  |  TN: {tn:3d}")

metrics_basic = {
    'Accuracy': accuracy_score(y_test, y_pred),
    'Precision': precision_score(y_test, y_pred),
    'Recall': recall_score(y_test, y_pred),
    'Specificity': tn / (tn + fp),
    'F1-Score': f1_score(y_test, y_pred)
}

print("\nScores:")
for metric, value in metrics_basic.items():
    print(f"  {metric:15s}: {value:.4f}")

# ============================================
# 2. ADVANCED METRICS
# ============================================
print("\n" + "="*70)
print("2. ADVANCED METRICS")
print("="*70)

auc = roc_auc_score(y_test, y_proba)
from sklearn.metrics import log_loss, cohen_kappa_score

metrics_advanced = {
    'ROC-AUC': auc,
    'Log Loss': log_loss(y_test, y_proba),
    "Cohen's Kappa": cohen_kappa_score(y_test, y_pred)
}

for metric, value in metrics_advanced.items():
    print(f"  {metric:15s}: {value:.4f}")

# ============================================
# 3. CLASSIFICATION REPORT
# ============================================
print("\n" + "="*70)
print("3. CLASSIFICATION REPORT")
print("="*70)
print(classification_report(y_test, y_pred, 
                           target_names=['Malignant', 'Benign']))

# ============================================
# 4. CROSS-VALIDATION
# ============================================
print("="*70)
print("4. CROSS-VALIDATION (5-fold)")
print("="*70)

cv_scores = {}
scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

for metric in scoring_metrics:
    scores = cross_val_score(model, cancer.data, cancer.target, 
                            cv=5, scoring=metric)
    cv_scores[metric] = scores
    print(f"  {metric:10s}: {scores.mean():.4f} (+/- {scores.std():.4f})")

# ============================================
# 5. –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø
# ============================================
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Subplot 1: Confusion Matrix
ConfusionMatrixDisplay(confusion_matrix=cm, 
                       display_labels=['Malignant', 'Benign']).plot(
    ax=axes[0, 0], cmap='Blues')
axes[0, 0].set_title('Confusion Matrix', fontsize=13, fontweight='bold')

# Subplot 2: ROC Curve
fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)
axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.3f}')
axes[0, 1].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')
axes[0, 1].set_xlabel('False Positive Rate', fontsize=11)
axes[0, 1].set_ylabel('True Positive Rate', fontsize=11)
axes[0, 1].set_title('ROC Curve', fontsize=13, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Subplot 3: Precision-Recall Curve
precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)
axes[1, 0].plot(recall, precision, linewidth=2)
axes[1, 0].set_xlabel('Recall', fontsize=11)
axes[1, 0].set_ylabel('Precision', fontsize=11)
axes[1, 0].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Subplot 4: Threshold Analysis
axes[1, 1].plot(thresholds_pr, precision[:-1], label='Precision', linewidth=2)
axes[1, 1].plot(thresholds_pr, recall[:-1], label='Recall', linewidth=2)

# F1 scores
f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])
axes[1, 1].plot(thresholds_pr, f1_scores, label='F1-Score', linewidth=2, linestyle='--')

# Optimal threshold
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds_pr[optimal_idx]
axes[1, 1].axvline(x=optimal_threshold, color='red', linestyle=':', 
                   linewidth=2, label=f'Optimal ({optimal_threshold:.2f})')

axes[1, 1].set_xlabel('Threshold', fontsize=11)
axes[1, 1].set_ylabel('Score', fontsize=11)
axes[1, 1].set_title('Metrics vs Threshold', fontsize=13, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================
# 6. RECOMMENDATIONS
# ============================================
print("\n" + "="*70)
print("6. RECOMMENDATIONS")
print("="*70)

if metrics_basic['Accuracy'] > 0.95:
    print("‚úÖ Excellent performance!")
elif metrics_basic['Accuracy'] > 0.9:
    print("‚úÖ Good performance")
else:
    print("‚ö†Ô∏è  Room for improvement")

if abs(metrics_basic['Precision'] - metrics_basic['Recall']) > 0.1:
    print("‚ö†Ô∏è  Imbalance between Precision and Recall")
    if metrics_basic['Precision'] > metrics_basic['Recall']:
        print("   ‚Üí Consider lowering threshold to improve Recall")
    else:
        print("   ‚Üí Consider raising threshold to improve Precision")

if auc > 0.95:
    print("‚úÖ Excellent discrimination ability (AUC > 0.95)")
elif auc > 0.9:
    print("‚úÖ Good discrimination ability (AUC > 0.9)")
else:
    print("‚ö†Ô∏è  Consider feature engineering or different model")

print(f"\nüí° Suggested optimal threshold: {optimal_threshold:.3f}")
print(f"   (maximizes F1-Score = {f1_scores[optimal_idx]:.4f})")

print("="*70)
```

---

## –ü—ñ–¥—Å—É–º–∫–æ–≤–∞ —Ç–∞–±–ª–∏—Ü—è –º–µ—Ç—Ä–∏–∫

### Regression

| –ú–µ—Ç—Ä–∏–∫–∞ | –§–æ—Ä–º—É–ª–∞ | –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ | –û–¥–∏–Ω–∏—Ü—ñ |
|---------|---------|---------------------|---------|
| **MAE** | $\frac{1}{n}\sum\|y - \hat{y}\|$ | –í–∏–∫–∏–¥–∏, –ø—Ä–æ—Å—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è | –¢—ñ –∂ —â–æ y |
| **MSE** | $\frac{1}{n}\sum(y - \hat{y})^2$ | –í–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ | –ö–≤–∞–¥—Ä–∞—Ç y |
| **RMSE** | $\sqrt{\text{MSE}}$ | MSE + —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è | –¢—ñ –∂ —â–æ y |
| **R¬≤** | $1 - \frac{\text{SS}_{res}}{\text{SS}_{tot}}$ | –ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ | 0 to 1 |
| **Adjusted R¬≤** | $1 - \frac{(1-R^2)(n-1)}{n-p-1}$ | –ë–∞–≥–∞—Ç–æ –æ–∑–Ω–∞–∫ | 0 to 1 |
| **MAPE** | $\frac{100\%}{n}\sum\|\frac{y-\hat{y}}{y}\|$ | –í—ñ–¥—Å–æ—Ç–∫–∏, –±—ñ–∑–Ω–µ—Å | % |

### Classification

| –ú–µ—Ç—Ä–∏–∫–∞ | –§–æ—Ä–º—É–ª–∞ | –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ |
|---------|---------|---------------------|
| **Accuracy** | $\frac{TP+TN}{\text{All}}$ | –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –∫–ª–∞—Å–∏ |
| **Precision** | $\frac{TP}{TP+FP}$ | –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ FP |
| **Recall** | $\frac{TP}{TP+FN}$ | –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ FN |
| **Specificity** | $\frac{TN}{TN+FP}$ | –ü—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ |
| **F1-Score** | $\frac{2 \cdot P \cdot R}{P + R}$ | –ë–∞–ª–∞–Ω—Å Precision/Recall |
| **ROC-AUC** | Area under ROC curve | –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π |
| **Log Loss** | $-\frac{1}{n}\sum[y\log(\hat{p})+(1-y)\log(1-\hat{p})]$ | –ö–∞–ª—ñ–±—Ä–æ–≤–∞–Ω—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ |
| **Cohen's Œ∫** | $\frac{p_o - p_e}{1 - p_e}$ | –ù–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –∫–ª–∞—Å–∏ |

---

## –ü–æ–≤'—è–∑–∞–Ω—ñ —Ç–µ–º–∏

- [[01_Bias_Variance_Tradeoff]] ‚Äî —è–∫ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ bias/variance
- [[02_Overfitting_Underfitting]] ‚Äî –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —á–µ—Ä–µ–∑ –º–µ—Ç—Ä–∏–∫–∏
- [[03_Train_Test_Split]] ‚Äî –¥–µ –æ—Ü—ñ–Ω—é–≤–∞—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏
- [[04_Cross_Validation]] ‚Äî –Ω–∞–¥—ñ–π–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫
- [[Confusion_Matrix]] ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è classification metrics
- [[Model_Selection]] ‚Äî –≤–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫

## –†–µ—Å—É—Ä—Å–∏

- [Scikit-learn: Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [Precision vs Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- [ROC Curves Explained](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> Evaluation Metrics ‚Äî —Ü–µ –∫—ñ–ª—å–∫—ñ—Å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ. –†—ñ–∑–Ω—ñ –∑–∞–¥–∞—á—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å —Ä—ñ–∑–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫. –í–∏–±—ñ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –º–µ—Ç—Ä–∏–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è —É—Å–ø—ñ—Ö—É –ø—Ä–æ–µ–∫—Ç—É.

**Regression:**
- **R¬≤** ‚Äî –æ—Å–Ω–æ–≤–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ (0-1, % –ø–æ—è—Å–Ω–µ–Ω–æ—ó –≤–∞—Ä—ñ–∞—Ü—ñ—ó)
- **MAE** ‚Äî –ø—Ä–æ—Å—Ç–∞, —Å—Ç—ñ–π–∫–∞ –¥–æ –≤–∏–∫–∏–¥—ñ–≤ (—Ç—ñ –∂ –æ–¥–∏–Ω–∏—Ü—ñ —â–æ y)
- **RMSE** ‚Äî –∫–∞—Ä–∞—î –≤–µ–ª–∏–∫—ñ –ø–æ–º–∏–ª–∫–∏ (—Ç—ñ –∂ –æ–¥–∏–Ω–∏—Ü—ñ —â–æ y)

**Classification:**
- **Accuracy** ‚Äî —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤
- **Precision** ‚Äî –º—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ FP (–Ω–µ –ø–æ–º–∏–ª–∫–æ–≤–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ)
- **Recall** ‚Äî –º—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ FN (–∑–Ω–∞–π—Ç–∏ –≤—Å—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ)
- **F1** ‚Äî –±–∞–ª–∞–Ω—Å Precision/Recall
- **ROC-AUC** ‚Äî –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π, –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –ø–æ—Ä–æ–≥—É

**–ó–æ–ª–æ—Ç—ñ –ø—Ä–∞–≤–∏–ª–∞:**
1. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π **–∫—ñ–ª—å–∫–∞ –º–µ—Ç—Ä–∏–∫** –æ–¥–Ω–æ—á–∞—Å–Ω–æ
2. –ó–∞–≤–∂–¥–∏ –¥–∏–≤–∏—Å—å –Ω–∞ **Confusion Matrix**
3. –í—Ä–∞—Ö–æ–≤—É–π **business context**
4. –ù–µ –ø–æ–∫–ª–∞–¥–∞–π—Å—è —Ç—ñ–ª—å–∫–∏ –Ω–∞ **Accuracy**
5. –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (ROC, PR curves)

---

#ml #metrics #evaluation #regression-metrics #classification-metrics #accuracy #precision #recall #f1-score #roc-auc
