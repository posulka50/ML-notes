# PCA ‚Äî Principal Component Analysis

**PCA (Principal Component Analysis)** ‚Äî –º–µ—Ç–æ–¥ –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ, —è–∫–∏–π –∑–Ω–∞—Ö–æ–¥–∏—Ç—å **–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ –Ω–∞–ø—Ä—è–º–∫–∏** (–≥–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏) –≤ –¥–∞–Ω–∏—Ö —ñ –ø—Ä–æ—î–∫—Ç—É—î –¥–∞–Ω—ñ –Ω–∞ —Ü—ñ –Ω–∞–ø—Ä—è–º–∫–∏.

**–ì–æ–ª–æ–≤–Ω–∞ —ñ–¥–µ—è:** –ó–∞–º—ñ—Å—Ç—å –±–∞–≥–∞—Ç—å–æ—Ö –æ–∑–Ω–∞–∫ (features) –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫—ñ–ª—å–∫–∞ **–≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç**, —è–∫—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å –±—ñ–ª—å—à—É —á–∞—Å—Ç–∏–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó.

---

## –©–æ —Ü–µ

PCA ‚Äî —Ü–µ —Ç–µ—Ö–Ω—ñ–∫–∞, —è–∫–∞:

- **–ó–º–µ–Ω—à—É—î —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö** (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 100 –æ–∑–Ω–∞–∫ ‚Üí 10 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç) ‚úì
- **–ó–±–µ—Ä—ñ–≥–∞—î –º–∞–∫—Å–∏–º—É–º —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó** (variance) ‚úì
- **–ó–Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–µ–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ –Ω–∞–ø—Ä—è–º–∫–∏** (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ñ –æ—Å—ñ) ‚úì
- **–£—Å—É–≤–∞—î —à—É–º** —Ç–∞ –Ω–∞–¥–º—ñ—Ä–Ω—ñ—Å—Ç—å ‚úì
- **–ü–æ–ª–µ–≥—à—É—î –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é** (–±—É–¥—å-—è–∫–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å ‚Üí 2D/3D) ‚úì

---

## –ù–∞–≤—ñ—â–æ

### –ü—Ä–æ–±–ª–µ–º–∞ –≤–∏—Å–æ–∫–æ—ó —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ

```
–ú–∞—î–º–æ –¥–∞–Ω—ñ: 1000 –æ–∑–Ω–∞–∫ (features)

–ü—Ä–æ–±–ª–µ–º–∏:
  ‚úó –í–∞–∂–∫–æ –≤—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏
  ‚úó –ü–æ–≤—ñ–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è
  ‚úó Curse of dimensionality (–≤—Å—ñ —Ç–æ—á–∫–∏ –¥–∞–ª–µ–∫–æ)
  ‚úó –ë–∞–≥–∞—Ç–æ —à—É–º—É
  ‚úó –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω—è (overfitting)

PCA:
  ‚úì –ó–º–µ–Ω—à—É—î–º–æ –¥–æ 10-50 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
  ‚úì –ó–±–µ—Ä—ñ–≥–∞—î–º–æ 95% —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
  ‚úì –®–≤–∏–¥—à–µ, –∫—Ä–∞—â–µ, –ø—Ä–æ—Å—Ç—ñ—à–µ
```

### –ü—Ä–∏–∫–ª–∞–¥–∏ –∑–∞–¥–∞—á

- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏—Å–æ–∫–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö (1000D ‚Üí 2D)
- –ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è ML –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ (–º–µ–Ω—à–µ –æ–∑–Ω–∞–∫ ‚Üí —à–≤–∏–¥—à–µ)
- –£—Å—É–Ω–µ–Ω–Ω—è –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω–æ—Å—Ç—ñ (–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏)
- –°—Ç–∏—Å–Ω–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö (–∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è, –ø–µ—Ä–µ–¥–∞—á–∞)
- –®—É–º–æ–æ—á–∏—â–µ–Ω–Ω—è (denoising)
- Feature extraction (–Ω–æ–≤—ñ –æ–∑–Ω–∞–∫–∏)

---

## –Ü–Ω—Ç—É—ó—Ü—ñ—è ‚Äî –ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏

### –ü—Ä–∏–∫–ª–∞–¥: –î–∞–Ω—ñ –ø—Ä–æ –ª—é–¥–µ–π

```
–ú–∞—î–º–æ 2 –æ–∑–Ω–∞–∫–∏:
- –ó—Ä—ñ—Å—Ç (—Å–º)
- –í–∞–≥–∞ (–∫–≥)

–í—ñ–∑—É–∞–ª—å–Ω–æ:
–í–∞–≥–∞
  ‚îÇ    ‚óè
  ‚îÇ   ‚óè ‚óè
  ‚îÇ  ‚óè ‚óè ‚óè   ‚Üê —Ç–æ—á–∫–∏ —Ä–æ–∑—Ç–∞—à–æ–≤–∞–Ω—ñ –ø–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ
  ‚îÇ ‚óè ‚óè ‚óè
  ‚îÇ‚óè ‚óè ‚óè
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ó—Ä—ñ—Å—Ç

–ó—Ä—ñ—Å—Ç —ñ –≤–∞–≥–∞ –ö–û–†–ï–õ–Æ–Æ–¢–¨ (–≤–∏—Å–æ–∫—ñ –ª—é–¥–∏ –≤–∞–∂—á—ñ)
```

**PCA –∑–Ω–∞—Ö–æ–¥–∏—Ç—å:**

```
PC1 (–ø–µ—Ä—à–∏–π –≥–æ–ª–æ–≤–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç):
  –ù–∞–ø—Ä—è–º–æ–∫ –ø–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ ‚Üó (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—è)
  "–†–æ–∑–º—ñ—Ä –ª—é–¥–∏–Ω–∏" = –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è –∑—Ä–æ—Å—Ç—É —ñ –≤–∞–≥–∏

PC2 (–¥—Ä—É–≥–∏–π –≥–æ–ª–æ–≤–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç):
  –ù–∞–ø—Ä—è–º–æ–∫ –ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–æ ‚Üñ (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–∞—Ä—ñ–∞—Ü—ñ—è)
  "–°—Ç–∞—Ç—É—Ä–∞" = —Ä—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ –≤–∞–≥–æ—é —ñ –∑—Ä–æ—Å—Ç–æ–º
  
–¢–µ–ø–µ—Ä –∑–∞–º—ñ—Å—Ç—å (–∑—Ä—ñ—Å—Ç, –≤–∞–≥–∞) –º–∞—î–º–æ (PC1, PC2)
```

**–ü–µ—Ä–µ–≤–∞–≥–∏:**

- PC1 —ñ PC2 **–Ω–µ –∫–æ—Ä–µ–ª—é—é—Ç—å** (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ñ)
- PC1 –æ–ø–∏—Å—É—î –±—ñ–ª—å—à—É —á–∞—Å—Ç–∏–Ω—É –≤–∞—Ä—ñ–∞—Ü—ñ—ó
- –ú–æ–∂–Ω–∞ –≤—ñ–¥–∫–∏–Ω—É—Ç–∏ PC2 (–º–∞–ª–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó) ‚Üí 2D ‚Üí 1D

---

### –ê–Ω–∞–ª–æ–≥—ñ—è: –§–æ—Ç–æ–≥—Ä–∞—Ñ—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç–∞

```
–ú–∞—î–º–æ 3D –æ–±'—î–∫—Ç, —Ö–æ—á–µ–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ –≤ 2D (—Ñ–æ—Ç–æ)

–í–∞—Ä—ñ–∞–Ω—Ç 1: –ó–≤–µ—Ä—Ö—É
     ‚óè‚îÄ‚îÄ‚îÄ‚óè
     ‚îÇ   ‚îÇ
     ‚óè‚îÄ‚îÄ‚îÄ‚óè
–ü–æ–≥–∞–Ω–æ ‚Äî –Ω–µ –≤–∏–¥–Ω–æ –≤–∏—Å–æ—Ç–∏

–í–∞—Ä—ñ–∞–Ω—Ç 2: –ó–±–æ–∫—É
     ‚óè
    ‚ï±‚îÇ‚ï≤
   ‚óè ‚óè ‚óè
–ü–æ–≥–∞–Ω–æ ‚Äî –Ω–µ –≤–∏–¥–Ω–æ —à–∏—Ä–∏–Ω–∏

–í–∞—Ä—ñ–∞–Ω—Ç 3: –ü—ñ–¥ –∫—É—Ç–æ–º (PCA!)
      ‚óè‚îÄ‚îÄ‚óè
     ‚ï±  ‚ï±
    ‚óè‚îÄ‚îÄ‚óè
–î–æ–±—Ä–µ ‚Äî –≤–∏–¥–Ω–æ –º–∞–∫—Å–∏–º—É–º –¥–µ—Ç–∞–ª–µ–π ‚úì

PCA –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –ù–ê–ô–ö–†–ê–©–ò–ô –∫—É—Ç –¥–ª—è –ø—Ä–æ–µ–∫—Ü—ñ—ó!
```

---

## –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ (–ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏)

### –ó–∞–¥–∞—á–∞ PCA

**–ú–µ—Ç–∞:** –ó–Ω–∞–π—Ç–∏ –Ω–∞–ø—Ä—è–º–æ–∫ (–≤–µ–∫—Ç–æ—Ä), –Ω–∞ —è–∫–∏–π –ø—Ä–æ–µ–∫—Ü—ñ—è –¥–∞–Ω–∏—Ö –º–∞—î **–º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –¥–∏—Å–ø–µ—Ä—Å—ñ—é** (variance).

```
–î–∏—Å–ø–µ—Ä—Å—ñ—è (variance) = —è–∫ —Å–∏–ª—å–Ω–æ —Ä–æ–∑–∫–∏–¥–∞–Ω—ñ –¥–∞–Ω—ñ

–ë—ñ–ª—å—à–µ variance = –±—ñ–ª—å—à–µ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
–ú–µ–Ω—à–µ variance = –º–µ–Ω—à–µ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó (—à—É–º)
```

**–í—ñ–∑—É–∞–ª—å–Ω–æ:**

```
–î–∞–Ω—ñ:
    ‚óè
  ‚óè ‚óè ‚óè
‚óè ‚óè ‚óè ‚óè
  ‚óè ‚óè
    ‚óè

–ù–∞–ø—Ä—è–º–æ–∫ 1 (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å):
‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚óè
Variance: —Å–µ—Ä–µ–¥–Ω—è

–ù–∞–ø—Ä—è–º–æ–∫ 2 (–≤–µ—Ä—Ç–∏–∫–∞–ª—å):
‚îÇ ‚óè ‚óè
‚îÇ ‚óè
‚îÇ ‚óè
‚îÇ ‚óè ‚óè
Variance: –º–∞–ª–∞

–ù–∞–ø—Ä—è–º–æ–∫ 3 (–¥—ñ–∞–≥–æ–Ω–∞–ª—å, PC1):
    ‚óè
   ‚óè
  ‚óè
 ‚óè
‚óè
Variance: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê ‚úì

PCA –æ–±–∏—Ä–∞—î –Ω–∞–ø—Ä—è–º–æ–∫ 3!
```

---

### –ö—Ä–æ–∫–∏ PCA (–±–µ–∑ —Ñ–æ—Ä–º—É–ª)

**1. –¶–µ–Ω—Ç—Ä—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ**

```
–í—ñ–¥–Ω—ñ–º–∞—î–º–æ —Å–µ—Ä–µ–¥–Ω—î –ø–æ –∫–æ–∂–Ω—ñ–π –æ–∑–Ω–∞—Ü—ñ

–ë—É–ª–æ:
x‚ÇÅ = [3, 7]
x‚ÇÇ = [5, 9]
x‚ÇÉ = [7, 11]

–°–µ—Ä–µ–¥–Ω—î: Œº = [5, 9]

–¶–µ–Ω—Ç—Ä–æ–≤–∞–Ω—ñ:
x‚ÇÅ' = [3-5, 7-9] = [-2, -2]
x‚ÇÇ' = [5-5, 9-9] = [0, 0]
x‚ÇÉ' = [7-5, 11-9] = [2, 2]

–¢–µ–ø–µ—Ä —Ü–µ–Ω—Ç—Ä –¥–∞–Ω–∏—Ö –≤ (0, 0)
```

---

**2. –ó–Ω–∞–π—Ç–∏ –Ω–∞–ø—Ä—è–º–∫–∏ –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –¥–∏—Å–ø–µ—Ä—Å—ñ—î—é**

```
–¶–µ –≤–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–æ—ó –º–∞—Ç—Ä–∏—Ü—ñ
(–Ω–µ —Ö–≤–∏–ª—é–π—Å—è –ø—Ä–æ –¥–µ—Ç–∞–ª—ñ ‚Äî sklearn –∑—Ä–æ–±–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ)

–†–µ–∑—É–ª—å—Ç–∞—Ç:
PC1 = [0.707, 0.707]  ‚Üê –Ω–∞–ø—Ä—è–º–æ–∫ –∑ MAX variance
PC2 = [-0.707, 0.707] ‚Üê –ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–∏–π –¥–æ PC1
```

---

**3. –ü—Ä–æ—î–∫—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –Ω–∞ –Ω–æ–≤—ñ –æ—Å—ñ**

```
–°—Ç–∞—Ä—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ (x, y):
x‚ÇÅ = [-2, -2]
x‚ÇÇ = [0, 0]
x‚ÇÉ = [2, 2]

–ù–æ–≤—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ (PC1, PC2):
–ü—Ä–æ–µ–∫—Ü—ñ—è –Ω–∞ PC1 = x ¬∑ PC1

x‚ÇÅ: PC1 = [-2, -2] ¬∑ [0.707, 0.707] = -2.83
x‚ÇÇ: PC1 = [0, 0] ¬∑ [0.707, 0.707] = 0
x‚ÇÉ: PC1 = [2, 2] ¬∑ [0.707, 0.707] = 2.83

–¢–µ–ø–µ—Ä –¥–∞–Ω—ñ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç!
```

---

**4. –í–∏–±—Ä–∞—Ç–∏ K –∫–æ–º–ø–æ–Ω–µ–Ω—Ç**

```
–Ø–∫—â–æ PC2 –º–∞—î –º–∞–ª–æ variance ‚Üí –≤—ñ–¥–∫–∏–Ω—É—Ç–∏!

–ë—É–ª–æ: 2D (x, y)
–°—Ç–∞–ª–æ: 1D (PC1)

–ó–º–µ–Ω—à–∏–ª–∏ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: 2D ‚Üí 1D ‚úì
```

---

## PCA –ø–æ–∫—Ä–æ–∫–æ–≤–æ (—Ñ–æ—Ä–º–∞–ª—å–Ω–æ, –∞–ª–µ –ø—Ä–æ—Å—Ç–æ)

### –í—Ö—ñ–¥

- –î–∞–Ω—ñ: X ‚Äî –º–∞—Ç—Ä–∏—Ü—è (n_samples, n_features)
- –ë–∞–∂–∞–Ω–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: k (–∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç)

---

### –ö—Ä–æ–∫ 1: –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è

```
Œº = —Å–µ—Ä–µ–¥–Ω—î –ø–æ –∫–æ–∂–Ω—ñ–π –æ–∑–Ω–∞—Ü—ñ

X_centered = X - Œº

–ü—Ä–∏–∫–ª–∞–¥:
X = [[1, 2],
     [3, 4],
     [5, 6]]

Œº = [3, 4]

X_centered = [[-2, -2],
              [0, 0],
              [2, 2]]
```

---

### –ö—Ä–æ–∫ 2: –ö–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è

```
–ö–æ–≤–∞—Ä—ñ–∞—Ü—ñ—è –ø–æ–∫–∞–∑—É—î, —è–∫ –æ–∑–Ω–∞–∫–∏ –∑–º—ñ–Ω—é—é—Ç—å—Å—è —Ä–∞–∑–æ–º

Cov(X) = (1/n) √ó X_centered^T √ó X_centered

–î–ª—è 2D:
Cov = [[var(x‚ÇÅ),    cov(x‚ÇÅ,x‚ÇÇ)],
       [cov(x‚ÇÇ,x‚ÇÅ), var(x‚ÇÇ)]]

–î—ñ–∞–≥–æ–Ω–∞–ª—å = –¥–∏—Å–ø–µ—Ä—Å—ñ—è –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏
–ü–æ–∑–∞ –¥—ñ–∞–≥–æ–Ω–∞–ª–ª—é = –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ—è –º—ñ–∂ –æ–∑–Ω–∞–∫–∞–º–∏
```

---

### –ö—Ä–æ–∫ 3: –í–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ —Ç–∞ –∑–Ω–∞—á–µ–Ω–Ω—è

```
–†–æ–∑–≤'—è–∑—É—î–º–æ: Cov √ó v = Œª √ó v

v ‚Äî –≤–ª–∞—Å–Ω–∏–π –≤–µ–∫—Ç–æ—Ä (eigenvector)
Œª ‚Äî –≤–ª–∞—Å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è (eigenvalue)

–í–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ = –Ω–∞–ø—Ä—è–º–∫–∏ –≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
–í–ª–∞—Å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è = –≤–µ–ª–∏—á–∏–Ω–∞ variance –≤ —Ü—å–æ–º—É –Ω–∞–ø—Ä—è–º–∫—É
```

**–Ü–Ω—Ç—É—ó—Ü—ñ—è:**

```
–£—è–≤–∏ –µ–ª—ñ–ø—Å (—Ä–æ–∑–ø–æ–¥—ñ–ª –¥–∞–Ω–∏—Ö):

       Œª‚ÇÅ (–≤–µ–ª–∏–∫–µ)
    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
  ‚Üë ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
  ‚îÇ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
Œª‚ÇÇ‚îÇ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè  ‚Üê –µ–ª—ñ–ø—Å —Ä–æ–∑—Ç—è–≥–Ω—É—Ç–∏–π –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
  ‚îÇ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
  ‚Üì ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
    
v‚ÇÅ ‚Äî –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∏–π –Ω–∞–ø—Ä—è–º–æ–∫ (PC1)
v‚ÇÇ ‚Äî –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∏–π –Ω–∞–ø—Ä—è–º–æ–∫ (PC2)

Œª‚ÇÅ > Œª‚ÇÇ ‚Üí PC1 –≤–∞–∂–ª–∏–≤—ñ—à–∏–π
```

---

### –ö—Ä–æ–∫ 4: –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è

```
–°–æ—Ä—Ç—É—î–º–æ –≤–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ –∑–∞ –∑–º–µ–Ω—à–µ–Ω–Ω—è–º –≤–ª–∞—Å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å

Œª‚ÇÅ > Œª‚ÇÇ > Œª‚ÇÉ > ... > Œª‚Çô

PC1 (–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π) ‚Üê Œª‚ÇÅ
PC2                  ‚Üê Œª‚ÇÇ
PC3                  ‚Üê Œª‚ÇÉ
...
```

---

### –ö—Ä–æ–∫ 5: –í–∏–±—ñ—Ä K –∫–æ–º–ø–æ–Ω–µ–Ω—Ç

```
–í–∏–±–∏—Ä–∞—î–º–æ –ø–µ—Ä—à—ñ k –≤–ª–∞—Å–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤

W = [v‚ÇÅ, v‚ÇÇ, ..., v‚Çñ]  (–º–∞—Ç—Ä–∏—Ü—è –ø—Ä–æ–µ–∫—Ü—ñ—ó)
```

---

### –ö—Ä–æ–∫ 6: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è

```
X_pca = X_centered √ó W

–ù–æ–≤—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –≤ –ø—Ä–æ—Å—Ç–æ—Ä—ñ –≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
```

---

## –ü—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥ (–≤—Ä—É—á–Ω—É)

**–î–∞–Ω—ñ:** 3 —Ç–æ—á–∫–∏ –≤ 2D

```
x‚ÇÅ = [2, 3]
x‚ÇÇ = [3, 4]
x‚ÇÉ = [4, 5]

–í—ñ–∑—É–∞–ª—å–Ω–æ:
  5‚îÇ      ‚óè x‚ÇÉ
  4‚îÇ    ‚óè x‚ÇÇ
  3‚îÇ  ‚óè x‚ÇÅ
  2‚îÇ
  1‚îÇ
  0‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    1 2 3 4 5
```

–¢–æ—á–∫–∏ –ª–µ–∂–∞—Ç—å –Ω–∞ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ y = x + 1.

---

### –ö—Ä–æ–∫ 1: –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è

```
–°–µ—Ä–µ–¥–Ω—î:
Œº = (x‚ÇÅ + x‚ÇÇ + x‚ÇÉ) / 3
  = ([2,3] + [3,4] + [4,5]) / 3
  = [9, 12] / 3
  = [3, 4]

–¶–µ–Ω—Ç—Ä–æ–≤–∞–Ω—ñ:
x‚ÇÅ' = [2-3, 3-4] = [-1, -1]
x‚ÇÇ' = [3-3, 4-4] = [0, 0]
x‚ÇÉ' = [4-3, 5-4] = [1, 1]

X_centered = [[-1, -1],
              [0, 0],
              [1, 1]]
```

---

### –ö—Ä–æ–∫ 2: –ö–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è

```
Cov(X) = (1/3) √ó X_centered^T √ó X_centered

X_centered^T = [[-1, 0, 1],
                [-1, 0, 1]]

X_centered^T √ó X_centered = [[-1, 0, 1],   √ó [[-1, -1],
                              [-1, 0, 1]]     [0, 0],
                                              [1, 1]]

= [[(-1)√ó(-1) + 0√ó0 + 1√ó1,  (-1)√ó(-1) + 0√ó0 + 1√ó1],
   [(-1)√ó(-1) + 0√ó0 + 1√ó1,  (-1)√ó(-1) + 0√ó0 + 1√ó1]]

= [[2, 2],
   [2, 2]]

Cov = (1/3) √ó [[2, 2],
               [2, 2]]
    = [[0.67, 0.67],
       [0.67, 0.67]]
```

---

### –ö—Ä–æ–∫ 3: –í–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ —Ç–∞ –∑–Ω–∞—á–µ–Ω–Ω—è

```
–†–æ–∑–≤'—è–∑—É—î–º–æ: Cov √ó v = Œª √ó v

–î–ª—è —Ü—ñ—î—ó –º–∞—Ç—Ä–∏—Ü—ñ (—Å–ø—Ä–æ—â–µ–Ω–æ):

Œª‚ÇÅ = 1.33  (–≤–µ–ª–∏–∫–µ –≤–ª–∞—Å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è)
v‚ÇÅ = [0.707, 0.707]  ‚âà [1/‚àö2, 1/‚àö2]  (–Ω–∞–ø—Ä—è–º–æ–∫ –ø–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ)

Œª‚ÇÇ = 0  (–º–∞–ª–µ –≤–ª–∞—Å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è)
v‚ÇÇ = [-0.707, 0.707]  ‚âà [-1/‚àö2, 1/‚àö2]  (–ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–∏–π)
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**

```
v‚ÇÅ = [0.707, 0.707] ‚Üí –Ω–∞–ø—Ä—è–º–æ–∫ ‚Üó (45¬∞)
  –¶–µ PC1 ‚Äî –≥–æ–ª–æ–≤–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
  Œª‚ÇÅ = 1.33 ‚Äî –≤–µ–ª–∏–∫–∞ variance

v‚ÇÇ = [-0.707, 0.707] ‚Üí –Ω–∞–ø—Ä—è–º–æ–∫ ‚Üñ
  –¶–µ PC2
  Œª‚ÇÇ = 0 ‚Äî –ù–£–õ–¨–û–í–ê variance (–≤—Å—ñ —Ç–æ—á–∫–∏ –Ω–∞ –æ–¥–Ω—ñ–π –ª—ñ–Ω—ñ—ó!)
```

---

### –ö—Ä–æ–∫ 4: –ü—Ä–æ–µ–∫—Ü—ñ—è –Ω–∞ PC1

```
X_pca = X_centered √ó v‚ÇÅ

x‚ÇÅ' √ó v‚ÇÅ = [-1, -1] ¬∑ [0.707, 0.707]
         = -1√ó0.707 + (-1)√ó0.707
         = -1.414

x‚ÇÇ' √ó v‚ÇÅ = [0, 0] ¬∑ [0.707, 0.707]
         = 0

x‚ÇÉ' √ó v‚ÇÅ = [1, 1] ¬∑ [0.707, 0.707]
         = 1.414

X_pca = [[-1.414],
         [0],
         [1.414]]
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**

```
–ë—É–ª–æ: 2D
x‚ÇÅ = [2, 3]
x‚ÇÇ = [3, 4]
x‚ÇÉ = [4, 5]

–°—Ç–∞–ª–æ: 1D (—Ç—ñ–ª—å–∫–∏ PC1)
x‚ÇÅ ‚Üí -1.414
x‚ÇÇ ‚Üí 0
x‚ÇÉ ‚Üí 1.414

–ó–º–µ–Ω—à–∏–ª–∏ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: 2D ‚Üí 1D ‚úì
```

---

## Explained Variance (–ø–æ—è—Å–Ω–µ–Ω–∞ –¥–∏—Å–ø–µ—Ä—Å—ñ—è)

**–©–æ —Ü–µ:** –°–∫—ñ–ª—å–∫–∏ –≤—ñ–¥—Å–æ—Ç–∫—ñ–≤ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑–±–µ—Ä—ñ–≥–∞—î –∫–æ–∂–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞.

```
–§–æ—Ä–º—É–ª–∞:
Explained Variance (PC_k) = Œª‚Çñ / (Œª‚ÇÅ + Œª‚ÇÇ + ... + Œª‚Çô)

–ü—Ä–∏–∫–ª–∞–¥:
Œª‚ÇÅ = 50
Œª‚ÇÇ = 30
Œª‚ÇÉ = 15
Œª‚ÇÑ = 5

–°—É–º–∞ = 50 + 30 + 15 + 5 = 100

PC1: 50/100 = 50%
PC2: 30/100 = 30%
PC3: 15/100 = 15%
PC4: 5/100 = 5%
```

**Cumulative (–∫—É–º—É–ª—è—Ç–∏–≤–Ω–∞):**

```
PC1: 50%
PC1+PC2: 50% + 30% = 80%
PC1+PC2+PC3: 80% + 15% = 95%  ‚Üê –∑–∞–∑–≤–∏—á–∞–π –¥–æ—Å—Ç–∞—Ç–Ω—å–æ!
PC1+PC2+PC3+PC4: 100%
```

**–Ø–∫ –≤–∏–±—Ä–∞—Ç–∏ K –∫–æ–º–ø–æ–Ω–µ–Ω—Ç:**

```
–í–∞—Ä—ñ–∞–Ω—Ç 1: –ó–∞–¥–∞—Ç–∏ –ø–æ—Ä—ñ–≥ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 95%)
  ‚Üí –í–∏–±—Ä–∞—Ç–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–µ K, —â–æ–± cumulative ‚â• 95%

–í–∞—Ä—ñ–∞–Ω—Ç 2: Elbow method
  ‚Üí –ì—Ä–∞—Ñ—ñ–∫ explained variance vs K
  ‚Üí –®—É–∫–∞—Ç–∏ "–ª—ñ–∫–æ—Ç—å"

–í–∞—Ä—ñ–∞–Ω—Ç 3: –ó–∞–¥–∞—Ç–∏ K –Ω–∞–ø–µ—Ä–µ–¥
  ‚Üí –ù–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó K=2
```

---

## –í–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ PCA

### 1. –ì–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ñ

```
PC1 ‚ä• PC2 ‚ä• PC3 ‚ä• ...

–í–æ–Ω–∏ –Ω–µ –∫–æ—Ä–µ–ª—é—é—Ç—å –º—ñ–∂ —Å–æ–±–æ—é
‚Üí –ù–µ–º–∞—î –Ω–∞–¥–º—ñ—Ä–Ω–æ—Å—Ç—ñ (redundancy)
```

---

### 2. –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ

```
PC1 ‚Äî –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π (max variance)
PC2 ‚Äî –¥—Ä—É–≥–∏–π –∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é
PC3 ‚Äî —Ç—Ä–µ—Ç—ñ–π
...
PC‚Çô ‚Äî –Ω–∞–π–º–µ–Ω—à –≤–∞–∂–ª–∏–≤–∏–π
```

---

### 3. –õ—ñ–Ω—ñ–π–Ω–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è

```
PCA ‚Äî —Ü–µ –ª—ñ–Ω—ñ–π–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è

X_pca = X_centered √ó W

–ù–µ –º–æ–∂–µ –∑–Ω–∞–π—Ç–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
‚Üí –î–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä: Kernel PCA, t-SNE, UMAP
```

---

### 4. –ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –º–∞—Å—à—Ç–∞–±—É

```
–ü–û–ì–ê–ù–û:
Feature 1: [0.1, 0.2, 0.3]  (–º–∞–ª—ñ –∑–Ω–∞—á–µ–Ω–Ω—è)
Feature 2: [1000, 2000, 3000]  (–≤–µ–ª–∏–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è)

‚Üí PCA –±—É–¥–µ –¥–æ–º—ñ–Ω—É–≤–∞—Ç–∏ Feature 2 (–±—ñ–ª—å—à–∞ variance)

–î–û–ë–†–ï:
–ú–∞—Å—à—Ç–∞–±—É–≤–∞—Ç–∏ –ø–µ—Ä–µ–¥ PCA!

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

### 5. –í—Ç—Ä–∞—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–æ—Å—Ç—ñ

```
–ë—É–ª–æ:
Feature 1 = "–í—ñ–∫"
Feature 2 = "–î–æ—Ö—ñ–¥"
Feature 3 = "–û—Å–≤—ñ—Ç–∞"

–°—Ç–∞–ª–æ:
PC1 = 0.5√ó–í—ñ–∫ + 0.7√ó–î–æ—Ö—ñ–¥ + 0.4√ó–û—Å–≤—ñ—Ç–∞
PC2 = -0.3√ó–í—ñ–∫ + 0.2√ó–î–æ—Ö—ñ–¥ + 0.9√ó–û—Å–≤—ñ—Ç–∞
PC3 = ...

–©–æ –æ–∑–Ω–∞—á–∞—î PC1? ü§î
‚Üí "–°–æ—Ü—ñ–æ-–µ–∫–æ–Ω–æ–º—ñ—á–Ω–∏–π —Å—Ç–∞—Ç—É—Å"? (–≤–∞–∂–∫–æ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏)
```

---

## –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ PCA

### ‚úÖ –Ü–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å

1. **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏—Å–æ–∫–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö**
   - 1000D ‚Üí 2D –¥–ª—è scatter plot
   
2. **–ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è ML –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤**
   - –ú–µ–Ω—à–µ –æ–∑–Ω–∞–∫ ‚Üí —à–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è
   
3. **–£—Å—É–Ω–µ–Ω–Ω—è –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω–æ—Å—Ç—ñ**
   - –ö–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏ ‚Üí –Ω–µ–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ PC
   
4. **–®—É–º–æ–æ—á–∏—â–µ–Ω–Ω—è**
   - –í—ñ–¥–∫–∏–Ω—É—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑ –º–∞–ª–æ—é variance (—à—É–º)
   
5. **–°—Ç–∏—Å–Ω–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö**
   - –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è, –ø–µ—Ä–µ–¥–∞—á–∞
   
6. **Feature extraction**
   - –°—Ç–≤–æ—Ä–∏—Ç–∏ –Ω–æ–≤—ñ –æ–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–¥ ML

**–ü—Ä–∏–∫–ª–∞–¥–∏:**

- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó
- Preprocessing –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂
- –ê–Ω–∞–ª—ñ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω—å (eigenfaces)
- –ë—ñ–æ—ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ (–∞–Ω–∞–ª—ñ–∑ –≥–µ–Ω—ñ–≤)
- –§—ñ–Ω–∞–Ω—Å–∏ (—Ñ–∞–∫—Ç–æ—Ä–Ω–∏–π –∞–Ω–∞–ª—ñ–∑)

---

### ‚ùå –ö—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à–µ

1. **Feature selection** (–≤–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–∏—Ö –æ–∑–Ω–∞–∫)
   - PCA —Å—Ç–≤–æ—Ä—é—î –ù–û–í–Ü –æ–∑–Ω–∞–∫–∏, –∞ –Ω–µ –≤–∏–±–∏—Ä–∞—î —ñ—Å–Ω—É—é—á—ñ
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: SelectKBest, RFE, feature importance
   
2. **–ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏**
   - PCA —Ç—ñ–ª—å–∫–∏ –ª—ñ–Ω—ñ–π–Ω–∏–π
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Kernel PCA, t-SNE, UMAP
   
3. **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞**
   - PC –≤–∞–∂–∫–æ –ø–æ—è—Å–Ω–∏—Ç–∏
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∑–±–µ—Ä–µ–≥—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏
   
4. **Supervised learning –∑ –º–∞–ª–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –¥–∞–Ω–∏—Ö**
   - PCA unsupervised, —ñ–≥–Ω–æ—Ä—É—î target
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: LDA (Linear Discriminant Analysis)

---

## –ü–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –Ω–µ–¥–æ–ª—ñ–∫–∏ PCA

### ‚úÖ –ü–µ—Ä–µ–≤–∞–≥–∏

|–ü–µ—Ä–µ–≤–∞–≥–∞|–ü–æ—è—Å–Ω–µ–Ω–Ω—è|
|---|---|
|**–ó–º–µ–Ω—à—É—î —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å**|100 –æ–∑–Ω–∞–∫ ‚Üí 10 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç|
|**–£—Å—É–≤–∞—î –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω—ñ—Å—Ç—å**|PC –Ω–µ–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ|
|**–®—É–º–æ–æ—á–∏—â–µ–Ω–Ω—è**|–í—ñ–¥–∫–∏–¥–∞—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑ –º–∞–ª–æ—é variance|
|**–®–≤–∏–¥–∫—ñ—Å—Ç—å**|–ú–µ–Ω—à–µ –æ–∑–Ω–∞–∫ ‚Üí —à–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è|
|**–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è**|–ë—É–¥—å-—è–∫–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å ‚Üí 2D/3D|
|**–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ –æ–±“ë—Ä—É–Ω—Ç–æ–≤–∞–Ω–æ**|–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –ª—ñ–Ω—ñ–π–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è|
|**–î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ**|–ó–∞–≤–∂–¥–∏ –æ–¥–Ω–∞–∫–æ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç|

---

### ‚ùå –ù–µ–¥–æ–ª—ñ–∫–∏

|–ù–µ–¥–æ–ª—ñ–∫|–ü–æ—è—Å–Ω–µ–Ω–Ω—è|
|---|---|
|**–í—Ç—Ä–∞—Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–æ—Å—Ç—ñ**|PC –≤–∞–∂–∫–æ –ø–æ—è—Å–Ω–∏—Ç–∏ –±—ñ–∑–Ω–µ—Å—É|
|**–¢—ñ–ª—å–∫–∏ –ª—ñ–Ω—ñ–π–Ω–∏–π**|–ù–µ –ø—Ä–∞—Ü—é—î –Ω–∞ —Å–∫–ª–∞–¥–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö|
|**–ß—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ –º–∞—Å—à—Ç–∞–±—É**|–ü–æ—Ç—Ä—ñ–±–Ω–µ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è|
|**Unsupervised**|–Ü–≥–Ω–æ—Ä—É—î target variable|
|**–ú–æ–∂–µ –≤—Ç—Ä–∞—Ç–∏—Ç–∏ –≤–∞–∂–ª–∏–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é**|–í—ñ–¥–∫–∏–¥–∞—î–º–æ "–º–∞–ª—ñ" –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏|
|**–ù–µ –≥–∞—Ä–∞–Ω—Ç—É—î –∫—Ä–∞—â—É —Ç–æ—á–Ω—ñ—Å—Ç—å**|ML –º–æ–∂–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –≥—ñ—Ä—à–µ –ø—ñ—Å–ª—è PCA|

---

## PCA vs —ñ–Ω—à—ñ –º–µ—Ç–æ–¥–∏

### PCA vs Feature Selection

```
PCA (Feature Extraction):
  –°—Ç–≤–æ—Ä—é—î –ù–û–í–Ü –æ–∑–Ω–∞–∫–∏ (–∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Å—Ç–∞—Ä–∏—Ö)
  PC1 = 0.5√óAge + 0.3√óIncome + ...
  ‚úì –ó–±–µ—Ä—ñ–≥–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
  ‚úó –í–∞–∂–∫–æ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏

Feature Selection:
  –í–ò–ë–ò–†–ê–Ñ —ñ—Å–Ω—É—é—á—ñ –æ–∑–Ω–∞–∫–∏
  –ó–∞–ª–∏—à–∞—î: Age, Income (–≤—ñ–¥–∫–∏–¥–∞—î —ñ–Ω—à—ñ)
  ‚úì –õ–µ–≥–∫–æ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏
  ‚úó –ú–æ–∂–µ –≤—Ç—Ä–∞—Ç–∏—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
```

---

### PCA vs t-SNE / UMAP

```
PCA:
  –õ—ñ–Ω—ñ–π–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è
  –ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–æ–±–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
  –®–≤–∏–¥–∫–æ
  –î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ
  ‚úì –î–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–¥ ML

t-SNE / UMAP:
  –ù–µ–ª—ñ–Ω—ñ–π–Ω–∞ –ø—Ä–æ–µ–∫—Ü—ñ—è
  –ó–±–µ—Ä—ñ–≥–∞—î –ª–æ–∫–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
  –ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ
  –°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ
  ‚úì –î–ª—è –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–á (–Ω–µ –¥–ª—è ML!)
```

---

### PCA vs LDA

```
PCA (unsupervised):
  –ú–∞–∫—Å–∏–º—ñ–∑—É—î variance
  –Ü–≥–Ω–æ—Ä—É—î target
  –ó–∞–≥–∞–ª—å–Ω–µ –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ

LDA (supervised):
  –ú–∞–∫—Å–∏–º—ñ–∑—É—î —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∫–ª–∞—Å—ñ–≤
  –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î target
  –î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
```

---

## –í–∞—Ä—ñ–∞—Ü—ñ—ó PCA

### 1. Kernel PCA

**–Ü–¥–µ—è:** PCA –≤ –ø—Ä–æ—Å—Ç–æ—Ä—ñ –≤–∏—â–æ—ó —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ (kernel trick)

```
–ú–æ–∂–µ –∑–Ω–∞–π—Ç–∏ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏

Kernels:
- RBF (Gaussian)
- Polynomial
- Sigmoid
```

---

### 2. Sparse PCA

**–Ü–¥–µ—è:** –ì–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑ –±–∞–≥–∞—Ç—å–º–∞ –Ω—É–ª—è–º–∏

```
PC1 = 0.8√óFeature1 + 0.6√óFeature2 + 0√ó... + 0√ó...
      ‚Üë —Ç—ñ–ª—å–∫–∏ –∫—ñ–ª—å–∫–∞ –Ω–µ–Ω—É–ª—å–æ–≤–∏—Ö

‚úì –õ–µ–≥—à–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏
‚úó –ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ
```

---

### 3. Incremental PCA

**–Ü–¥–µ—è:** PCA –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö (–Ω–µ –≤–ª–∞–∑—è—Ç—å —É –ø–∞–º'—è—Ç—å)

```
–û–±—Ä–æ–±–ª—è—î–º–æ –¥–∞–Ω—ñ –±–∞—Ç—á–∞–º–∏

from sklearn.decomposition import IncrementalPCA
```

---

### 4. Randomized PCA

**–Ü–¥–µ—è:** –®–≤–∏–¥–∫–∞ –∞–ø—Ä–æ–∫—Å–∏–º–∞—Ü—ñ—è PCA

```
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≤–∏–ø–∞–¥–∫–æ–≤—É –ø—Ä–æ–µ–∫—Ü—ñ—é

–®–≤–∏–¥—à–µ –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –º–∞—Ç—Ä–∏—Ü—å
```

---

## –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏

### 1. –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π –¥–∞–Ω—ñ –ø–µ—Ä–µ–¥ PCA

```python
from sklearn.preprocessing import StandardScaler

# –ü–û–ì–ê–ù–û
pca = PCA(n_components=2)
pca.fit(X)

# –î–û–ë–†–ï
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=2)
pca.fit(X_scaled)
```

---

### 2. –ü–µ—Ä–µ–≤—ñ—Ä—è–π explained variance

```python
pca = PCA()
pca.fit(X_scaled)

print(pca.explained_variance_ratio_)
# [0.50, 0.30, 0.15, 0.05]
# PC1 ‚Üí 50%, PC2 ‚Üí 30%, ...

cumsum = np.cumsum(pca.explained_variance_ratio_)
print(cumsum)
# [0.50, 0.80, 0.95, 1.00]
# –ü–µ—Ä—à—ñ 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ ‚Üí 95% —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
```

---

### 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π elbow method

```python
pca = PCA()
pca.fit(X_scaled)

plt.plot(range(1, len(pca.explained_variance_ratio_)+1),
         pca.explained_variance_ratio_, 'o-')
plt.xlabel('Component')
plt.ylabel('Explained Variance')
plt.title('Scree Plot')
plt.show()

# –®—É–∫–∞–π "–ª—ñ–∫–æ—Ç—å"
```

---

### 4. PCA –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó vs ML

```python
# –î–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó: –∑–∞–≤–∂–¥–∏ 2-3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
pca_viz = PCA(n_components=2)
X_viz = pca_viz.fit_transform(X_scaled)
plt.scatter(X_viz[:, 0], X_viz[:, 1])

# –î–ª—è ML: –≤–∏–±–∏—Ä–∞–π –∑–∞ explained variance
pca_ml = PCA(n_components=0.95)  # 95% variance
X_ml = pca_ml.fit_transform(X_scaled)
print(f"–û–±—Ä–∞–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç: {pca_ml.n_components_}")
```

---

### 5. –ü–µ—Ä–µ–≤—ñ—Ä—è–π, —á–∏ –ø–æ–∫—Ä–∞—â–∏–ª–æ—Å—è

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# –ë–µ–∑ PCA
score_before = cross_val_score(LogisticRegression(), X, y, cv=5).mean()

# –ó PCA
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X)
score_after = cross_val_score(LogisticRegression(), X_pca, y, cv=5).mean()

print(f"–ë–µ–∑ PCA: {score_before:.3f}")
print(f"–ó PCA: {score_after:.3f}")

# PCA –Ω–µ –∑–∞–≤–∂–¥–∏ –ø–æ–∫—Ä–∞—â—É—î —Ç–æ—á–Ω—ñ—Å—Ç—å!
```

---

## –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

> PCA –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ñ –Ω–∞–ø—Ä—è–º–∫–∏ –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –¥–∏—Å–ø–µ—Ä—Å—ñ—î—é –≤ –¥–∞–Ω–∏—Ö —ñ –ø—Ä–æ—î–∫—Ç—É—î –¥–∞–Ω—ñ –Ω–∞ —Ü—ñ –Ω–∞–ø—Ä—è–º–∫–∏ –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ.

**–û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–∏–Ω—Ü–∏–ø–∏:**

- **–í–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏** –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–æ—ó –º–∞—Ç—Ä–∏—Ü—ñ = –≥–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
- **–í–ª–∞—Å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è** = –≤–µ–ª–∏—á–∏–Ω–∞ variance –≤ –∫–æ–∂–Ω—ñ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ
- **Explained variance** = —Å–∫—ñ–ª—å–∫–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑–±–µ—Ä—ñ–≥–∞—î –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
- PC1 > PC2 > PC3 > ... (–∑–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é)
- –ì–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ **–Ω–µ–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ** (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ñ)

**–§–æ—Ä–º—É–ª–∞:**
```
1. X_centered = X - mean(X)
2. Cov = (1/n) √ó X_centered^T √ó X_centered
3. –ó–Ω–∞–π—Ç–∏ –≤–ª–∞—Å–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏/–∑–Ω–∞—á–µ–Ω–Ω—è: Cov √ó v = Œª √ó v
4. X_pca = X_centered √ó [v‚ÇÅ, v‚ÇÇ, ..., v‚Çñ]
```

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏—Å–æ–∫–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö ‚úì
- –ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è ML –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ ‚úì
- –£—Å—É–Ω–µ–Ω–Ω—è –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω–æ—Å—Ç—ñ ‚úì
- –®—É–º–æ–æ—á–∏—â–µ–Ω–Ω—è ‚úì

**–ö–æ–ª–∏ –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- Feature selection (–≤–∏–±—ñ—Ä –æ–∑–Ω–∞–∫) ‚Üí SelectKBest
- –ù–µ–ª—ñ–Ω—ñ–π–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ ‚Üí t-SNE, UMAP
- –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞ ‚Üí –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏
- Supervised task ‚Üí LDA

**–í–∞–∂–ª–∏–≤–æ:**
1. –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π –¥–∞–Ω—ñ (StandardScaler) ‚ö†Ô∏è
2. –ü–µ—Ä–µ–≤—ñ—Ä—è–π explained variance
3. PCA –Ω–µ –∑–∞–≤–∂–¥–∏ –ø–æ–∫—Ä–∞—â—É—î ML —Ç–æ—á–Ω—ñ—Å—Ç—å

---

## –ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏

1. **t-SNE** ‚Äî –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è (–∫—Ä–∞—â–∞ –∑–∞ PCA –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó)
2. **UMAP** ‚Äî —à–≤–∏–¥—à–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ t-SNE
3. **LDA** ‚Äî supervised dimensionality reduction
4. **Autoencoders** ‚Äî –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–µ–≤–∏–π –ø—ñ–¥—Ö—ñ–¥
5. **Feature Selection** ‚Äî –≤–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–∏—Ö –æ–∑–Ω–∞–∫
