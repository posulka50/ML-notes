–ü–æ–≤–Ω–∏–π –ø—Ä–∞–∫—Ç–∏—á–Ω–∏–π –≥–∞–π–¥ –ø–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—é K-Means –≤ scikit-learn –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏ –∫–æ–¥—É.

---

## üì¶ –û—Å–Ω–æ–≤–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# K-Means
from sklearn.cluster import KMeans, MiniBatchKMeans

# –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.metrics import (
    silhouette_score,
    davies_bouldin_score,
    calinski_harabasz_score,
    silhouette_samples
)

# Preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# –î–∞–Ω—ñ
from sklearn.datasets import make_blobs, load_iris
```

---

## 1Ô∏è‚É£ KMeans ‚Äî –æ—Å–Ω–æ–≤–Ω–∏–π –∫–ª–∞—Å

### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
KMeans(
    n_clusters=8,              # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ K
    init='k-means++',          # –ú–µ—Ç–æ–¥ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó: 'k-means++', 'random',                                                                         –∞–±–æ array
    n_init=10,                 # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø—É—Å–∫—ñ–≤ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è–º–∏
    max_iter=300,              # –ú–∞–∫—Å–∏–º—É–º —ñ—Ç–µ—Ä–∞—Ü—ñ–π –Ω–∞ –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫
    tol=1e-4,                  # –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω—ñ—Å—Ç—å –¥–ª—è –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ
    verbose=0,                 # –í–∏–≤–æ–¥–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å (0, 1, 2)
    random_state=None,         # Seed –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ
    copy_x=True,               # –ö–æ–ø—ñ—é–≤–∞—Ç–∏ –¥–∞–Ω—ñ
    algorithm='lloyd'          # 'lloyd', 'elkan' (—à–≤–∏–¥—à–∏–π –¥–ª—è –±–∞–≥–∞—Ç—å–æ—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤)
)
```

### –ê—Ç—Ä–∏–±—É—Ç–∏ –ø—ñ—Å–ª—è fit

```python
model = KMeans(n_clusters=3)
model.fit(X)

# –î–æ—Å—Ç—É–ø–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏:
model.cluster_centers_     # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Ü–µ–Ω—Ç—Ä—ñ–≤ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ (K, n_features)
model.labels_              # –ú—ñ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö (n_samples,)
model.inertia_             # –°—É–º–∞ –∫–≤–∞–¥—Ä–∞—Ç—ñ–≤ –≤—ñ–¥—Å—Ç–∞–Ω–µ–π –¥–æ —Ü–µ–Ω—Ç—Ä—ñ–≤
model.n_iter_              # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π –¥–æ –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ
model.n_features_in_       # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
```

### –ú–µ—Ç–æ–¥–∏

```python
# –ù–∞–≤—á–∞–Ω–Ω—è
model.fit(X)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º—ñ—Ç–æ–∫
labels = model.predict(X_new)

# –ù–∞–≤—á–∞–Ω–Ω—è + –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
labels = model.fit_predict(X)

# –í—ñ–¥—Å—Ç–∞–Ω—å –¥–æ —Ü–µ–Ω—Ç—Ä—ñ–≤
distances = model.transform(X)  # shape: (n_samples, n_clusters)

# –û—Ü—ñ–Ω–∫–∞ (negative inertia)
score = model.score(X)  # –ü–æ–≤–µ—Ä—Ç–∞—î -inertia
```

---

## 2Ô∏è‚É£ –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
import numpy as np
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
X, y_true = make_blobs(
    n_samples=300,
    centers=4,
    cluster_std=0.60,
    random_state=0
)

# 2. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(X)

# 3. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
labels = kmeans.labels_
centers = kmeans.cluster_centers_
inertia = kmeans.inertia_

print(f"Inertia: {inertia:.2f}")
print(f"Iterations: {kmeans.n_iter_}")

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 6))

# –¢–æ—á–∫–∏ –∑ –∫–æ–ª—å–æ—Ä–∞–º–∏ –∑–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6, s=50)

# –¶–µ–Ω—Ç—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
plt.scatter(centers[:, 0], centers[:, 1], 
            c='red', marker='X', s=200, 
            edgecolors='black', linewidths=2,
            label='Centroids')

plt.title('K-Means Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.colorbar(label='Cluster')
plt.show()
```

---

## 3Ô∏è‚É£ –í–∏–±—ñ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ K

### –ú–µ—Ç–æ–¥ 1: Elbow Method

```python
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# –¢–µ—Å—Ç—É—î–º–æ —Ä—ñ–∑–Ω—ñ K
K_range = range(1, 11)
inertias = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 6))
plt.plot(K_range, inertias, 'o-', linewidth=2, markersize=8)
plt.xlabel('Number of clusters (K)')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal K')
plt.grid(True, alpha=0.3)
plt.show()

# –ó–Ω–∞—Ö–æ–¥–∏–º–æ "–ª—ñ–∫–æ—Ç—å" –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ (–ø—Ä–∏–±–ª–∏–∑–Ω–æ)
from kneed import KneeLocator  # pip install kneed

kl = KneeLocator(K_range, inertias, curve='convex', direction='decreasing')
optimal_k = kl.elbow
print(f"Optimal K by Elbow: {optimal_k}")
```

### –ú–µ—Ç–æ–¥ 2: Silhouette Score

```python
from sklearn.metrics import silhouette_score

K_range = range(2, 11)
silhouette_scores = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    silhouette_scores.append(score)
    print(f"K={k}: Silhouette={score:.3f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 6))
plt.plot(K_range, silhouette_scores, 'o-', linewidth=2, markersize=8)
plt.xlabel('Number of clusters (K)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score For Different K')
plt.grid(True, alpha=0.3)
plt.axhline(y=0.5, color='red', linestyle='--', label='Threshold (0.5)')
plt.legend()
plt.show()

# –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π K
optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"Optimal K by Silhouette: {optimal_k}")
```

### –ú–µ—Ç–æ–¥ 3: –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥

```python
from sklearn.metrics import (
    silhouette_score, 
    davies_bouldin_score,
    calinski_harabasz_score
)

def evaluate_kmeans(X, k_range):
    results = []
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(X)
        
        results.append({
            'K': k,
            'Inertia': kmeans.inertia_,
            'Silhouette': silhouette_score(X, labels),
            'Davies-Bouldin': davies_bouldin_score(X, labels),
            'Calinski-Harabasz': calinski_harabasz_score(X, labels)
        })
    
    return pd.DataFrame(results)

# –û—Ü—ñ–Ω–∫–∞
results_df = evaluate_kmeans(X, range(2, 11))
print(results_df)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Inertia (Elbow)
axes[0, 0].plot(results_df['K'], results_df['Inertia'], 'o-')
axes[0, 0].set_title('Elbow Method (Inertia)')
axes[0, 0].set_xlabel('K')
axes[0, 0].set_ylabel('Inertia')
axes[0, 0].grid(True, alpha=0.3)

# Silhouette (–º–∞–∫—Å–∏–º—É–º)
axes[0, 1].plot(results_df['K'], results_df['Silhouette'], 'o-', color='green')
axes[0, 1].set_title('Silhouette Score (max)')
axes[0, 1].set_xlabel('K')
axes[0, 1].set_ylabel('Silhouette')
axes[0, 1].grid(True, alpha=0.3)

# Davies-Bouldin (–º—ñ–Ω—ñ–º—É–º)
axes[1, 0].plot(results_df['K'], results_df['Davies-Bouldin'], 'o-', color='red')
axes[1, 0].set_title('Davies-Bouldin Index (min)')
axes[1, 0].set_xlabel('K')
axes[1, 0].set_ylabel('Davies-Bouldin')
axes[1, 0].grid(True, alpha=0.3)

# Calinski-Harabasz (–º–∞–∫—Å–∏–º—É–º)
axes[1, 1].plot(results_df['K'], results_df['Calinski-Harabasz'], 'o-', color='purple')
axes[1, 1].set_title('Calinski-Harabasz Score (max)')
axes[1, 1].set_xlabel('K')
axes[1, 1].set_ylabel('Calinski-Harabasz')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## 4Ô∏è‚É£ Silhouette Plot

```python
from sklearn.metrics import silhouette_samples
import matplotlib.pyplot as plt
import matplotlib.cm as cm

def plot_silhouette(X, n_clusters):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è Silhouette Plot –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó"""
    
    # K-Means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(X)
    
    # Silhouette scores
    silhouette_avg = silhouette_score(X, cluster_labels)
    sample_silhouette_values = silhouette_samples(X, cluster_labels)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    fig, ax = plt.subplots(figsize=(10, 7))
    
    y_lower = 10
    for i in range(n_clusters):
        # Silhouette scores –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ i
        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
        ith_cluster_silhouette_values.sort()
        
        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i
        
        color = cm.nipy_spectral(float(i) / n_clusters)
        ax.fill_betweenx(
            np.arange(y_lower, y_upper),
            0,
            ith_cluster_silhouette_values,
            facecolor=color,
            edgecolor=color,
            alpha=0.7
        )
        
        # Label –∫–ª–∞—Å—Ç–µ—Ä–∞
        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        
        y_lower = y_upper + 10
    
    ax.set_title(f'Silhouette Plot for K={n_clusters}')
    ax.set_xlabel('Silhouette Coefficient')
    ax.set_ylabel('Cluster')
    
    # –°–µ—Ä–µ–¥–Ω—è –ª—ñ–Ω—ñ—è
    ax.axvline(x=silhouette_avg, color="red", linestyle="--", 
               label=f'Average: {silhouette_avg:.3f}')
    
    ax.set_yticks([])
    ax.set_xlim([-0.1, 1])
    ax.legend()
    plt.show()

# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
plot_silhouette(X, n_clusters=4)
```

---

## 5Ô∏è‚É£ Preprocessing ‚Äî –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è

```python
from sklearn.preprocessing import StandardScaler

# K-Means —á—É—Ç–ª–∏–≤–∏–π –¥–æ –º–∞—Å—à—Ç–∞–±—É –æ–∑–Ω–∞–∫!
# –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π –¥–∞–Ω—ñ –ø–µ—Ä–µ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—î—é

# –ë–µ–∑ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
kmeans_no_scale = KMeans(n_clusters=3, random_state=42)
labels_no_scale = kmeans_no_scale.fit_predict(X)

# –ó –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è–º
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans_scaled = KMeans(n_clusters=3, random_state=42)
labels_scaled = kmeans_scaled.fit_predict(X_scaled)

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
from sklearn.metrics import silhouette_score

print(f"Silhouette –±–µ–∑ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è: {silhouette_score(X, labels_no_scale):.3f}")
print(f"Silhouette –∑ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è–º: {silhouette_score(X_scaled, labels_scaled):.3f}")
```

---

## 6Ô∏è‚É£ MiniBatchKMeans ‚Äî –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö

```python
from sklearn.cluster import MiniBatchKMeans
import time

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤–µ–ª–∏–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É
X_large, _ = make_blobs(n_samples=100000, centers=5, random_state=42)

# KMeans (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π)
start = time.time()
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_large)
time_kmeans = time.time() - start

# MiniBatchKMeans
start = time.time()
mbkmeans = MiniBatchKMeans(
    n_clusters=5,
    batch_size=1000,      # –†–æ–∑–º—ñ—Ä –±–∞—Ç—á—É
    max_iter=100,
    random_state=42
)
mbkmeans.fit(X_large)
time_mbkmeans = time.time() - start

print(f"KMeans:         {time_kmeans:.2f} —Å–µ–∫")
print(f"MiniBatchKMeans: {time_mbkmeans:.2f} —Å–µ–∫")
print(f"–ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è:    {time_kmeans/time_mbkmeans:.1f}x")

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —è–∫–æ—Å—Ç—ñ
from sklearn.metrics import silhouette_score

labels_km = kmeans.predict(X_large)
labels_mbkm = mbkmeans.predict(X_large)

print(f"\nSilhouette KMeans:     {silhouette_score(X_large, labels_km):.3f}")
print(f"Silhouette MiniBatch:  {silhouette_score(X_large, labels_mbkm):.3f}")
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ MiniBatchKMeans

```python
MiniBatchKMeans(
    n_clusters=8,
    init='k-means++',
    max_iter=100,
    batch_size=1024,           # –†–æ–∑–º—ñ—Ä –±–∞—Ç—á—É (–±—ñ–ª—å—à–µ = —Ç–æ—á–Ω—ñ—à–µ, –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ)
    verbose=0,
    compute_labels=True,
    random_state=None,
    tol=0.0,
    max_no_improvement=10,     # –ó—É–ø–∏–Ω–∫–∞, —è–∫—â–æ –Ω–µ–º–∞—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è
    init_size=None,            # –†–æ–∑–º—ñ—Ä –≤–∏–±—ñ—Ä–∫–∏ –¥–ª—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
    n_init=3,                  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ–π
    reassignment_ratio=0.01    # –ü–æ—Ä—ñ–≥ –¥–ª—è –ø–µ—Ä–µ–ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è
)
```

---

## 7Ô∏è‚É£ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

### 2D –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

```python
def visualize_clusters(X, labels, centers=None, title='K-Means Clustering'):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤ –¥–ª—è 2D –¥–∞–Ω–∏—Ö"""
    plt.figure(figsize=(10, 6))
    
    # –ö–ª–∞—Å—Ç–µ—Ä–∏
    scatter = plt.scatter(X[:, 0], X[:, 1], c=labels, 
                         cmap='viridis', alpha=0.6, s=50)
    
    # –¶–µ–Ω—Ç—Ä–∏
    if centers is not None:
        plt.scatter(centers[:, 0], centers[:, 1],
                   c='red', marker='X', s=200,
                   edgecolors='black', linewidths=2,
                   label='Centroids')
    
    plt.title(title)
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.colorbar(scatter, label='Cluster')
    if centers is not None:
        plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

# –ü—Ä–∏–∫–ª–∞–¥
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X)
visualize_clusters(X, labels, kmeans.cluster_centers_)
```

### –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ PCA (–¥–ª—è –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö)

```python
from sklearn.decomposition import PCA

def visualize_high_dim_clusters(X, labels, centers=None):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –±–∞–≥–∞—Ç–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö —á–µ—Ä–µ–∑ PCA"""
    
    # PCA –¥–æ 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X)
    
    # –¶–µ–Ω—Ç—Ä–∏ —Ç–∞–∫–æ–∂ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—É—î–º–æ
    centers_pca = None
    if centers is not None:
        centers_pca = pca.transform(centers)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    plt.figure(figsize=(10, 6))
    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels,
                         cmap='viridis', alpha=0.6, s=50)
    
    if centers_pca is not None:
        plt.scatter(centers_pca[:, 0], centers_pca[:, 1],
                   c='red', marker='X', s=200,
                   edgecolors='black', linewidths=2,
                   label='Centroids')
    
    plt.title(f'K-Means (PCA projection, explained var: {pca.explained_variance_ratio_.sum():.2%})')
    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
    plt.colorbar(scatter, label='Cluster')
    if centers_pca is not None:
        plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

# –ü—Ä–∏–∫–ª–∞–¥ –∑ Iris (4D ‚Üí 2D)
from sklearn.datasets import load_iris

iris = load_iris()
X_iris = iris.data

kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X_iris)

visualize_high_dim_clusters(X_iris, labels, kmeans.cluster_centers_)
```

---

## 8Ô∏è‚É£ –ü–æ–≤–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç—ñ–≤

```python
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns

# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –∫–ª—ñ—î–Ω—Ç—ñ–≤
np.random.seed(42)
n_customers = 500

data = {
    'Age': np.random.randint(18, 70, n_customers),
    'Income': np.random.randint(20000, 150000, n_customers),
    'SpendingScore': np.random.randint(1, 100, n_customers),
    'Frequency': np.random.randint(1, 50, n_customers)
}

df = pd.DataFrame(data)
print(df.head())
print(df.describe())

# 2. Preprocessing
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df)

# 3. –í–∏–±—ñ—Ä K
K_range = range(2, 11)
silhouette_scores = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(score)
    print(f"K={k}: Silhouette={score:.3f}")

# –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π K
optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"\nOptimal K: {optimal_k}")

# 4. –§—ñ–Ω–∞–ª—å–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# 5. –ê–Ω–∞–ª—ñ–∑ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
print("\n=== Cluster Analysis ===")
cluster_summary = df.groupby('Cluster').agg({
    'Age': ['mean', 'std'],
    'Income': ['mean', 'std'],
    'SpendingScore': ['mean', 'std'],
    'Frequency': ['mean', 'std']
}).round(2)
print(cluster_summary)

# –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª—ñ—î–Ω—Ç—ñ–≤ —É –∫–æ–∂–Ω–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—ñ
print("\nCluster sizes:")
print(df['Cluster'].value_counts().sort_index())

# 6. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Income vs Spending Score
axes[0, 0].scatter(df['Income'], df['SpendingScore'], 
                   c=df['Cluster'], cmap='viridis', alpha=0.6)
axes[0, 0].set_xlabel('Income')
axes[0, 0].set_ylabel('Spending Score')
axes[0, 0].set_title('Income vs Spending Score')

# Age vs Spending Score
axes[0, 1].scatter(df['Age'], df['SpendingScore'],
                   c=df['Cluster'], cmap='viridis', alpha=0.6)
axes[0, 1].set_xlabel('Age')
axes[0, 1].set_ylabel('Spending Score')
axes[0, 1].set_title('Age vs Spending Score')

# Income vs Frequency
axes[1, 0].scatter(df['Income'], df['Frequency'],
                   c=df['Cluster'], cmap='viridis', alpha=0.6)
axes[1, 0].set_xlabel('Income')
axes[1, 0].set_ylabel('Frequency')
axes[1, 0].set_title('Income vs Frequency')

# Cluster distribution
df['Cluster'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 1])
axes[1, 1].set_xlabel('Cluster')
axes[1, 1].set_ylabel('Count')
axes[1, 1].set_title('Cluster Distribution')

plt.tight_layout()
plt.show()

# 7. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
print("\n=== Cluster Interpretation ===")
for cluster in range(optimal_k):
    cluster_data = df[df['Cluster'] == cluster]
    print(f"\nCluster {cluster} ({len(cluster_data)} customers):")
    print(f"  Age: {cluster_data['Age'].mean():.1f} years")
    print(f"  Income: ${cluster_data['Income'].mean():.0f}")
    print(f"  Spending Score: {cluster_data['SpendingScore'].mean():.1f}")
    print(f"  Frequency: {cluster_data['Frequency'].mean():.1f} times")
```

---

## 9Ô∏è‚É£ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ

```python
import joblib

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)

joblib.dump(kmeans, 'kmeans_model.pkl')
joblib.dump(scaler, 'scaler.pkl')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
loaded_kmeans = joblib.load('kmeans_model.pkl')
loaded_scaler = joblib.load('scaler.pkl')

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
new_data = np.array([[25, 50000, 75, 12]])
new_data_scaled = loaded_scaler.transform(new_data)
cluster = loaded_kmeans.predict(new_data_scaled)

print(f"New customer belongs to cluster: {cluster[0]}")
```

---

## üîü –ü–æ—Ä–∞–¥–∏ —Ç–∞ best practices

### 1. –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π –¥–∞–Ω—ñ

```python
# –ü–û–ì–ê–ù–û
kmeans = KMeans(n_clusters=3)
kmeans.fit(X)

# –î–û–ë–†–ï
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
kmeans = KMeans(n_clusters=3)
kmeans.fit(X_scaled)
```

### 2. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π n_init > 1

```python
# –ü–û–ì–ê–ù–û
kmeans = KMeans(n_clusters=3, n_init=1)

# –î–û–ë–†–ï (10 —Ä—ñ–∑–Ω–∏—Ö —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ–π, –≤–∏–±–∏—Ä–∞—î –Ω–∞–π–∫—Ä–∞—â—É)
kmeans = KMeans(n_clusters=3, n_init=10)
```

### 3. –§—ñ–∫—Å—É–π random_state

```python
kmeans = KMeans(n_clusters=3, random_state=42)
```

### 4. –ü–µ—Ä–µ–≤—ñ—Ä—è–π –º–µ—Ç—Ä–∏–∫–∏

```python
from sklearn.metrics import silhouette_score

labels = kmeans.fit_predict(X_scaled)
score = silhouette_score(X_scaled, labels)

if score < 0.25:
    print("‚ö†Ô∏è –°–ª–∞–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤!")
```

### 5. –í—ñ–∑—É–∞–ª—ñ–∑—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

```python
# –ó–∞–≤–∂–¥–∏ –¥–∏–≤–∏—Å—å –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏ –æ—á–∏–º–∞
visualize_clusters(X_scaled, labels, kmeans.cluster_centers_)
```

### 6. –î–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö ‚Üí MiniBatchKMeans

```python
if len(X) > 10000:
    kmeans = MiniBatchKMeans(n_clusters=3, batch_size=1000)
else:
    kmeans = KMeans(n_clusters=3)
```

---

## –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è K-Means

```python
# ‚úÖ 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
X = load_data()

# ‚úÖ 2. EDA
print(X.shape)
print(pd.DataFrame(X).describe())

# ‚úÖ 3. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ‚úÖ 4. –í–∏–±—ñ—Ä K (Elbow + Silhouette)
evaluate_kmeans(X_scaled, range(2, 11))

# ‚úÖ 5. –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
kmeans = KMeans(n_clusters=optimal_k, n_init=10, random_state=42)
labels = kmeans.fit_predict(X_scaled)

# ‚úÖ 6. –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
silhouette = silhouette_score(X_scaled, labels)
print(f"Silhouette: {silhouette:.3f}")

# ‚úÖ 7. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
visualize_clusters(X_scaled, labels, kmeans.cluster_centers_)

# ‚úÖ 8. –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è
analyze_clusters(X, labels)

# ‚úÖ 9. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
joblib.dump(kmeans, 'model.pkl')
```

---

## –ö–æ—Ä–∏—Å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è

- [sklearn KMeans docs](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [sklearn Clustering Guide](https://scikit-learn.org/stable/modules/clustering.html)
- [Silhouette Analysis](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)

---

**–°—Ç–≤–æ—Ä–µ–Ω–æ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è K-Means –≤ –ø—Ä–æ—î–∫—Ç–∞—Ö** üöÄ