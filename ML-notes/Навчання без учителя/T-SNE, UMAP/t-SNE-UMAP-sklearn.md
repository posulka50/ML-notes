# t-SNE —Ç–∞ UMAP ‚Äî sklearn –ø—Ä–∞–∫—Ç–∏–∫–∞

–ü–æ–≤–Ω–∏–π –ø—Ä–∞–∫—Ç–∏—á–Ω–∏–π –≥–∞–π–¥ –ø–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—é t-SNE —Ç–∞ UMAP –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏ –∫–æ–¥—É.

---

## üì¶ –û—Å–Ω–æ–≤–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D

# t-SNE
from sklearn.manifold import TSNE

# UMAP (–ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏: pip install umap-learn)
import umap

# PCA (–¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è)
from sklearn.decomposition import PCA

# Preprocessing
from sklearn.preprocessing import StandardScaler

# Metrics
from sklearn.metrics import silhouette_score

# Data
from sklearn.datasets import (
    load_iris, 
    load_digits, 
    load_wine,
    make_blobs,
    make_moons
)

# –î–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
from sklearn.datasets import fetch_openml
```

---

## 1Ô∏è‚É£ t-SNE ‚Äî sklearn.manifold.TSNE

### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
TSNE(
    n_components=2,            # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É (2 –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó)
    perplexity=30.0,           # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤ (5-50)
    early_exaggeration=12.0,   # –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –Ω–∞ —Ä–∞–Ω–Ω—ñ—Ö —ñ—Ç–µ—Ä–∞—Ü—ñ—è—Ö
    learning_rate=200.0,       # –®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è (10-1000, auto='auto')
    n_iter=1000,               # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π (–º—ñ–Ω 250, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ 1000+)
    n_iter_without_progress=300,  # –ó—É–ø–∏–Ω–∫–∞ —è–∫—â–æ –Ω–µ–º–∞—î –ø—Ä–æ–≥—Ä–µ—Å—É
    min_grad_norm=1e-7,        # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç –¥–ª—è –∑—É–ø–∏–Ω–∫–∏
    metric='euclidean',        # –ú–µ—Ç—Ä–∏–∫–∞: 'euclidean', 'cosine', 'manhattan', etc.
    metric_params=None,        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–µ—Ç—Ä–∏–∫–∏
    init='random',             # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è: 'random', 'pca'
    verbose=0,                 # –í–∏–≤–æ–¥–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å (0, 1, 2)
    random_state=None,         # Seed –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ
    method='barnes_hut',       # 'barnes_hut' (—à–≤–∏–¥—à–∏–π) –∞–±–æ 'exact'
    angle=0.5,                 # –î–ª—è barnes_hut (0.2-0.8)
    n_jobs=None                # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —è–¥–µ—Ä (—Ç—ñ–ª—å–∫–∏ –¥–ª—è exact method)
)
```

---

### –ê—Ç—Ä–∏–±—É—Ç–∏ –ø—ñ—Å–ª—è fit

```python
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X)

# –î–æ—Å—Ç—É–ø–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏:
tsne.embedding_          # –†–µ–∑—É–ª—å—Ç–∞—Ç (n_samples, n_components)
tsne.kl_divergence_      # –§—ñ–Ω–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è KL divergence
tsne.n_iter_             # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π –¥–æ –∑–±—ñ–∂–Ω–æ—Å—Ç—ñ
tsne.n_features_in_      # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤—Ö—ñ–¥–Ω–∏—Ö –æ–∑–Ω–∞–∫
```

---

### –ú–µ—Ç–æ–¥–∏

```python
# –ù–∞–≤—á–∞–Ω–Ω—è + —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
X_tsne = tsne.fit_transform(X)

# –í–ê–ñ–õ–ò–í–û: t-SNE –ù–ï –º–∞—î –æ–∫—Ä–µ–º–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ fit() —Ç–∞ transform()!
# –ù–µ –º–æ–∂–Ω–∞ –ø–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –¥–ª—è –Ω–æ–≤–∏—Ö —Ç–æ—á–æ–∫
```

---

## 2Ô∏è‚É£ –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥ t-SNE

```python
import numpy as np
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ (4D)
iris = load_iris()
X = iris.data
y = iris.target
target_names = iris.target_names

print(f"–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X.shape}")  # (150, 4)

# 2. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è (–û–ë–û–í'–Ø–ó–ö–û–í–û!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. t-SNE
tsne = TSNE(
    n_components=2,
    perplexity=30,
    learning_rate=200,
    n_iter=1000,
    random_state=42,
    verbose=1
)
X_tsne = tsne.fit_transform(X_scaled)

print(f"–ù–æ–≤–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X_tsne.shape}")  # (150, 2)
print(f"KL divergence: {tsne.kl_divergence_:.4f}")
print(f"–Ü—Ç–µ—Ä–∞—Ü—ñ–π: {tsne.n_iter_}")

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], 
                     c=y, cmap='viridis', s=50, alpha=0.7)
plt.colorbar(scatter, label='Species', ticks=[0, 1, 2])
plt.title('t-SNE visualization of Iris dataset')
plt.xlabel('t-SNE 1')
plt.ylabel('t-SNE 2')
plt.grid(True, alpha=0.3)

# –î–æ–¥–∞—Ç–∏ –ª–µ–≥–µ–Ω–¥—É –∑ –Ω–∞–∑–≤–∞–º–∏
for i, name in enumerate(target_names):
    plt.scatter([], [], c=plt.cm.viridis(i/2), label=name, s=50)
plt.legend()

plt.show()
```

---

## 3Ô∏è‚É£ UMAP ‚Äî umap.UMAP

### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏

```python
umap.UMAP(
    n_neighbors=15,            # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å—É—Å—ñ–¥—ñ–≤ (2-100)
    n_components=2,            # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–∏—Ö–æ–¥—É
    metric='euclidean',        # –ú–µ—Ç—Ä–∏–∫–∞: 'euclidean', 'cosine', 'manhattan', etc.
    metric_kwds=None,          # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–µ—Ç—Ä–∏–∫–∏
    output_metric='euclidean', # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –≤–∏—Ö–æ–¥—É
    n_epochs=None,             # –ö—ñ–ª—å–∫—ñ—Å—Ç—å epochs (auto = 200-500)
    learning_rate=1.0,         # –®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
    init='spectral',           # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è: 'spectral', 'random'
    min_dist=0.1,              # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏ (0.0-0.99)
    spread=1.0,                # –†–æ–∑–∫–∏–¥ —Ç–æ—á–æ–∫
    low_memory=False,          # –†–µ–∂–∏–º –Ω–∏–∑—å–∫–æ—ó –ø–∞–º'—è—Ç—ñ
    set_op_mix_ratio=1.0,      # –ë–∞–ª–∞–Ω—Å fuzzy union/intersection
    local_connectivity=1.0,    # –õ–æ–∫–∞–ª—å–Ω–∞ –∑–≤'—è–∑–∞–Ω—ñ—Å—Ç—å
    repulsion_strength=1.0,    # –°–∏–ª–∞ –≤—ñ–¥—à—Ç–æ–≤—Ö—É–≤–∞–Ω–Ω—è
    negative_sample_rate=5,    # –ß–∞—Å—Ç–æ—Ç–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö —Å–µ–º–ø–ª—ñ–≤
    transform_queue_size=4.0,  # –†–æ–∑–º—ñ—Ä —á–µ—Ä–≥–∏ –¥–ª—è transform
    a=None,                    # –ü–∞—Ä–∞–º–µ—Ç—Ä –∫—Ä–∏–≤–æ—ó (auto)
    b=None,                    # –ü–∞—Ä–∞–º–µ—Ç—Ä –∫—Ä–∏–≤–æ—ó (auto)
    random_state=None,         # Seed
    angular_rp_forest=False,   # Angular random projection forest
    target_n_neighbors=-1,     # –î–ª—è supervised UMAP
    target_metric='categorical',  # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è target
    target_weight=0.5,         # –í–∞–≥–∞ target —É supervised
    transform_seed=42,         # Seed –¥–ª—è transform
    force_approximation_algorithm=False,
    verbose=False,             # –í–∏–≤–æ–¥–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å
    unique=False               # –í–∏–¥–∞–ª–∏—Ç–∏ –¥—É–±–ª—ñ–∫–∞—Ç–∏
)
```

---

### –ê—Ç—Ä–∏–±—É—Ç–∏ –ø—ñ—Å–ª—è fit

```python
reducer = umap.UMAP(n_components=2, random_state=42)
X_umap = reducer.fit_transform(X)

# –î–æ—Å—Ç—É–ø–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏:
reducer.embedding_           # –†–µ–∑—É–ª—å—Ç–∞—Ç (n_samples, n_components)
reducer.graph_               # –ì—Ä–∞—Ñ —Å—É—Å—ñ–¥—Å—Ç–≤–∞
reducer.transform_            # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –Ω–æ–≤–∏—Ö —Ç–æ—á–æ–∫
```

---

### –ú–µ—Ç–æ–¥–∏

```python
# –ù–∞–≤—á–∞–Ω–Ω—è
reducer.fit(X)

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è (–¥–ª—è –Ω–∞–≤—á–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö)
X_umap = reducer.transform(X)

# –ù–∞–≤—á–∞–Ω–Ω—è + —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
X_umap = reducer.fit_transform(X)

# –ü–ï–†–ï–í–ê–ì–ê –Ω–∞–¥ t-SNE: –º–æ–∂–Ω–∞ –¥–ª—è –Ω–æ–≤–∏—Ö —Ç–æ—á–æ–∫!
X_new_umap = reducer.transform(X_new)
```

---

## 4Ô∏è‚É£ –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥ UMAP

```python
import umap
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
iris = load_iris()
X = iris.data
y = iris.target

# 2. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. UMAP
reducer = umap.UMAP(
    n_neighbors=15,
    min_dist=0.1,
    n_components=2,
    random_state=42
)
X_umap = reducer.fit_transform(X_scaled)

print(f"–ù–æ–≤–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X_umap.shape}")

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], 
                     c=y, cmap='viridis', s=50, alpha=0.7)
plt.colorbar(scatter, label='Species')
plt.title('UMAP visualization of Iris dataset')
plt.xlabel('UMAP 1')
plt.ylabel('UMAP 2')
plt.grid(True, alpha=0.3)
plt.show()
```

---

## 5Ô∏è‚É£ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è PCA vs t-SNE vs UMAP

```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ –¥–∞–Ω—ñ (64D: 8x8 –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ü–∏—Ñ—Ä)
digits = load_digits()
X = digits.data
y = digits.target

print(f"–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X.shape}")

# 2. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. PCA
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)
print(f"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}")

# 4. t-SNE
tsne = TSNE(n_components=2, perplexity=30, random_state=42, verbose=0)
X_tsne = tsne.fit_transform(X_scaled)
print(f"t-SNE KL divergence: {tsne.kl_divergence_:.4f}")

# 5. UMAP
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_umap = reducer.fit_transform(X_scaled)

# 6. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# PCA
axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
axes[0].set_title(f'PCA ({pca.explained_variance_ratio_.sum():.1%} variance)')
axes[0].set_xlabel('PC1')
axes[0].set_ylabel('PC2')
axes[0].grid(True, alpha=0.3)

# t-SNE
axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
axes[1].set_title('t-SNE')
axes[1].set_xlabel('t-SNE 1')
axes[1].set_ylabel('t-SNE 2')
axes[1].grid(True, alpha=0.3)

# UMAP
axes[2].scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
axes[2].set_title('UMAP')
axes[2].set_xlabel('UMAP 1')
axes[2].set_ylabel('UMAP 2')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## 6Ô∏è‚É£ –í–ø–ª–∏–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ t-SNE

### Perplexity

```python
from sklearn.manifold import TSNE
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

# –î–∞–Ω—ñ
digits = load_digits()
X = digits.data
y = digits.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# –†—ñ–∑–Ω—ñ perplexity
perplexities = [5, 10, 30, 50]

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, perplexity in enumerate(perplexities):
    tsne = TSNE(
        n_components=2,
        perplexity=perplexity,
        random_state=42,
        verbose=0
    )
    X_tsne = tsne.fit_transform(X_scaled)
    
    axes[idx].scatter(X_tsne[:, 0], X_tsne[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
    axes[idx].set_title(f'Perplexity = {perplexity}')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- `perplexity=5`: –ë–∞–≥–∞—Ç–æ –º–∞–ª–∏—Ö, —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
- `perplexity=30`: –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
- `perplexity=50`: –ë—ñ–ª—å—à—ñ, –æ–±'—î–¥–Ω–∞–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏

---

### Learning rate

```python
learning_rates = [10, 100, 200, 1000]

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, lr in enumerate(learning_rates):
    tsne = TSNE(
        n_components=2,
        learning_rate=lr,
        random_state=42,
        verbose=0
    )
    X_tsne = tsne.fit_transform(X_scaled)
    
    axes[idx].scatter(X_tsne[:, 0], X_tsne[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
    axes[idx].set_title(f'Learning Rate = {lr}')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- `lr=10`: –ü–æ–≤—ñ–ª—å–Ω–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å, –º–æ–∂–µ –Ω–µ –∑—ñ–π—Ç–∏—Å—å
- `lr=200`: –î–æ–±—Ä–µ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º)
- `lr=1000`: –î—É–∂–µ —à–≤–∏–¥–∫–æ, –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω–æ

---

### Iterations

```python
n_iters = [250, 500, 1000, 5000]

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, n_iter in enumerate(n_iters):
    tsne = TSNE(
        n_components=2,
        n_iter=n_iter,
        random_state=42,
        verbose=0
    )
    X_tsne = tsne.fit_transform(X_scaled)
    
    axes[idx].scatter(X_tsne[:, 0], X_tsne[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
    axes[idx].set_title(f'Iterations = {n_iter}')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## 7Ô∏è‚É£ –í–ø–ª–∏–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ UMAP

### n_neighbors

```python
import umap
import matplotlib.pyplot as plt

# –†—ñ–∑–Ω—ñ n_neighbors
n_neighbors_list = [5, 15, 30, 50]

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, n_neighbors in enumerate(n_neighbors_list):
    reducer = umap.UMAP(
        n_neighbors=n_neighbors,
        min_dist=0.1,
        random_state=42
    )
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[idx].scatter(X_umap[:, 0], X_umap[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
    axes[idx].set_title(f'n_neighbors = {n_neighbors}')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- `n_neighbors=5`: –§–æ–∫—É—Å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ, –±–∞–≥–∞—Ç–æ –º–∞–ª–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
- `n_neighbors=15`: –ë–∞–ª–∞–Ω—Å (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º)
- `n_neighbors=50`: –§–æ–∫—É—Å –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ, –≤–µ–ª–∏–∫—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏

---

### min_dist

```python
min_dists = [0.0, 0.1, 0.5, 0.99]

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, min_dist in enumerate(min_dists):
    reducer = umap.UMAP(
        n_neighbors=15,
        min_dist=min_dist,
        random_state=42
    )
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[idx].scatter(X_umap[:, 0], X_umap[:, 1], 
                     c=y, cmap='tab10', s=20, alpha=0.6)
    axes[idx].set_title(f'min_dist = {min_dist}')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- `min_dist=0.0`: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —â—ñ–ª—å–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω—ñ —Ç–æ—á–∫–∏
- `min_dist=0.1`: –ù–æ—Ä–º–∞–ª—å–Ω–æ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º)
- `min_dist=0.99`: –†–æ–∑—Ä—ñ–¥–∂–µ–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏

---

## 8Ô∏è‚É£ –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏

### –ü—Ä–∏–∫–ª–∞–¥ 1: –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó

```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_blobs
import umap
import matplotlib.pyplot as plt

# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤–∏—Å–æ–∫–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö (50D)
X, y_true = make_blobs(
    n_samples=500,
    n_features=50,
    centers=5,
    cluster_std=1.0,
    random_state=42
)

# 2. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è
kmeans = KMeans(n_clusters=5, random_state=42)
y_pred = kmeans.fit_predict(X_scaled)

# 4. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ UMAP
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_umap = reducer.fit_transform(X_scaled)

# 5. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# –°–ø—Ä–∞–≤–∂–Ω—ñ –º—ñ—Ç–∫–∏
axes[0].scatter(X_umap[:, 0], X_umap[:, 1], c=y_true, cmap='tab10', s=50, alpha=0.6)
axes[0].set_title('True Labels (UMAP)')
axes[0].grid(True, alpha=0.3)

# –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ –º—ñ—Ç–∫–∏
axes[1].scatter(X_umap[:, 0], X_umap[:, 1], c=y_pred, cmap='tab10', s=50, alpha=0.6)
axes[1].set_title('K-Means Predictions (UMAP)')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.metrics import adjusted_rand_score
ari = adjusted_rand_score(y_true, y_pred)
print(f"Adjusted Rand Index: {ari:.3f}")
```

---

### –ü—Ä–∏–∫–ª–∞–¥ 2: –ó–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–¥ ML

```python
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import umap
import time

# 1. –î–∞–Ω—ñ (64D)
digits = load_digits()
X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 2. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# === –ë–ï–ó –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ ===
print("=== –ë–ï–ó –∑–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ ===")
clf = LogisticRegression(max_iter=1000, random_state=42)

start = time.time()
clf.fit(X_train_scaled, y_train)
time_train = time.time() - start

score = clf.score(X_test_scaled, y_test)
print(f"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X_train_scaled.shape}")
print(f"–¢–æ—á–Ω—ñ—Å—Ç—å: {score:.3f}")
print(f"–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {time_train:.3f} —Å–µ–∫")

# === –ó UMAP ===
print("\n=== –ó UMAP (n_components=10) ===")

# –í–ê–ñ–õ–ò–í–û: fit –Ω–∞ train, transform –Ω–∞ test
reducer = umap.UMAP(n_components=10, random_state=42)
X_train_umap = reducer.fit_transform(X_train_scaled)
X_test_umap = reducer.transform(X_test_scaled)

clf_umap = LogisticRegression(max_iter=1000, random_state=42)

start = time.time()
clf_umap.fit(X_train_umap, y_train)
time_train_umap = time.time() - start

score_umap = clf_umap.score(X_test_umap, y_test)
print(f"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {X_train_umap.shape}")
print(f"–¢–æ—á–Ω—ñ—Å—Ç—å: {score_umap:.3f}")
print(f"–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {time_train_umap:.3f} —Å–µ–∫")

print(f"\n=== –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è ===")
print(f"–ó–º—ñ–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ: {score_umap - score:+.3f}")
print(f"–ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: {time_train/time_train_umap:.1f}x")
```

---

### –ü—Ä–∏–∫–ª–∞–¥ 3: Supervised UMAP (–∑ –º—ñ—Ç–∫–∞–º–∏)

```python
import umap
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# 1. –î–∞–Ω—ñ
digits = load_digits()
X = digits.data
y = digits.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 2. Unsupervised UMAP
reducer_unsup = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_unsup = reducer_unsup.fit_transform(X_scaled)

# 3. Supervised UMAP (–∑ –º—ñ—Ç–∫–∞–º–∏)
reducer_sup = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_sup = reducer_sup.fit_transform(X_scaled, y=y)

# 4. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Unsupervised
axes[0].scatter(X_unsup[:, 0], X_unsup[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
axes[0].set_title('Unsupervised UMAP')
axes[0].grid(True, alpha=0.3)

# Supervised
axes[1].scatter(X_sup[:, 0], X_sup[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
axes[1].set_title('Supervised UMAP (with labels)')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Supervised UMAP –∫—Ä–∞—â–µ —Ä–æ–∑–¥—ñ–ª—è—î –∫–ª–∞—Å–∏!
```

---

### –ü—Ä–∏–∫–ª–∞–¥ 4: 3D –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

```python
from mpl_toolkits.mplot3d import Axes3D
import umap
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

# 1. –î–∞–Ω—ñ
digits = load_digits()
X = digits.data
y = digits.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 2. UMAP –≤ 3D
reducer = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)
X_umap_3d = reducer.fit_transform(X_scaled)

# 3. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

scatter = ax.scatter(
    X_umap_3d[:, 0], 
    X_umap_3d[:, 1], 
    X_umap_3d[:, 2],
    c=y, 
    cmap='tab10', 
    s=20, 
    alpha=0.6
)

ax.set_xlabel('UMAP 1')
ax.set_ylabel('UMAP 2')
ax.set_zlabel('UMAP 3')
ax.set_title('UMAP 3D visualization')
plt.colorbar(scatter, ax=ax, label='Digit')

plt.show()
```

---

### –ü—Ä–∏–∫–ª–∞–¥ 5: –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

```python
from sklearn.datasets import load_digits
import umap
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# –î–∞–Ω—ñ
digits = load_digits()
X = digits.data[:500]  # –ø—ñ–¥–≤–∏–±—ñ—Ä–∫–∞ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
y = digits.target[:500]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# t-SNE: –∫—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤
fig, axes = plt.subplots(2, 3, figsize=(18, 10))

for i in range(3):
    # t-SNE
    tsne = TSNE(n_components=2, random_state=i*42, verbose=0)
    X_tsne = tsne.fit_transform(X_scaled)
    
    axes[0, i].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
    axes[0, i].set_title(f't-SNE (seed={i*42})')
    axes[0, i].grid(True, alpha=0.3)
    
    # UMAP
    reducer = umap.UMAP(n_components=2, random_state=i*42)
    X_umap = reducer.fit_transform(X_scaled)
    
    axes[1, i].scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='tab10', s=20, alpha=0.6)
    axes[1, i].set_title(f'UMAP (seed={i*42})')
    axes[1, i].grid(True, alpha=0.3)

plt.suptitle('Stability: t-SNE vs UMAP (different random seeds)', fontsize=14)
plt.tight_layout()
plt.show()

# UMAP –±—ñ–ª—å—à —Å—Ç–∞–±—ñ–ª—å–Ω–∏–π (—Å—Ö–æ–∂—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö seeds)
```

---

## 9Ô∏è‚É£ PCA –ø–µ—Ä–µ–¥ t-SNE/UMAP (–¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ)

```python
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
import time

# –î–∞–Ω—ñ –∑ –±–∞–≥–∞—Ç—å–º–∞ –æ–∑–Ω–∞–∫–∞–º–∏
from sklearn.datasets import make_classification
X, y = make_classification(
    n_samples=1000,
    n_features=200,  # –±–∞–≥–∞—Ç–æ –æ–∑–Ω–∞–∫
    n_informative=50,
    random_state=42
)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# === –ë–µ–∑ PCA ===
print("=== –ë–ï–ó PCA ===")

start = time.time()
tsne = TSNE(n_components=2, random_state=42, verbose=0)
X_tsne_direct = tsne.fit_transform(X_scaled)
time_direct = time.time() - start

print(f"–ß–∞—Å: {time_direct:.2f} —Å–µ–∫")

# === –ó PCA ===
print("\n=== –ó PCA (200D ‚Üí 50D ‚Üí 2D) ===")

start = time.time()

# PCA —Å–ø–æ—á–∞—Ç–∫—É
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X_scaled)
print(f"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}")

# –ü–æ—Ç—ñ–º t-SNE
tsne = TSNE(n_components=2, random_state=42, verbose=0)
X_tsne_pca = tsne.fit_transform(X_pca)

time_pca = time.time() - start

print(f"–ß–∞—Å: {time_pca:.2f} —Å–µ–∫")
print(f"–ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: {time_direct/time_pca:.1f}x")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

axes[0].scatter(X_tsne_direct[:, 0], X_tsne_direct[:, 1], c=y, cmap='viridis', s=20, alpha=0.6)
axes[0].set_title(f't-SNE –Ω–∞–ø—Ä—è–º—É ({time_direct:.1f}s)')

axes[1].scatter(X_tsne_pca[:, 0], X_tsne_pca[:, 1], c=y, cmap='viridis', s=20, alpha=0.6)
axes[1].set_title(f'PCA ‚Üí t-SNE ({time_pca:.1f}s)')

plt.tight_layout()
plt.show()
```

---

## üîü –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è

### t-SNE (–ù–ï –º–æ–∂–Ω–∞ –∑–±–µ—Ä–µ–≥—Ç–∏ –¥–ª—è –Ω–æ–≤–∏—Ö —Ç–æ—á–æ–∫)

```python
import joblib
from sklearn.manifold import TSNE

# –ù–∞–≤—á–∞–Ω–Ω—è
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_scaled)

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É (–∞–ª–µ –Ω–µ –º–æ–¥–µ–ª—ñ!)
result = {
    'X_tsne': X_tsne,
    'scaler': scaler,
    'kl_divergence': tsne.kl_divergence_
}

joblib.dump(result, 'tsne_result.pkl')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
loaded = joblib.load('tsne_result.pkl')
X_tsne_loaded = loaded['X_tsne']

# –í–ê–ñ–õ–ò–í–û: –ù–µ –º–æ–∂–Ω–∞ –∑–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ –¥–æ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö!
# –¢—Ä–µ–±–∞ –∑–∞–Ω–æ–≤–æ —Ä–æ–±–∏—Ç–∏ fit_transform –¥–ª—è –≤—Å—å–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É
```

---

### UMAP (–ú–û–ñ–ù–ê –∑–±–µ—Ä–µ–≥—Ç–∏ –º–æ–¥–µ–ª—å)

```python
import joblib
import umap

# –ù–∞–≤—á–∞–Ω–Ω—è
reducer = umap.UMAP(n_components=2, random_state=42)
X_umap = reducer.fit_transform(X_scaled)

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
model = {
    'umap': reducer,
    'scaler': scaler
}

joblib.dump(model, 'umap_model.pkl')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
loaded_model = joblib.load('umap_model.pkl')
loaded_reducer = loaded_model['umap']
loaded_scaler = loaded_model['scaler']

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
X_new = np.random.randn(10, X.shape[1])
X_new_scaled = loaded_scaler.transform(X_new)
X_new_umap = loaded_reducer.transform(X_new_scaled)

print(f"–ù–æ–≤—ñ —Ç–æ—á–∫–∏: {X_new.shape} ‚Üí {X_new_umap.shape}")
```

---

## 1Ô∏è‚É£1Ô∏è‚É£ –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è (Plotly)

```python
import plotly.express as px
import pandas as pd
import umap
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler

# 1. –î–∞–Ω—ñ
digits = load_digits()
X = digits.data
y = digits.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 2. UMAP
reducer = umap.UMAP(n_components=2, random_state=42)
X_umap = reducer.fit_transform(X_scaled)

# 3. DataFrame
df = pd.DataFrame({
    'UMAP_1': X_umap[:, 0],
    'UMAP_2': X_umap[:, 1],
    'Digit': y.astype(str)
})

# 4. –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π scatter plot
fig = px.scatter(
    df, 
    x='UMAP_1', 
    y='UMAP_2', 
    color='Digit',
    title='Interactive UMAP visualization of Digits',
    width=900, 
    height=700
)

fig.update_traces(marker=dict(size=5, opacity=0.7))
fig.show()

# –ú–æ–∂–Ω–∞ –∑–±–µ—Ä–µ–≥—Ç–∏ –≤ HTML
# fig.write_html('umap_digits.html')
```

---

## 1Ô∏è‚É£2Ô∏è‚É£ –ü–æ—Ä–∞–¥–∏ —Ç–∞ best practices

### 1. –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π –¥–∞–Ω—ñ

```python
# –ü–û–ì–ê–ù–û
tsne = TSNE()
X_tsne = tsne.fit_transform(X)

# –î–û–ë–†–ï
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
tsne = TSNE()
X_tsne = tsne.fit_transform(X_scaled)
```

---

### 2. –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

```python
# t-SNE: —Å–ø—Ä–æ–±—É–π —Ä—ñ–∑–Ω—ñ perplexity
for perp in [5, 10, 30, 50]:
    tsne = TSNE(perplexity=perp, random_state=42)
    X_tsne = tsne.fit_transform(X_scaled)
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π

# UMAP: —Å–ø—Ä–æ–±—É–π —Ä—ñ–∑–Ω—ñ n_neighbors
for n_neigh in [5, 15, 30, 50]:
    reducer = umap.UMAP(n_neighbors=n_neigh, random_state=42)
    X_umap = reducer.fit_transform(X_scaled)
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–π
```

---

### 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π PCA –ø–µ—Ä–µ–¥ t-SNE/UMAP –¥–ª—è >100 –æ–∑–Ω–∞–∫

```python
# –Ø–∫—â–æ –±–∞–≥–∞—Ç–æ –æ–∑–Ω–∞–∫
if X.shape[1] > 100:
    pca = PCA(n_components=50)
    X_pca = pca.fit_transform(X_scaled)
    
    # –ü–æ—Ç—ñ–º t-SNE/UMAP
    tsne = TSNE()
    X_tsne = tsne.fit_transform(X_pca)
```

---

### 4. –ü–µ—Ä–µ–≤—ñ—Ä—è–π —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å (–∫—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤)

```python
# –ó–∞–ø—É—Å—Ç–∏ 3-5 —Ä–∞–∑—ñ–≤ –∑ —Ä—ñ–∑–Ω–∏–º–∏ seeds
results = []
for seed in [42, 123, 456]:
    tsne = TSNE(random_state=seed)
    X_tsne = tsne.fit_transform(X_scaled)
    results.append(X_tsne)

# –Ø–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥—É–∂–µ —Ä—ñ–∑–Ω—ñ ‚Üí –ø–æ–≥–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∞–±–æ –¥–∞–Ω—ñ
```

---

### 5. t-SNE —Ç—ñ–ª—å–∫–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó!

```python
# –ü–û–ì–ê–ù–û (–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥–ª—è ML)
X_tsne = tsne.fit_transform(X_train)
model.fit(X_tsne, y_train)  # ‚úó

# –î–û–ë–†–ï (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π PCA –∞–±–æ UMAP)
X_pca = pca.fit_transform(X_train)
model.fit(X_pca, y_train)  # ‚úì
```

---

### 6. –î–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö: sampling

```python
# –Ø–∫—â–æ >100,000 —Ç–æ—á–æ–∫
if len(X) > 100000:
    # –í—ñ–∑—É–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ø—ñ–¥–≤–∏–±—ñ—Ä–∫—É
    idx = np.random.choice(len(X), size=10000, replace=False)
    X_sample = X_scaled[idx]
    
    tsne = TSNE()
    X_tsne = tsne.fit_transform(X_sample)
```

---

### 7. –§—ñ–∫—Å—É–π random_state

```python
# –î–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ
tsne = TSNE(random_state=42)
reducer = umap.UMAP(random_state=42)
```

---

## –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è t-SNE/UMAP

```python
# ‚úÖ 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ
X = load_data()

# ‚úÖ 2. EDA
print(X.shape)
print(pd.DataFrame(X).describe())

# ‚úÖ 3. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è (–û–ë–û–í'–Ø–ó–ö–û–í–û!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ‚úÖ 4. –Ø–∫—â–æ >100 –æ–∑–Ω–∞–∫ ‚Üí —Å–ø–æ—á–∞—Ç–∫—É PCA
if X.shape[1] > 100:
    pca = PCA(n_components=50)
    X_scaled = pca.fit_transform(X_scaled)

# ‚úÖ 5. –í–∏–±—ñ—Ä –º–µ—Ç–æ–¥—É
# –î–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó: t-SNE –∞–±–æ UMAP
# –î–ª—è ML preprocessing: PCA –∞–±–æ UMAP

# ‚úÖ 6. t-SNE
tsne = TSNE(
    n_components=2,
    perplexity=30,  # –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π: 5-50
    random_state=42
)
X_tsne = tsne.fit_transform(X_scaled)

# –∞–±–æ UMAP
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=15,  # –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π: 5-50
    min_dist=0.1,    # –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π: 0.0-0.5
    random_state=42
)
X_umap = reducer.fit_transform(X_scaled)

# ‚úÖ 7. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels, alpha=0.6)
plt.title('t-SNE')
plt.show()

# ‚úÖ 8. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ (–∫—ñ–ª—å–∫–∞ –∑–∞–ø—É—Å–∫—ñ–≤)
for seed in [42, 123, 456]:
    # –ó–∞–ø—É—Å—Ç–∏ –∑–Ω–æ–≤—É –∑ —ñ–Ω—à–∏–º seed
    # –ü–æ—Ä—ñ–≤–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

# ‚úÖ 9. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è (—Ç—ñ–ª—å–∫–∏ –¥–ª—è UMAP, –Ω–µ –¥–ª—è t-SNE)
if using_umap:
    joblib.dump(reducer, 'umap_model.pkl')
```

---

## –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | PCA | t-SNE | UMAP |
|----------------|-----|-------|------|
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å (10k —Ç–æ—á–æ–∫)** | ~1 —Å–µ–∫ | ~5 —Ö–≤ | ~30 —Å–µ–∫ |
| **–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è** | ‚úó –ü–æ–≥–∞–Ω–æ | ‚úì‚úì‚úì –í—ñ–¥–º—ñ–Ω–Ω–æ | ‚úì‚úì‚úì –í—ñ–¥–º—ñ–Ω–Ω–æ |
| **–î–ª—è ML** | ‚úì‚úì‚úì –¢–∞–∫ | ‚úó –ù—ñ | ‚úì –ú–æ–∂–Ω–∞ |
| **–ù–æ–≤—ñ —Ç–æ—á–∫–∏** | ‚úì‚úì‚úì transform() | ‚úó –ù—ñ | ‚úì transform() |
| **–î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω—ñ—Å—Ç—å** | ‚úì‚úì‚úì –¢–∞–∫ | ‚úó –ù—ñ | ‚úó –ù—ñ |
| **–í–µ–ª–∏–∫—ñ –¥–∞–Ω—ñ (>100k)** | ‚úì‚úì‚úì –¢–∞–∫ | ‚úó –ù—ñ | ‚úì‚úì –¢–∞–∫ |
| **–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏** | n_components=2 | perplexity=30 | n_neighbors=15, min_dist=0.1 |

---

## –ö–æ—Ä–∏—Å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è

- [sklearn t-SNE docs](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)
- [UMAP docs](https://umap-learn.readthedocs.io/)
- [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [Understanding UMAP](https://pair-code.github.io/understanding-umap/)

---

**–°—Ç–≤–æ—Ä–µ–Ω–æ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –≤–∏—Å–æ–∫–æ–≤–∏–º—ñ—Ä–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ t-SNE —Ç–∞ UMAP** üöÄ
